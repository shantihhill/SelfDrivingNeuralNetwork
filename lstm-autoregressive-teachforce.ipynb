{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n-C_P-zs-pY"
      },
      "source": [
        "# LSTM - vanilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = \"best_model14.pt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:17.728787Z",
          "iopub.status.busy": "2025-04-01T17:39:17.728324Z",
          "iopub.status.idle": "2025-04-01T17:39:18.875979Z",
          "shell.execute_reply": "2025-04-01T17:39:18.874618Z"
        },
        "id": "F4_wHjhZs-pa",
        "papermill": {
          "duration": 1.154057,
          "end_time": "2025-04-01T17:39:18.878059",
          "exception": false,
          "start_time": "2025-04-01T17:39:17.724002",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/salmawafa/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "/Users/salmawafa/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import Data, Batch\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:18.890746Z",
          "iopub.status.busy": "2025-04-01T17:39:18.890075Z",
          "iopub.status.idle": "2025-04-01T17:39:40.968717Z",
          "shell.execute_reply": "2025-04-01T17:39:40.967158Z"
        },
        "id": "09texa_os-pc",
        "papermill": {
          "duration": 22.084222,
          "end_time": "2025-04-01T17:39:40.970631",
          "exception": false,
          "start_time": "2025-04-01T17:39:18.886409",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data's shape (10000, 50, 110, 6)\n",
            "test_data's shape (2100, 50, 50, 6)\n"
          ]
        }
      ],
      "source": [
        "train_file = np.load('./cse-251-b-2025/train.npz')\n",
        "\n",
        "train_data = train_file['data']\n",
        "print(\"train_data's shape\", train_data.shape)\n",
        "test_file = np.load('./cse-251-b-2025/test_input.npz')\n",
        "\n",
        "test_data = test_file['data']\n",
        "print(\"test_data's shape\", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:40.97884Z",
          "iopub.status.busy": "2025-04-01T17:39:40.978362Z",
          "iopub.status.idle": "2025-04-01T17:39:41.323077Z",
          "shell.execute_reply": "2025-04-01T17:39:41.321787Z"
        },
        "id": "ckJbGP_ds-pc",
        "papermill": {
          "duration": 0.351374,
          "end_time": "2025-04-01T17:39:41.325147",
          "exception": false,
          "start_time": "2025-04-01T17:39:40.973773",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot one\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_matrix = train_data[0]\n",
        "\n",
        "for i in range(data_matrix.shape[0]):\n",
        "    xs = data_matrix[i, :, 0]\n",
        "    ys = data_matrix[i, :, 1]\n",
        "    # trim all zeros\n",
        "    xs = xs[xs != 0]\n",
        "    ys = ys[ys != 0]\n",
        "    # plot each line going from transparent to full\n",
        "    plt.plot(xs, ys)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrajectoryDatasetTrain(Dataset):\n",
        "    def __init__(self, data, scale=10.0, augment=True):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Training data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        augment: Whether to apply data augmentation (only for training)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        scene = self.data[idx]\n",
        "        # Getting 50 historical timestamps and 60 future timestamps\n",
        "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
        "        future = torch.tensor(scene[0, 50:, :2].copy(), dtype=torch.float32)  # (60, 2)\n",
        "        \n",
        "        # Data augmentation(only for training)\n",
        "        if self.augment:\n",
        "            if np.random.rand() < 0.5:\n",
        "                theta = np.random.uniform(-np.pi, np.pi)\n",
        "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
        "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
        "                # Rotate the historical trajectory and future trajectory\n",
        "                hist[..., :2] = hist[..., :2] @ R\n",
        "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
        "                future = future @ R\n",
        "            if np.random.rand() < 0.5:\n",
        "                hist[..., 0] *= -1\n",
        "                hist[..., 2] *= -1\n",
        "                future[:, 0] *= -1\n",
        "\n",
        "        # Use the last timeframe of the historical trajectory as the origin\n",
        "        origin = hist[0, 49, :2].copy()  # (2,)\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        future = future - origin\n",
        "\n",
        "        # Normalize the historical trajectory and future trajectory\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "        future = future / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            y=future.type(torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0), # (1,2)\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32), # scalar e.g. 7.0\n",
        "        )\n",
        "\n",
        "        return data_item\n",
        "    \n",
        "\n",
        "class TrajectoryDatasetTest(Dataset):\n",
        "    def __init__(self, data, scale=10.0):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Testing data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Testing data only contains historical trajectory\n",
        "        scene = self.data[idx]  # (50, 50, 6)\n",
        "        hist = scene.copy()\n",
        "        \n",
        "        origin = hist[0, 49, :2].copy()\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
        "        )\n",
        "        return data_item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple Silicon GPU\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(251)\n",
        "np.random.seed(42)\n",
        "\n",
        "scale = 7.0\n",
        "\n",
        "N = len(train_data)\n",
        "val_size = int(0.1 * N)\n",
        "train_size = N - val_size\n",
        "\n",
        "train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
        "val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "\n",
        "# Set device for training speedup\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"Using Apple Silicon GPU\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AutoRegressiveLSTM(nn.Module):\n",
        "    def __init__(self, input_dim=5, hidden_dim=512, output_dim=2, num_layers=1, future_steps=60):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.future_steps = future_steps\n",
        "\n",
        "        # Encoder: takes in past trajectory\n",
        "        self.encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        # Decoder: predicts future positions one step at a time\n",
        "        self.decoder = nn.LSTM(input_size=2, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data, forcing_ratio = 0.5):\n",
        "    # def forward(self, data):\n",
        "        x = data.x[..., :5]  # Use position + velocity\n",
        "        x = x.reshape(-1, 50, 50, 5)[:, 0, :, :]  # (batch, 50, 5), ego only\n",
        "        \n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "        if self.training:\n",
        "            future = data.y.view(batch_size, 60, 2) # (batch, 60, 2)\n",
        "\n",
        "        device = x.device\n",
        "\n",
        "        # Encode past\n",
        "        _, (hidden, cell) = self.encoder(x)\n",
        "\n",
        "        # Initialize decoder input with last observed position\n",
        "        decoder_input = x[:, -1, :2].unsqueeze(1)  # (batch, 1, 2)\n",
        "        \n",
        "        # print(\"decoder_input.shape - initial\", decoder_input.shape)  # should be (batch, 1, 2)\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(self.future_steps):\n",
        "            output, (hidden, cell) = self.decoder(decoder_input, (hidden, cell))\n",
        "            pred = self.out(output)  # (batch, 1, 2)\n",
        "            outputs.append(pred)\n",
        "\n",
        "            # TODO: remove forcing ratio?\n",
        "            if self.training and random.random() < forcing_ratio:\n",
        "            # if self.training:\n",
        "                decoder_input = future[:, t].unsqueeze(1)  # ground truth\n",
        "                # print(\"decoder_input.shape - teacher forcing\", decoder_input.shape)  # should be (batch, 1, 2)\n",
        "            else:\n",
        "                decoder_input = pred.detach()  # predicted output as next input\n",
        "                # print(\"decoder_input.shape - autoreg\", decoder_input.shape)  # should be (batch, 1, 2)\n",
        "\n",
        "        outputs = torch.cat(outputs, dim=1)  # (batch, 60, 2)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Example of basic model with simple attention mechanism\n",
        "# class SimpleLSTMWithAttn(nn.Module):\n",
        "#     def __init__(self, input_dim=5, hidden_dim=512, output_dim=60*2):\n",
        "#         super(SimpleLSTMWithAttn, self).__init__()\n",
        "#         self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        \n",
        "#         # Simple attention mechanism\n",
        "#         self.attention = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "#         # Add multi-layer prediction head for better results\n",
        "#         self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "#         self.dropout = nn.Dropout(0.1)  # Add dropout for regularization\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "#         # Initialize weights properly\n",
        "#         for name, param in self.named_parameters():\n",
        "#             if 'weight' in name:\n",
        "#                 nn.init.xavier_normal_(param)\n",
        "#             elif 'bias' in name:\n",
        "#                 nn.init.constant_(param, 0.0)\n",
        "        \n",
        "#     def forward(self, data):\n",
        "#         x = data.x[..., :5]\n",
        "#         x = x.reshape(-1, 50, 50, 5)  # (batch_size, num_agents, seq_len, input_dim)\n",
        "#         x = x[:, 0, :, :]  # Only consider ego agent (index 0)\n",
        "        \n",
        "#         # Process through LSTM\n",
        "#         lstm_out, _ = self.lstm(x)  # (batch_size, seq_len, hidden_dim)\n",
        "        \n",
        "#         # Apply attention mechanism\n",
        "#         attention_weights = torch.softmax(self.attention(lstm_out), dim=1)  # (batch_size, seq_len, 1)\n",
        "#         attended_features = torch.sum(lstm_out * attention_weights, dim=1)  # (batch_size, hidden_dim)\n",
        "        \n",
        "#         # Process through prediction head\n",
        "#         features = self.relu(self.fc1(attended_features))\n",
        "#         features = self.dropout(features)\n",
        "#         out = self.fc2(features)\n",
        "        \n",
        "#         # Reshape to (batch_size, 60, 2)\n",
        "#         return out.view(-1, 60, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_improved_model(model, train_dataloader, val_dataloader, \n",
        "                         device, criterion=nn.MSELoss(), \n",
        "                         lr=0.001, epochs=100, patience=15):\n",
        "    \"\"\"\n",
        "    Improved training function with better debugging and early stopping\n",
        "    \"\"\"\n",
        "    # Initialize optimizer with smaller learning rate\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    # Exponential decay scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "    \n",
        "    early_stopping_patience = patience\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement = 0\n",
        "    \n",
        "    # Save initial state for comparison\n",
        "    initial_state_dict = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "    \n",
        "    for epoch in tqdm.tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
        "        # ---- Training ----\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        num_train_batches = 0\n",
        "        forcing_ratio = max(0.0, 1.0 - epoch / 50)\n",
        "        \n",
        "        for batch in train_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch, forcing_ratio=forcing_ratio)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            \n",
        "            # Check for NaN predictions\n",
        "            if torch.isnan(pred).any():\n",
        "                print(f\"WARNING: NaN detected in predictions during training\")\n",
        "                continue\n",
        "                \n",
        "            loss = criterion(pred, y)\n",
        "            \n",
        "            # Check if loss is valid\n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                print(f\"WARNING: Invalid loss value: {loss.item()}\")\n",
        "                continue\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            \n",
        "            # More conservative gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            \n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            num_train_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid batches\n",
        "        if num_train_batches == 0:\n",
        "            print(\"WARNING: No valid training batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        train_loss /= num_train_batches\n",
        "        \n",
        "        # ---- Validation ----\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_mae = 0\n",
        "        val_mse = 0\n",
        "        num_val_batches = 0\n",
        "        \n",
        "        # Sample predictions for debugging\n",
        "        sample_input = None\n",
        "        sample_pred = None\n",
        "        sample_target = None\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(val_dataloader):\n",
        "                batch = batch.to(device)\n",
        "                pred = model(batch)\n",
        "                y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "                \n",
        "                # Store sample for debugging\n",
        "                if batch_idx == 0 and sample_input is None:\n",
        "                    sample_input = batch.x[0].cpu().numpy()\n",
        "                    sample_pred = pred[0].cpu().numpy()\n",
        "                    sample_target = y[0].cpu().numpy()\n",
        "                \n",
        "                # Skip invalid predictions\n",
        "                if torch.isnan(pred).any():\n",
        "                    print(f\"WARNING: NaN detected in predictions during validation\")\n",
        "                    continue\n",
        "                    \n",
        "                batch_loss = criterion(pred, y).item()\n",
        "                val_loss += batch_loss\n",
        "                \n",
        "                # Unnormalize for real-world metrics\n",
        "                # batch.scale turns scale from 7.0 or (1,) shape i.e. scalar to (B,) shape\n",
        "                # batch.origin turns origin from (1,2) shape to (B,2)\n",
        "                \n",
        "                # then .view(-1, 1, 1) turns scale from (B,) to (B, 1, 1)\n",
        "                # then .unsqueeze(1) turns origin from (B, 2) to (B, 1, 2)\n",
        "                # because pred and y have shapes (B, 60, 2) so these transformations make them compatible for the calculation\n",
        "                \n",
        "                pred_unnorm = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "                y_unnorm = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "                \n",
        "                val_mae += nn.L1Loss()(pred_unnorm, y_unnorm).item()\n",
        "                val_mse += nn.MSELoss()(pred_unnorm, y_unnorm).item()\n",
        "                \n",
        "                num_val_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid validation batches\n",
        "        if num_val_batches == 0:\n",
        "            print(\"WARNING: No valid validation batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        val_loss /= num_val_batches\n",
        "        val_mae /= num_val_batches\n",
        "        val_mse /= num_val_batches\n",
        "        \n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Print with more details\n",
        "        tqdm.tqdm.write(\n",
        "            f\"Epoch {epoch:03d} | LR {optimizer.param_groups[0]['lr']:.6f} | \"\n",
        "            f\"Train MSE {train_loss:.4f} | Val MSE {val_loss:.4f} | \"\n",
        "            f\"Val MAE {val_mae:.4f} | Val MSE {val_mse:.4f}\"\n",
        "        )\n",
        "        \n",
        "        # Debug output - first 3 predictions vs targets\n",
        "        if epoch % 5 == 0:\n",
        "            tqdm.tqdm.write(f\"Sample pred first 3 steps: {sample_pred[:3]}\")\n",
        "            tqdm.tqdm.write(f\"Sample target first 3 steps: {sample_target[:3]}\")\n",
        "            \n",
        "            # Check if model weights are changing\n",
        "            if epoch > 0:\n",
        "                weight_change = False\n",
        "                for name, param in model.named_parameters():\n",
        "                    if param.requires_grad:\n",
        "                        initial_param = initial_state_dict[name]\n",
        "                        if not torch.allclose(param, initial_param, rtol=1e-4):\n",
        "                            weight_change = True\n",
        "                            break\n",
        "                if not weight_change:\n",
        "                    tqdm.tqdm.write(\"WARNING: Model weights barely changing!\")\n",
        "        \n",
        "        # Relaxed improvement criterion - consider any improvement\n",
        "        if val_loss < best_val_loss:\n",
        "            tqdm.tqdm.write(f\"Validation improved: {best_val_loss:.6f} -> {val_loss:.6f}\")\n",
        "            best_val_loss = val_loss\n",
        "            no_improvement = 0\n",
        "            torch.save(model.state_dict(), best_model)\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "            if no_improvement >= early_stopping_patience:\n",
        "                print(f\"Early stopping after {epoch+1} epochs without improvement\")\n",
        "                break\n",
        "    \n",
        "    # Load best model before returning\n",
        "    model.load_state_dict(torch.load(best_model))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage\n",
        "def train_and_evaluate_model():\n",
        "    # Create model\n",
        "    model = AutoRegressiveLSTM(input_dim=5, hidden_dim=512)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Train with improved function\n",
        "    train_improved_model(\n",
        "        model=model,\n",
        "        train_dataloader=train_dataloader,\n",
        "        val_dataloader=val_dataloader,\n",
        "        device=device,\n",
        "        # lr = 0.007 => 8.946\n",
        "        lr=0.007,  # Lower learning rate\n",
        "        patience=20,  # More patience\n",
        "        epochs=100\n",
        "    )\n",
        "    \n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    test_mse = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            \n",
        "            # Unnormalize\n",
        "            pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            y = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            \n",
        "            test_mse += nn.MSELoss()(pred, y).item()\n",
        "    \n",
        "    test_mse /= len(val_dataloader)\n",
        "    print(f\"Val MSE: {test_mse:.4f}\")\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s]/var/folders/w3/lr66s56958q3881y1btpylth0000gn/T/ipykernel_36239/2425023728.py:39: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future = future - origin\n",
            "/var/folders/w3/lr66s56958q3881y1btpylth0000gn/T/ipykernel_36239/2425023728.py:30: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future = future @ R\n",
            "Epoch:   1%|          | 1/100 [00:18<29:56, 18.15s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000 | LR 0.006650 | Train MSE 0.8196 | Val MSE 9.9922 | Val MAE 14.2046 | Val MSE 489.6186\n",
            "Sample pred first 3 steps: [[-0.0718951   0.04398853]\n",
            " [-0.10230919  0.06296059]\n",
            " [-0.15777715  0.07428043]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: inf -> 9.992216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   2%|▏         | 2/100 [00:35<29:17, 17.93s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 | LR 0.006317 | Train MSE 0.0254 | Val MSE 11.4765 | Val MAE 15.7512 | Val MSE 562.3474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   3%|▎         | 3/100 [00:53<29:02, 17.96s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 002 | LR 0.006002 | Train MSE 0.0009 | Val MSE 3.5812 | Val MAE 8.5068 | Val MSE 175.4802\n",
            "Validation improved: 9.992216 -> 3.581230\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   4%|▍         | 4/100 [01:11<28:34, 17.86s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 003 | LR 0.005702 | Train MSE 0.0002 | Val MSE 1.5754 | Val MAE 5.9034 | Val MSE 77.1970\n",
            "Validation improved: 3.581230 -> 1.575449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   5%|▌         | 5/100 [01:28<27:58, 17.66s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 004 | LR 0.005416 | Train MSE 0.0025 | Val MSE 5.9807 | Val MAE 9.7893 | Val MSE 293.0543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   6%|▌         | 6/100 [01:46<27:30, 17.56s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 005 | LR 0.005146 | Train MSE 0.0004 | Val MSE 4.5416 | Val MAE 8.4041 | Val MSE 222.5374\n",
            "Sample pred first 3 steps: [[ 0.01263717 -0.00051657]\n",
            " [-0.00077995  0.02224584]\n",
            " [ 0.0413419   0.04084098]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   7%|▋         | 7/100 [02:03<27:11, 17.54s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 006 | LR 0.004888 | Train MSE 0.0020 | Val MSE 33.1298 | Val MAE 26.2718 | Val MSE 1623.3581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   8%|▊         | 8/100 [02:21<26:57, 17.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 007 | LR 0.004644 | Train MSE 0.0047 | Val MSE 29.8564 | Val MAE 24.2493 | Val MSE 1462.9642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   9%|▉         | 9/100 [02:38<26:37, 17.55s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 008 | LR 0.004412 | Train MSE 0.0030 | Val MSE 1.8298 | Val MAE 5.8148 | Val MSE 89.6612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  10%|█         | 10/100 [02:56<26:12, 17.48s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 009 | LR 0.004191 | Train MSE 0.0001 | Val MSE 1.4930 | Val MAE 4.9411 | Val MSE 73.1549\n",
            "Validation improved: 1.575449 -> 1.492958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  11%|█         | 11/100 [03:13<25:51, 17.44s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 010 | LR 0.003982 | Train MSE 0.0003 | Val MSE 3.7060 | Val MAE 7.9218 | Val MSE 181.5953\n",
            "Sample pred first 3 steps: [[-0.02618653  0.00369637]\n",
            " [-0.02835346  0.01186895]\n",
            " [-0.05971552  0.02991204]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  12%|█▏        | 12/100 [03:48<33:13, 22.66s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 011 | LR 0.003783 | Train MSE 0.0002 | Val MSE 1.3260 | Val MAE 4.4889 | Val MSE 64.9746\n",
            "Validation improved: 1.492958 -> 1.326012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  13%|█▎        | 13/100 [04:05<30:34, 21.09s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 012 | LR 0.003593 | Train MSE 0.0004 | Val MSE 1.3219 | Val MAE 4.5021 | Val MSE 64.7707\n",
            "Validation improved: 1.326012 -> 1.321851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  14%|█▍        | 14/100 [04:23<28:49, 20.11s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 013 | LR 0.003414 | Train MSE 0.0012 | Val MSE 10.2055 | Val MAE 14.6776 | Val MSE 500.0717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  15%|█▌        | 15/100 [04:41<27:25, 19.36s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 014 | LR 0.003243 | Train MSE 0.0013 | Val MSE 4.3220 | Val MAE 8.5685 | Val MSE 211.7757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  16%|█▌        | 16/100 [04:58<26:13, 18.74s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 015 | LR 0.003081 | Train MSE 0.0042 | Val MSE 2.4896 | Val MAE 6.3457 | Val MSE 121.9928\n",
            "Sample pred first 3 steps: [[-0.00362361 -0.0070461 ]\n",
            " [-0.01687053 -0.01908521]\n",
            " [-0.03325962 -0.03368102]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  17%|█▋        | 17/100 [05:15<25:16, 18.28s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 016 | LR 0.002927 | Train MSE 0.0003 | Val MSE 1.7836 | Val MAE 6.0609 | Val MSE 87.3972\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  18%|█▊        | 18/100 [05:34<25:05, 18.36s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 017 | LR 0.002781 | Train MSE 0.0005 | Val MSE 3.6035 | Val MAE 7.0914 | Val MSE 176.5718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  19%|█▉        | 19/100 [05:53<25:02, 18.55s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 018 | LR 0.002641 | Train MSE 0.0056 | Val MSE 2.1645 | Val MAE 6.3068 | Val MSE 106.0617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  20%|██        | 20/100 [06:10<24:21, 18.27s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 019 | LR 0.002509 | Train MSE 0.0003 | Val MSE 0.7336 | Val MAE 3.2188 | Val MSE 35.9478\n",
            "Validation improved: 1.321851 -> 0.733628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  21%|██        | 21/100 [06:28<23:38, 17.95s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 020 | LR 0.002384 | Train MSE 0.0004 | Val MSE 1.8870 | Val MAE 4.9719 | Val MSE 92.4606\n",
            "Sample pred first 3 steps: [[ 0.00091591 -0.0037553 ]\n",
            " [ 0.00167079 -0.00636551]\n",
            " [ 0.00257285 -0.00358195]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  22%|██▏       | 22/100 [06:45<23:03, 17.74s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 021 | LR 0.002265 | Train MSE 0.0003 | Val MSE 1.6589 | Val MAE 5.0271 | Val MSE 81.2876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  23%|██▎       | 23/100 [07:02<22:32, 17.57s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 022 | LR 0.002151 | Train MSE 0.0008 | Val MSE 9.9086 | Val MAE 13.1119 | Val MSE 485.5219\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  24%|██▍       | 24/100 [07:19<22:05, 17.44s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 023 | LR 0.002044 | Train MSE 0.0026 | Val MSE 1.1025 | Val MAE 4.5765 | Val MSE 54.0219\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  25%|██▌       | 25/100 [07:36<21:45, 17.41s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 024 | LR 0.001942 | Train MSE 0.0016 | Val MSE 1.6506 | Val MAE 5.0296 | Val MSE 80.8808\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  26%|██▌       | 26/100 [07:54<21:22, 17.33s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 025 | LR 0.001845 | Train MSE 0.0005 | Val MSE 1.4555 | Val MAE 5.4447 | Val MSE 71.3212\n",
            "Sample pred first 3 steps: [[ 0.01372853  0.00348483]\n",
            " [ 0.02257523 -0.01663537]\n",
            " [ 0.04967353 -0.03191414]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  27%|██▋       | 27/100 [08:11<21:07, 17.36s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 026 | LR 0.001752 | Train MSE 0.0022 | Val MSE 1.6192 | Val MAE 5.5979 | Val MSE 79.3423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  28%|██▊       | 28/100 [08:29<20:57, 17.46s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 027 | LR 0.001665 | Train MSE 0.0014 | Val MSE 7.3625 | Val MAE 12.4970 | Val MSE 360.7647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  29%|██▉       | 29/100 [08:46<20:34, 17.38s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 028 | LR 0.001582 | Train MSE 0.0028 | Val MSE 3.7081 | Val MAE 7.9253 | Val MSE 181.6988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  30%|███       | 30/100 [09:02<19:53, 17.05s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 029 | LR 0.001502 | Train MSE 0.0022 | Val MSE 6.9519 | Val MAE 9.8055 | Val MSE 340.6453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  31%|███       | 31/100 [09:17<18:59, 16.51s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 030 | LR 0.001427 | Train MSE 0.0076 | Val MSE 0.5919 | Val MAE 3.1127 | Val MSE 29.0031\n",
            "Sample pred first 3 steps: [[-0.00283753  0.00549819]\n",
            " [ 0.00270076 -0.0022848 ]\n",
            " [ 0.01027548 -0.00527777]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.733628 -> 0.591900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  32%|███▏      | 32/100 [09:32<18:11, 16.05s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 031 | LR 0.001356 | Train MSE 0.0009 | Val MSE 0.5815 | Val MAE 3.2609 | Val MSE 28.4926\n",
            "Validation improved: 0.591900 -> 0.581482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  33%|███▎      | 33/100 [09:47<17:32, 15.71s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 032 | LR 0.001288 | Train MSE 0.0016 | Val MSE 1.2442 | Val MAE 4.6252 | Val MSE 60.9652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  34%|███▍      | 34/100 [10:02<17:00, 15.47s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 033 | LR 0.001224 | Train MSE 0.0021 | Val MSE 1.4353 | Val MAE 5.3891 | Val MSE 70.3309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  35%|███▌      | 35/100 [10:17<16:33, 15.29s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 034 | LR 0.001163 | Train MSE 0.0016 | Val MSE 0.7808 | Val MAE 3.8472 | Val MSE 38.2582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  36%|███▌      | 36/100 [10:32<16:11, 15.19s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 035 | LR 0.001104 | Train MSE 0.0061 | Val MSE 4.0121 | Val MAE 7.8581 | Val MSE 196.5938\n",
            "Sample pred first 3 steps: [[ 0.00023239  0.00973888]\n",
            " [ 0.0006681   0.00371622]\n",
            " [-0.02088071 -0.01150791]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  37%|███▋      | 37/100 [10:47<15:49, 15.07s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 036 | LR 0.001049 | Train MSE 0.0070 | Val MSE 0.6534 | Val MAE 3.1341 | Val MSE 32.0160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  38%|███▊      | 38/100 [11:02<15:30, 15.01s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 037 | LR 0.000997 | Train MSE 0.0014 | Val MSE 0.4283 | Val MAE 2.4472 | Val MSE 20.9844\n",
            "Validation improved: 0.581482 -> 0.428254\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  39%|███▉      | 39/100 [11:16<15:01, 14.78s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 038 | LR 0.000947 | Train MSE 0.0153 | Val MSE 0.6821 | Val MAE 3.1769 | Val MSE 33.4217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  40%|████      | 40/100 [11:30<14:37, 14.63s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 039 | LR 0.000900 | Train MSE 0.0061 | Val MSE 0.5842 | Val MAE 2.6874 | Val MSE 28.6267\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  41%|████      | 41/100 [11:45<14:17, 14.54s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 040 | LR 0.000855 | Train MSE 0.0137 | Val MSE 1.4626 | Val MAE 5.4582 | Val MSE 71.6689\n",
            "Sample pred first 3 steps: [[-0.00985987 -0.00749688]\n",
            " [-0.00856727 -0.00622812]\n",
            " [-0.01880124 -0.0129041 ]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  42%|████▏     | 42/100 [12:00<14:24, 14.90s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 041 | LR 0.000812 | Train MSE 0.0151 | Val MSE 2.1176 | Val MAE 5.8677 | Val MSE 103.7623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  43%|████▎     | 43/100 [12:15<14:08, 14.88s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 042 | LR 0.000771 | Train MSE 0.0080 | Val MSE 0.4589 | Val MAE 2.6758 | Val MSE 22.4880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  44%|████▍     | 44/100 [12:30<13:50, 14.82s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 043 | LR 0.000733 | Train MSE 0.0424 | Val MSE 0.7513 | Val MAE 3.5784 | Val MSE 36.8117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  45%|████▌     | 45/100 [12:45<13:42, 14.95s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 044 | LR 0.000696 | Train MSE 0.0425 | Val MSE 0.6089 | Val MAE 3.0116 | Val MSE 29.8348\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  46%|████▌     | 46/100 [13:01<13:40, 15.20s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 045 | LR 0.000661 | Train MSE 0.0756 | Val MSE 0.6292 | Val MAE 3.1214 | Val MSE 30.8318\n",
            "Sample pred first 3 steps: [[ 0.00377483 -0.00323125]\n",
            " [ 0.0007752  -0.00132729]\n",
            " [-0.00101924  0.00542174]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  47%|████▋     | 47/100 [13:17<13:37, 15.43s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 046 | LR 0.000628 | Train MSE 0.0445 | Val MSE 0.3720 | Val MAE 2.1637 | Val MSE 18.2259\n",
            "Validation improved: 0.428254 -> 0.371958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  48%|████▊     | 48/100 [13:32<13:17, 15.33s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 047 | LR 0.000597 | Train MSE 0.1173 | Val MSE 0.4635 | Val MAE 2.5562 | Val MSE 22.7093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  49%|████▉     | 49/100 [13:47<12:52, 15.14s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 048 | LR 0.000567 | Train MSE 0.2134 | Val MSE 0.4424 | Val MAE 2.3399 | Val MSE 21.6772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  50%|█████     | 50/100 [14:01<12:29, 14.99s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 049 | LR 0.000539 | Train MSE 0.2993 | Val MSE 0.5228 | Val MAE 2.7196 | Val MSE 25.6151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  51%|█████     | 51/100 [14:16<12:09, 14.88s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 050 | LR 0.000512 | Train MSE 0.5404 | Val MSE 0.4120 | Val MAE 2.5099 | Val MSE 20.1899\n",
            "Sample pred first 3 steps: [[-0.02215626  0.00599189]\n",
            " [-0.01779971  0.00656336]\n",
            " [-0.00252126  0.01050247]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  52%|█████▏    | 52/100 [14:31<11:50, 14.81s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 051 | LR 0.000486 | Train MSE 0.3835 | Val MSE 0.3459 | Val MAE 2.1872 | Val MSE 16.9492\n",
            "Validation improved: 0.371958 -> 0.345903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  53%|█████▎    | 53/100 [14:45<11:37, 14.85s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 052 | LR 0.000462 | Train MSE 0.3379 | Val MSE 0.3223 | Val MAE 2.0423 | Val MSE 15.7907\n",
            "Validation improved: 0.345903 -> 0.322259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  54%|█████▍    | 54/100 [15:01<11:26, 14.93s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 053 | LR 0.000439 | Train MSE 0.3227 | Val MSE 0.3037 | Val MAE 1.9919 | Val MSE 14.8792\n",
            "Validation improved: 0.322259 -> 0.303657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  55%|█████▌    | 55/100 [15:16<11:24, 15.22s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 054 | LR 0.000417 | Train MSE 0.3061 | Val MSE 0.2822 | Val MAE 1.9393 | Val MSE 13.8276\n",
            "Validation improved: 0.303657 -> 0.282196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  56%|█████▌    | 56/100 [15:32<11:07, 15.18s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 055 | LR 0.000396 | Train MSE 0.2890 | Val MSE 0.3172 | Val MAE 2.0312 | Val MSE 15.5444\n",
            "Sample pred first 3 steps: [[-0.01173007  0.00476076]\n",
            " [ 0.00430884 -0.00215281]\n",
            " [ 0.01269537 -0.00165564]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  57%|█████▋    | 57/100 [15:46<10:45, 15.01s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 056 | LR 0.000376 | Train MSE 0.2803 | Val MSE 0.2812 | Val MAE 1.9779 | Val MSE 13.7786\n",
            "Validation improved: 0.282196 -> 0.281195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  58%|█████▊    | 58/100 [16:01<10:30, 15.02s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 057 | LR 0.000357 | Train MSE 0.2719 | Val MSE 0.2606 | Val MAE 1.7764 | Val MSE 12.7705\n",
            "Validation improved: 0.281195 -> 0.260622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  59%|█████▉    | 59/100 [16:17<10:20, 15.15s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 058 | LR 0.000339 | Train MSE 0.2608 | Val MSE 0.2582 | Val MAE 1.8270 | Val MSE 12.6536\n",
            "Validation improved: 0.260622 -> 0.258237\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  60%|██████    | 60/100 [16:31<09:59, 14.98s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 059 | LR 0.000322 | Train MSE 0.2548 | Val MSE 0.2668 | Val MAE 1.9960 | Val MSE 13.0719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  61%|██████    | 61/100 [16:46<09:36, 14.79s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 060 | LR 0.000306 | Train MSE 0.2491 | Val MSE 0.2354 | Val MAE 1.7252 | Val MSE 11.5351\n",
            "Sample pred first 3 steps: [[-0.00612266  0.01162862]\n",
            " [ 0.001677   -0.00156065]\n",
            " [ 0.01679495 -0.01929476]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.258237 -> 0.235411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  62%|██████▏   | 62/100 [17:00<09:17, 14.67s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 061 | LR 0.000291 | Train MSE 0.2477 | Val MSE 0.2398 | Val MAE 1.7099 | Val MSE 11.7496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  63%|██████▎   | 63/100 [17:14<08:58, 14.56s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 062 | LR 0.000276 | Train MSE 0.2450 | Val MSE 0.2734 | Val MAE 1.9545 | Val MSE 13.3981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  64%|██████▍   | 64/100 [17:29<08:44, 14.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 063 | LR 0.000263 | Train MSE 0.2375 | Val MSE 0.2352 | Val MAE 1.7627 | Val MSE 11.5270\n",
            "Validation improved: 0.235411 -> 0.235245\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  65%|██████▌   | 65/100 [17:44<08:38, 14.81s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 064 | LR 0.000250 | Train MSE 0.2347 | Val MSE 0.2233 | Val MAE 1.5652 | Val MSE 10.9415\n",
            "Validation improved: 0.235245 -> 0.223297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  66%|██████▌   | 66/100 [18:49<16:57, 29.94s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 065 | LR 0.000237 | Train MSE 0.2315 | Val MSE 0.2258 | Val MAE 1.6368 | Val MSE 11.0628\n",
            "Sample pred first 3 steps: [[ 0.00061681  0.01047336]\n",
            " [ 0.00407044 -0.00595302]\n",
            " [ 0.02243225 -0.00754274]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  67%|██████▋   | 67/100 [19:41<19:59, 36.35s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 066 | LR 0.000225 | Train MSE 0.2279 | Val MSE 0.2190 | Val MAE 1.6699 | Val MSE 10.7326\n",
            "Validation improved: 0.223297 -> 0.219033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  68%|██████▊   | 68/100 [19:55<15:53, 29.81s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 067 | LR 0.000214 | Train MSE 0.2233 | Val MSE 0.2146 | Val MAE 1.6182 | Val MSE 10.5174\n",
            "Validation improved: 0.219033 -> 0.214641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  69%|██████▉   | 69/100 [20:10<13:02, 25.26s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 068 | LR 0.000203 | Train MSE 0.2176 | Val MSE 0.2084 | Val MAE 1.5743 | Val MSE 10.2103\n",
            "Validation improved: 0.214641 -> 0.208373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  70%|███████   | 70/100 [20:25<11:03, 22.13s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 069 | LR 0.000193 | Train MSE 0.2200 | Val MSE 0.2125 | Val MAE 1.6745 | Val MSE 10.4144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  71%|███████   | 71/100 [20:40<09:38, 19.96s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 070 | LR 0.000183 | Train MSE 0.2194 | Val MSE 0.2189 | Val MAE 1.6402 | Val MSE 10.7245\n",
            "Sample pred first 3 steps: [[-0.00636791  0.00071825]\n",
            " [-0.00825751 -0.00259419]\n",
            " [-0.00857692  0.00709706]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  72%|███████▏  | 72/100 [20:54<08:34, 18.36s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 071 | LR 0.000174 | Train MSE 0.2160 | Val MSE 0.2201 | Val MAE 1.6490 | Val MSE 10.7833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  73%|███████▎  | 73/100 [21:09<07:43, 17.17s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 072 | LR 0.000166 | Train MSE 0.2168 | Val MSE 0.2065 | Val MAE 1.5868 | Val MSE 10.1201\n",
            "Validation improved: 0.208373 -> 0.206533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  74%|███████▍  | 74/100 [21:24<07:08, 16.47s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 073 | LR 0.000157 | Train MSE 0.2110 | Val MSE 0.2013 | Val MAE 1.5561 | Val MSE 9.8658\n",
            "Validation improved: 0.206533 -> 0.201343\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  75%|███████▌  | 75/100 [21:38<06:39, 16.00s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 074 | LR 0.000149 | Train MSE 0.2131 | Val MSE 0.2010 | Val MAE 1.5192 | Val MSE 9.8473\n",
            "Validation improved: 0.201343 -> 0.200966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  76%|███████▌  | 76/100 [21:53<06:12, 15.53s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 075 | LR 0.000142 | Train MSE 0.2074 | Val MSE 0.2017 | Val MAE 1.5327 | Val MSE 9.8839\n",
            "Sample pred first 3 steps: [[-0.0018997   0.01393134]\n",
            " [-0.00041861  0.00045135]\n",
            " [ 0.01829001  0.00165817]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  77%|███████▋  | 77/100 [22:07<05:50, 15.23s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 076 | LR 0.000135 | Train MSE 0.2069 | Val MSE 0.2175 | Val MAE 1.7658 | Val MSE 10.6587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  78%|███████▊  | 78/100 [22:23<05:36, 15.28s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 077 | LR 0.000128 | Train MSE 0.2069 | Val MSE 0.1959 | Val MAE 1.4799 | Val MSE 9.6006\n",
            "Validation improved: 0.200966 -> 0.195932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  79%|███████▉  | 79/100 [22:38<05:17, 15.13s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 078 | LR 0.000122 | Train MSE 0.2055 | Val MSE 0.1974 | Val MAE 1.4990 | Val MSE 9.6722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  80%|████████  | 80/100 [22:53<05:01, 15.07s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 079 | LR 0.000116 | Train MSE 0.2049 | Val MSE 0.2033 | Val MAE 1.5955 | Val MSE 9.9637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  81%|████████  | 81/100 [23:08<04:48, 15.20s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 080 | LR 0.000110 | Train MSE 0.2003 | Val MSE 0.1963 | Val MAE 1.5077 | Val MSE 9.6208\n",
            "Sample pred first 3 steps: [[-0.0022492   0.01810633]\n",
            " [-0.00648953  0.0074232 ]\n",
            " [ 0.00122742  0.00616866]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  82%|████████▏ | 82/100 [23:23<04:33, 15.20s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 081 | LR 0.000104 | Train MSE 0.2010 | Val MSE 0.2041 | Val MAE 1.5248 | Val MSE 10.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  83%|████████▎ | 83/100 [23:38<04:16, 15.08s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 082 | LR 0.000099 | Train MSE 0.1985 | Val MSE 0.2017 | Val MAE 1.5628 | Val MSE 9.8822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  84%|████████▍ | 84/100 [23:54<04:04, 15.25s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 083 | LR 0.000094 | Train MSE 0.1994 | Val MSE 0.1982 | Val MAE 1.5190 | Val MSE 9.7133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  85%|████████▌ | 85/100 [24:09<03:46, 15.13s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 084 | LR 0.000089 | Train MSE 0.1989 | Val MSE 0.1941 | Val MAE 1.4814 | Val MSE 9.5119\n",
            "Validation improved: 0.195932 -> 0.194120\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  86%|████████▌ | 86/100 [24:23<03:30, 15.03s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 085 | LR 0.000085 | Train MSE 0.1965 | Val MSE 0.1925 | Val MAE 1.4479 | Val MSE 9.4311\n",
            "Sample pred first 3 steps: [[-0.00437902  0.01652651]\n",
            " [-0.0090647   0.00839883]\n",
            " [ 0.00016806  0.00413497]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.194120 -> 0.192473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  87%|████████▋ | 87/100 [24:38<03:14, 14.93s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 086 | LR 0.000081 | Train MSE 0.1972 | Val MSE 0.1942 | Val MAE 1.4854 | Val MSE 9.5147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  88%|████████▊ | 88/100 [24:53<02:59, 14.98s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 087 | LR 0.000077 | Train MSE 0.1955 | Val MSE 0.1995 | Val MAE 1.5637 | Val MSE 9.7772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  89%|████████▉ | 89/100 [25:08<02:45, 15.07s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 088 | LR 0.000073 | Train MSE 0.1931 | Val MSE 0.1915 | Val MAE 1.4767 | Val MSE 9.3823\n",
            "Validation improved: 0.192473 -> 0.191477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  90%|█████████ | 90/100 [25:23<02:30, 15.05s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 089 | LR 0.000069 | Train MSE 0.1926 | Val MSE 0.1905 | Val MAE 1.5129 | Val MSE 9.3352\n",
            "Validation improved: 0.191477 -> 0.190515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  91%|█████████ | 91/100 [25:38<02:13, 14.81s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 090 | LR 0.000066 | Train MSE 0.1933 | Val MSE 0.1914 | Val MAE 1.4756 | Val MSE 9.3795\n",
            "Sample pred first 3 steps: [[-0.00474864  0.01023892]\n",
            " [-0.00817875  0.0095375 ]\n",
            " [-0.00634696  0.00672149]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  92%|█████████▏| 92/100 [25:52<01:58, 14.77s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 091 | LR 0.000062 | Train MSE 0.1935 | Val MSE 0.1883 | Val MAE 1.4650 | Val MSE 9.2286\n",
            "Validation improved: 0.190515 -> 0.188339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  93%|█████████▎| 93/100 [26:07<01:43, 14.80s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 092 | LR 0.000059 | Train MSE 0.1933 | Val MSE 0.1893 | Val MAE 1.4752 | Val MSE 9.2754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  94%|█████████▍| 94/100 [26:22<01:28, 14.70s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 093 | LR 0.000056 | Train MSE 0.1914 | Val MSE 0.1868 | Val MAE 1.4622 | Val MSE 9.1534\n",
            "Validation improved: 0.188339 -> 0.186803\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  95%|█████████▌| 95/100 [26:36<01:12, 14.56s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 094 | LR 0.000054 | Train MSE 0.1920 | Val MSE 0.1872 | Val MAE 1.4741 | Val MSE 9.1735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  96%|█████████▌| 96/100 [26:50<00:58, 14.54s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 095 | LR 0.000051 | Train MSE 0.1909 | Val MSE 0.1882 | Val MAE 1.4489 | Val MSE 9.2202\n",
            "Sample pred first 3 steps: [[-0.00238459  0.00447339]\n",
            " [-0.00335112  0.00557549]\n",
            " [-0.00167468  0.00315861]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  97%|█████████▋| 97/100 [27:06<00:44, 14.72s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 096 | LR 0.000048 | Train MSE 0.1875 | Val MSE 0.1887 | Val MAE 1.4523 | Val MSE 9.2487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  98%|█████████▊| 98/100 [27:20<00:29, 14.77s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 097 | LR 0.000046 | Train MSE 0.1892 | Val MSE 0.1834 | Val MAE 1.4261 | Val MSE 8.9850\n",
            "Validation improved: 0.186803 -> 0.183368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  99%|█████████▉| 99/100 [27:35<00:14, 14.77s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 098 | LR 0.000044 | Train MSE 0.1903 | Val MSE 0.1833 | Val MAE 1.4275 | Val MSE 8.9813\n",
            "Validation improved: 0.183368 -> 0.183292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 100/100 [27:50<00:00, 16.71s/epoch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 099 | LR 0.000041 | Train MSE 0.1893 | Val MSE 0.1887 | Val MAE 1.5091 | Val MSE 9.2481\n",
            "Val MSE: 8.9813\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AutoRegressiveLSTM(\n",
              "  (encoder): LSTM(5, 512, batch_first=True)\n",
              "  (decoder): LSTM(2, 512, batch_first=True)\n",
              "  (out): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_and_evaluate_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = TrajectoryDatasetTest(test_data, scale=scale)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
        "                         collate_fn=lambda xs: Batch.from_data_list(xs))\n",
        "\n",
        "best_model2 = torch.load(best_model)\n",
        "model = AutoRegressiveLSTM().to(device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25) # You can try different schedulers\n",
        "# criterion = nn.MSELoss()\n",
        "\n",
        "model.load_state_dict(best_model2)\n",
        "model.eval()\n",
        "\n",
        "pred_list = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        pred_norm = model(batch)\n",
        "        \n",
        "        # Reshape the prediction to (N, 60, 2)\n",
        "        pred = pred_norm * batch.scale.view(-1,1,1) + batch.origin.unsqueeze(1)\n",
        "        pred_list.append(pred.cpu().numpy())\n",
        "pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
        "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
        "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
        "output_df.index.name = 'index'\n",
        "output_df.to_csv('submission_lstm_simple_auto14.csv', index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "data-loading-and-submission-preperation",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 27.524611,
      "end_time": "2025-04-01T17:39:42.223757",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-01T17:39:14.699146",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
