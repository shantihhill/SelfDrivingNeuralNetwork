{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n-C_P-zs-pY"
      },
      "source": [
        "# LSTM - vanilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = \"best_model2.pt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:17.728787Z",
          "iopub.status.busy": "2025-04-01T17:39:17.728324Z",
          "iopub.status.idle": "2025-04-01T17:39:18.875979Z",
          "shell.execute_reply": "2025-04-01T17:39:18.874618Z"
        },
        "id": "F4_wHjhZs-pa",
        "papermill": {
          "duration": 1.154057,
          "end_time": "2025-04-01T17:39:18.878059",
          "exception": false,
          "start_time": "2025-04-01T17:39:17.724002",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/salmawafa/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "/Users/salmawafa/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import Data, Batch\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:18.890746Z",
          "iopub.status.busy": "2025-04-01T17:39:18.890075Z",
          "iopub.status.idle": "2025-04-01T17:39:40.968717Z",
          "shell.execute_reply": "2025-04-01T17:39:40.967158Z"
        },
        "id": "09texa_os-pc",
        "papermill": {
          "duration": 22.084222,
          "end_time": "2025-04-01T17:39:40.970631",
          "exception": false,
          "start_time": "2025-04-01T17:39:18.886409",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data's shape (10000, 50, 110, 6)\n",
            "test_data's shape (2100, 50, 50, 6)\n"
          ]
        }
      ],
      "source": [
        "train_file = np.load('./cse-251-b-2025/train.npz')\n",
        "\n",
        "train_data = train_file['data']\n",
        "print(\"train_data's shape\", train_data.shape)\n",
        "test_file = np.load('./cse-251-b-2025/test_input.npz')\n",
        "\n",
        "test_data = test_file['data']\n",
        "print(\"test_data's shape\", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:40.97884Z",
          "iopub.status.busy": "2025-04-01T17:39:40.978362Z",
          "iopub.status.idle": "2025-04-01T17:39:41.323077Z",
          "shell.execute_reply": "2025-04-01T17:39:41.321787Z"
        },
        "id": "ckJbGP_ds-pc",
        "papermill": {
          "duration": 0.351374,
          "end_time": "2025-04-01T17:39:41.325147",
          "exception": false,
          "start_time": "2025-04-01T17:39:40.973773",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot one\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_matrix = train_data[0]\n",
        "\n",
        "for i in range(data_matrix.shape[0]):\n",
        "    xs = data_matrix[i, :, 0]\n",
        "    ys = data_matrix[i, :, 1]\n",
        "    # trim all zeros\n",
        "    xs = xs[xs != 0]\n",
        "    ys = ys[ys != 0]\n",
        "    # plot each line going from transparent to full\n",
        "    plt.plot(xs, ys)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrajectoryDatasetTrain(Dataset):\n",
        "    def __init__(self, data, scale=10.0, augment=True):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Training data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        augment: Whether to apply data augmentation (only for training)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        scene = self.data[idx]\n",
        "        # Getting 50 historical timestamps and 60 future timestamps\n",
        "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
        "        future = torch.tensor(scene[0, 50:, :2].copy(), dtype=torch.float32)  # (60, 2)\n",
        "        \n",
        "        # Data augmentation(only for training)\n",
        "        if self.augment:\n",
        "            if np.random.rand() < 0.5:\n",
        "                theta = np.random.uniform(-np.pi, np.pi)\n",
        "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
        "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
        "                # Rotate the historical trajectory and future trajectory\n",
        "                hist[..., :2] = hist[..., :2] @ R\n",
        "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
        "                future = future @ R\n",
        "            if np.random.rand() < 0.5:\n",
        "                hist[..., 0] *= -1\n",
        "                hist[..., 2] *= -1\n",
        "                future[:, 0] *= -1\n",
        "\n",
        "        # Use the last timeframe of the historical trajectory as the origin\n",
        "        origin = hist[0, 49, :2].copy()  # (2,)\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        future = future - origin\n",
        "\n",
        "        # Normalize the historical trajectory and future trajectory\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "        future = future / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            y=future.type(torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
        "        )\n",
        "\n",
        "        return data_item\n",
        "    \n",
        "\n",
        "class TrajectoryDatasetTest(Dataset):\n",
        "    def __init__(self, data, scale=10.0):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Testing data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Testing data only contains historical trajectory\n",
        "        scene = self.data[idx]  # (50, 50, 6)\n",
        "        hist = scene.copy()\n",
        "        \n",
        "        origin = hist[0, 49, :2].copy()\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
        "        )\n",
        "        return data_item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple Silicon GPU\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(251)\n",
        "np.random.seed(42)\n",
        "\n",
        "scale = 7.0\n",
        "\n",
        "N = len(train_data)\n",
        "val_size = int(0.1 * N)\n",
        "train_size = N - val_size\n",
        "\n",
        "train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
        "val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "\n",
        "# Set device for training speedup\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"Using Apple Silicon GPU\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of basic model that should work\n",
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, input_dim=4, hidden_dim=512, output_dim=60*2):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        \n",
        "        # Add multi-layer prediction head for better results\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.dropout = nn.Dropout(0.1)  # Add dropout for regularization\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "        # Initialize weights properly\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        x = data.x[..., :4]\n",
        "        x = x.reshape(-1, 50, 50, 4)  # (batch_size, num_agents, seq_len, input_dim)\n",
        "        x = x[:, 0, :, :]  # Only consider ego agent (index 0)\n",
        "        \n",
        "        # Process through LSTM\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        \n",
        "        # Extract final hidden state\n",
        "        features = lstm_out[:, -1, :]\n",
        "        \n",
        "        # Process through prediction head\n",
        "        features = self.relu(self.fc1(features))\n",
        "        features = self.dropout(features)\n",
        "        out = self.fc2(features)\n",
        "        \n",
        "        # Reshape to (batch_size, 60, 2)\n",
        "        return out.view(-1, 60, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_improved_model(model, train_dataloader, val_dataloader, \n",
        "                         device, criterion=nn.MSELoss(), \n",
        "                         lr=0.001, epochs=100, patience=15):\n",
        "    \"\"\"\n",
        "    Improved training function with better debugging and early stopping\n",
        "    \"\"\"\n",
        "    # Initialize optimizer with smaller learning rate\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    # Exponential decay scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "    \n",
        "    early_stopping_patience = patience\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement = 0\n",
        "    \n",
        "    # Save initial state for comparison\n",
        "    initial_state_dict = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "    \n",
        "    for epoch in tqdm.tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
        "        # ---- Training ----\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        num_train_batches = 0\n",
        "        \n",
        "        for batch in train_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            \n",
        "            # Check for NaN predictions\n",
        "            if torch.isnan(pred).any():\n",
        "                print(f\"WARNING: NaN detected in predictions during training\")\n",
        "                continue\n",
        "                \n",
        "            loss = criterion(pred, y)\n",
        "            \n",
        "            # Check if loss is valid\n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                print(f\"WARNING: Invalid loss value: {loss.item()}\")\n",
        "                continue\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            \n",
        "            # More conservative gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            \n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            num_train_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid batches\n",
        "        if num_train_batches == 0:\n",
        "            print(\"WARNING: No valid training batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        train_loss /= num_train_batches\n",
        "        \n",
        "        # ---- Validation ----\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_mae = 0\n",
        "        val_mse = 0\n",
        "        num_val_batches = 0\n",
        "        \n",
        "        # Sample predictions for debugging\n",
        "        sample_input = None\n",
        "        sample_pred = None\n",
        "        sample_target = None\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(val_dataloader):\n",
        "                batch = batch.to(device)\n",
        "                pred = model(batch)\n",
        "                y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "                \n",
        "                # Store sample for debugging\n",
        "                if batch_idx == 0 and sample_input is None:\n",
        "                    sample_input = batch.x[0].cpu().numpy()\n",
        "                    sample_pred = pred[0].cpu().numpy()\n",
        "                    sample_target = y[0].cpu().numpy()\n",
        "                \n",
        "                # Skip invalid predictions\n",
        "                if torch.isnan(pred).any():\n",
        "                    print(f\"WARNING: NaN detected in predictions during validation\")\n",
        "                    continue\n",
        "                    \n",
        "                batch_loss = criterion(pred, y).item()\n",
        "                val_loss += batch_loss\n",
        "                \n",
        "                # Unnormalize for real-world metrics\n",
        "                pred_unnorm = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "                y_unnorm = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "                \n",
        "                val_mae += nn.L1Loss()(pred_unnorm, y_unnorm).item()\n",
        "                val_mse += nn.MSELoss()(pred_unnorm, y_unnorm).item()\n",
        "                \n",
        "                num_val_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid validation batches\n",
        "        if num_val_batches == 0:\n",
        "            print(\"WARNING: No valid validation batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        val_loss /= num_val_batches\n",
        "        val_mae /= num_val_batches\n",
        "        val_mse /= num_val_batches\n",
        "        \n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Print with more details\n",
        "        tqdm.tqdm.write(\n",
        "            f\"Epoch {epoch:03d} | LR {optimizer.param_groups[0]['lr']:.6f} | \"\n",
        "            f\"Train MSE {train_loss:.4f} | Val MSE {val_loss:.4f} | \"\n",
        "            f\"Val MAE {val_mae:.4f} | Val MSE {val_mse:.4f}\"\n",
        "        )\n",
        "        \n",
        "        # Debug output - first 3 predictions vs targets\n",
        "        if epoch % 5 == 0:\n",
        "            tqdm.tqdm.write(f\"Sample pred first 3 steps: {sample_pred[:3]}\")\n",
        "            tqdm.tqdm.write(f\"Sample target first 3 steps: {sample_target[:3]}\")\n",
        "            \n",
        "            # Check if model weights are changing\n",
        "            if epoch > 0:\n",
        "                weight_change = False\n",
        "                for name, param in model.named_parameters():\n",
        "                    if param.requires_grad:\n",
        "                        initial_param = initial_state_dict[name]\n",
        "                        if not torch.allclose(param, initial_param, rtol=1e-4):\n",
        "                            weight_change = True\n",
        "                            break\n",
        "                if not weight_change:\n",
        "                    tqdm.tqdm.write(\"WARNING: Model weights barely changing!\")\n",
        "        \n",
        "        # Relaxed improvement criterion - consider any improvement\n",
        "        if val_loss < best_val_loss:\n",
        "            tqdm.tqdm.write(f\"Validation improved: {best_val_loss:.6f} -> {val_loss:.6f}\")\n",
        "            best_val_loss = val_loss\n",
        "            no_improvement = 0\n",
        "            torch.save(model.state_dict(), best_model)\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "            if no_improvement >= early_stopping_patience:\n",
        "                print(f\"Early stopping after {epoch+1} epochs without improvement\")\n",
        "                break\n",
        "    \n",
        "    # Load best model before returning\n",
        "    model.load_state_dict(torch.load(best_model))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage\n",
        "def train_and_evaluate_model():\n",
        "    # Create model\n",
        "    model = SimpleLSTM(input_dim=4, hidden_dim=512)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Train with improved function\n",
        "    train_improved_model(\n",
        "        model=model,\n",
        "        train_dataloader=train_dataloader,\n",
        "        val_dataloader=val_dataloader,\n",
        "        device=device,\n",
        "        # lr = 0.007 => 8.946\n",
        "        lr=0.01,  # Lower learning rate\n",
        "        patience=20,  # More patience\n",
        "        epochs=100\n",
        "    )\n",
        "    \n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    test_mse = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            \n",
        "            # Unnormalize\n",
        "            pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            y = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            \n",
        "            test_mse += nn.MSELoss()(pred, y).item()\n",
        "    \n",
        "    test_mse /= len(val_dataloader)\n",
        "    print(f\"Val MSE: {test_mse:.4f}\")\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s]/var/folders/w3/lr66s56958q3881y1btpylth0000gn/T/ipykernel_28946/3713195397.py:30: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future = future @ R\n",
            "/var/folders/w3/lr66s56958q3881y1btpylth0000gn/T/ipykernel_28946/3713195397.py:39: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future = future - origin\n",
            "Epoch:   1%|          | 1/100 [00:08<14:02,  8.51s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000 | LR 0.009500 | Train MSE 2.0615 | Val MSE 0.4742 | Val MAE 3.0568 | Val MSE 23.2337\n",
            "Sample pred first 3 steps: [[ 0.00575173  0.00966802]\n",
            " [-0.03109622  0.00472478]\n",
            " [-0.02798022  0.03648886]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: inf -> 0.474158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   2%|▏         | 2/100 [00:15<12:11,  7.47s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 | LR 0.009025 | Train MSE 0.4222 | Val MSE 0.3606 | Val MAE 2.4660 | Val MSE 17.6701\n",
            "Validation improved: 0.474158 -> 0.360614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   3%|▎         | 3/100 [00:22<11:33,  7.15s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 002 | LR 0.008574 | Train MSE 0.3643 | Val MSE 0.3611 | Val MAE 2.2729 | Val MSE 17.6943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   4%|▍         | 4/100 [00:28<11:03,  6.91s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 003 | LR 0.008145 | Train MSE 0.3432 | Val MSE 0.2766 | Val MAE 1.9427 | Val MSE 13.5513\n",
            "Validation improved: 0.360614 -> 0.276556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   5%|▌         | 5/100 [00:35<10:54,  6.88s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 004 | LR 0.007738 | Train MSE 0.3252 | Val MSE 0.2785 | Val MAE 2.0553 | Val MSE 13.6460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   6%|▌         | 6/100 [00:42<10:46,  6.88s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 005 | LR 0.007351 | Train MSE 0.3114 | Val MSE 0.2782 | Val MAE 1.9545 | Val MSE 13.6325\n",
            "Sample pred first 3 steps: [[-4.6998402e-04 -2.3793099e-03]\n",
            " [-1.7567333e-03  7.3445961e-05]\n",
            " [ 1.8781982e-04 -7.4702324e-03]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   7%|▋         | 7/100 [00:49<10:41,  6.90s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 006 | LR 0.006983 | Train MSE 0.2885 | Val MSE 0.2748 | Val MAE 2.2229 | Val MSE 13.4638\n",
            "Validation improved: 0.276556 -> 0.274772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   8%|▊         | 8/100 [00:55<10:23,  6.78s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 007 | LR 0.006634 | Train MSE 0.2771 | Val MSE 0.2350 | Val MAE 1.8694 | Val MSE 11.5144\n",
            "Validation improved: 0.274772 -> 0.234988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   9%|▉         | 9/100 [01:02<10:09,  6.70s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 008 | LR 0.006302 | Train MSE 0.2721 | Val MSE 0.2462 | Val MAE 1.9729 | Val MSE 12.0656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  10%|█         | 10/100 [01:08<10:00,  6.67s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 009 | LR 0.005987 | Train MSE 0.2606 | Val MSE 0.2279 | Val MAE 1.8282 | Val MSE 11.1648\n",
            "Validation improved: 0.234988 -> 0.227854\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  11%|█         | 11/100 [01:15<09:57,  6.71s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 010 | LR 0.005688 | Train MSE 0.2608 | Val MSE 0.2254 | Val MAE 1.8214 | Val MSE 11.0426\n",
            "Sample pred first 3 steps: [[0.00172885 0.00148868]\n",
            " [0.00502335 0.00240451]\n",
            " [0.0033188  0.01067907]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.227854 -> 0.225360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  12%|█▏        | 12/100 [01:22<09:58,  6.80s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 011 | LR 0.005404 | Train MSE 0.2472 | Val MSE 0.2049 | Val MAE 1.6844 | Val MSE 10.0378\n",
            "Validation improved: 0.225360 -> 0.204854\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  13%|█▎        | 13/100 [01:29<09:54,  6.83s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 012 | LR 0.005133 | Train MSE 0.2409 | Val MSE 0.2127 | Val MAE 1.7114 | Val MSE 10.4210\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  14%|█▍        | 14/100 [01:36<09:59,  6.97s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 013 | LR 0.004877 | Train MSE 0.2409 | Val MSE 0.2078 | Val MAE 1.6507 | Val MSE 10.1830\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  15%|█▌        | 15/100 [01:43<09:54,  7.00s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 014 | LR 0.004633 | Train MSE 0.2347 | Val MSE 0.2068 | Val MAE 1.7183 | Val MSE 10.1344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  16%|█▌        | 16/100 [01:50<09:45,  6.97s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 015 | LR 0.004401 | Train MSE 0.2330 | Val MSE 0.2142 | Val MAE 1.6927 | Val MSE 10.4961\n",
            "Sample pred first 3 steps: [[-1.8497852e-03  1.1395487e-03]\n",
            " [-1.9617206e-03  4.7805449e-03]\n",
            " [-2.3049302e-05  2.8086067e-03]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  17%|█▋        | 17/100 [01:57<09:29,  6.86s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 016 | LR 0.004181 | Train MSE 0.2339 | Val MSE 0.1868 | Val MAE 1.4733 | Val MSE 9.1543\n",
            "Validation improved: 0.204854 -> 0.186822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  18%|█▊        | 18/100 [02:03<09:14,  6.76s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 017 | LR 0.003972 | Train MSE 0.2310 | Val MSE 0.2004 | Val MAE 1.7023 | Val MSE 9.8214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  19%|█▉        | 19/100 [02:10<09:01,  6.68s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 018 | LR 0.003774 | Train MSE 0.2268 | Val MSE 0.1854 | Val MAE 1.5200 | Val MSE 9.0852\n",
            "Validation improved: 0.186822 -> 0.185413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  20%|██        | 20/100 [02:17<08:52,  6.66s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 019 | LR 0.003585 | Train MSE 0.2204 | Val MSE 0.1914 | Val MAE 1.5732 | Val MSE 9.3762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  21%|██        | 21/100 [02:23<08:44,  6.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 020 | LR 0.003406 | Train MSE 0.2252 | Val MSE 0.1877 | Val MAE 1.5553 | Val MSE 9.1963\n",
            "Sample pred first 3 steps: [[-0.00034093  0.00187799]\n",
            " [ 0.00514104 -0.00057867]\n",
            " [ 0.0040519  -0.00107233]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  22%|██▏       | 22/100 [02:30<08:48,  6.78s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 021 | LR 0.003235 | Train MSE 0.2192 | Val MSE 0.1895 | Val MAE 1.5586 | Val MSE 9.2869\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  23%|██▎       | 23/100 [02:37<08:51,  6.90s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 022 | LR 0.003074 | Train MSE 0.2192 | Val MSE 0.1887 | Val MAE 1.5128 | Val MSE 9.2447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  24%|██▍       | 24/100 [02:44<08:45,  6.92s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 023 | LR 0.002920 | Train MSE 0.2193 | Val MSE 0.1934 | Val MAE 1.5407 | Val MSE 9.4768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  25%|██▌       | 25/100 [02:52<08:43,  6.98s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 024 | LR 0.002774 | Train MSE 0.2155 | Val MSE 0.2006 | Val MAE 1.6443 | Val MSE 9.8298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  26%|██▌       | 26/100 [02:58<08:32,  6.93s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 025 | LR 0.002635 | Train MSE 0.2135 | Val MSE 0.1832 | Val MAE 1.4839 | Val MSE 8.9750\n",
            "Sample pred first 3 steps: [[ 0.00173975 -0.00220528]\n",
            " [ 0.00318256 -0.00352367]\n",
            " [ 0.00480814 -0.00368191]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.185413 -> 0.183164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  27%|██▋       | 27/100 [03:05<08:23,  6.89s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 026 | LR 0.002503 | Train MSE 0.2075 | Val MSE 0.1991 | Val MAE 1.5499 | Val MSE 9.7545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  28%|██▊       | 28/100 [03:11<07:48,  6.51s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 027 | LR 0.002378 | Train MSE 0.2154 | Val MSE 0.1806 | Val MAE 1.4375 | Val MSE 8.8511\n",
            "Validation improved: 0.183164 -> 0.180635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  29%|██▉       | 29/100 [03:17<07:29,  6.33s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 028 | LR 0.002259 | Train MSE 0.2079 | Val MSE 0.1765 | Val MAE 1.4476 | Val MSE 8.6490\n",
            "Validation improved: 0.180635 -> 0.176511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  30%|███       | 30/100 [03:23<07:15,  6.23s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 029 | LR 0.002146 | Train MSE 0.2088 | Val MSE 0.1795 | Val MAE 1.4077 | Val MSE 8.7940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  31%|███       | 31/100 [03:29<07:02,  6.12s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 030 | LR 0.002039 | Train MSE 0.2064 | Val MSE 0.1895 | Val MAE 1.5203 | Val MSE 9.2851\n",
            "Sample pred first 3 steps: [[-0.00088989 -0.0005555 ]\n",
            " [-0.00298937 -0.00413689]\n",
            " [-0.00515097 -0.00594141]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  32%|███▏      | 32/100 [03:34<06:44,  5.94s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 031 | LR 0.001937 | Train MSE 0.2092 | Val MSE 0.1832 | Val MAE 1.5101 | Val MSE 8.9758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  33%|███▎      | 33/100 [03:40<06:31,  5.84s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 032 | LR 0.001840 | Train MSE 0.2057 | Val MSE 0.1843 | Val MAE 1.4695 | Val MSE 9.0294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  34%|███▍      | 34/100 [03:45<06:18,  5.74s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 033 | LR 0.001748 | Train MSE 0.2039 | Val MSE 0.1777 | Val MAE 1.4514 | Val MSE 8.7077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  35%|███▌      | 35/100 [03:51<06:06,  5.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 034 | LR 0.001661 | Train MSE 0.2019 | Val MSE 0.1726 | Val MAE 1.3961 | Val MSE 8.4592\n",
            "Validation improved: 0.176511 -> 0.172638\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  36%|███▌      | 36/100 [03:56<05:57,  5.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 035 | LR 0.001578 | Train MSE 0.2009 | Val MSE 0.1740 | Val MAE 1.4505 | Val MSE 8.5247\n",
            "Sample pred first 3 steps: [[-0.00018525 -0.00116561]\n",
            " [ 0.00170998 -0.00058822]\n",
            " [ 0.00348494  0.00148263]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  37%|███▋      | 37/100 [04:01<05:46,  5.50s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 036 | LR 0.001499 | Train MSE 0.1978 | Val MSE 0.1790 | Val MAE 1.5500 | Val MSE 8.7710\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  38%|███▊      | 38/100 [04:07<05:38,  5.46s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 037 | LR 0.001424 | Train MSE 0.2002 | Val MSE 0.1783 | Val MAE 1.4721 | Val MSE 8.7374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  39%|███▉      | 39/100 [04:12<05:26,  5.36s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 038 | LR 0.001353 | Train MSE 0.1986 | Val MSE 0.1735 | Val MAE 1.4228 | Val MSE 8.5018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  40%|████      | 40/100 [04:17<05:22,  5.38s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 039 | LR 0.001285 | Train MSE 0.1979 | Val MSE 0.1720 | Val MAE 1.4175 | Val MSE 8.4299\n",
            "Validation improved: 0.172638 -> 0.172039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  41%|████      | 41/100 [04:23<05:31,  5.61s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 040 | LR 0.001221 | Train MSE 0.1975 | Val MSE 0.1725 | Val MAE 1.3865 | Val MSE 8.4534\n",
            "Sample pred first 3 steps: [[0.00036736 0.00178782]\n",
            " [0.00022644 0.00292497]\n",
            " [0.00138285 0.00324379]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  42%|████▏     | 42/100 [04:29<05:29,  5.68s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 041 | LR 0.001160 | Train MSE 0.1948 | Val MSE 0.1761 | Val MAE 1.4378 | Val MSE 8.6269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  43%|████▎     | 43/100 [04:36<05:44,  6.04s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 042 | LR 0.001102 | Train MSE 0.1958 | Val MSE 0.1709 | Val MAE 1.4096 | Val MSE 8.3722\n",
            "Validation improved: 0.172039 -> 0.170861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  44%|████▍     | 44/100 [04:43<05:49,  6.23s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 043 | LR 0.001047 | Train MSE 0.1957 | Val MSE 0.1702 | Val MAE 1.3657 | Val MSE 8.3381\n",
            "Validation improved: 0.170861 -> 0.170165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  45%|████▌     | 45/100 [04:50<05:56,  6.48s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 044 | LR 0.000994 | Train MSE 0.1927 | Val MSE 0.1715 | Val MAE 1.3981 | Val MSE 8.4030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  46%|████▌     | 46/100 [04:57<05:54,  6.57s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 045 | LR 0.000945 | Train MSE 0.1935 | Val MSE 0.1704 | Val MAE 1.4033 | Val MSE 8.3519\n",
            "Sample pred first 3 steps: [[ 0.00148346 -0.00098821]\n",
            " [ 0.00257357 -0.0005536 ]\n",
            " [ 0.00354352 -0.00094767]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  47%|████▋     | 47/100 [05:03<05:51,  6.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 046 | LR 0.000897 | Train MSE 0.1913 | Val MSE 0.1705 | Val MAE 1.3843 | Val MSE 8.3548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  48%|████▊     | 48/100 [05:10<05:43,  6.61s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 047 | LR 0.000853 | Train MSE 0.1930 | Val MSE 0.1740 | Val MAE 1.4164 | Val MSE 8.5273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  49%|████▉     | 49/100 [05:16<05:34,  6.56s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 048 | LR 0.000810 | Train MSE 0.1932 | Val MSE 0.1710 | Val MAE 1.3784 | Val MSE 8.3787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  50%|█████     | 50/100 [05:23<05:25,  6.51s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 049 | LR 0.000769 | Train MSE 0.1894 | Val MSE 0.1695 | Val MAE 1.3503 | Val MSE 8.3041\n",
            "Validation improved: 0.170165 -> 0.169472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  51%|█████     | 51/100 [05:30<05:24,  6.61s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 050 | LR 0.000731 | Train MSE 0.1905 | Val MSE 0.1678 | Val MAE 1.3478 | Val MSE 8.2205\n",
            "Sample pred first 3 steps: [[ 0.0010706   0.00044944]\n",
            " [ 0.00307206  0.00068695]\n",
            " [ 0.00374786 -0.00015742]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.169472 -> 0.167765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  52%|█████▏    | 52/100 [05:37<05:22,  6.72s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 051 | LR 0.000694 | Train MSE 0.1893 | Val MSE 0.1661 | Val MAE 1.3364 | Val MSE 8.1405\n",
            "Validation improved: 0.167765 -> 0.166133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  53%|█████▎    | 53/100 [05:44<05:18,  6.78s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 052 | LR 0.000660 | Train MSE 0.1902 | Val MSE 0.1671 | Val MAE 1.3267 | Val MSE 8.1882\n"
          ]
        }
      ],
      "source": [
        "train_and_evaluate_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = TrajectoryDatasetTest(test_data, scale=scale)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
        "                         collate_fn=lambda xs: Batch.from_data_list(xs))\n",
        "\n",
        "best_model2 = torch.load(best_model)\n",
        "model = SimpleLSTM().to(device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25) # You can try different schedulers\n",
        "# criterion = nn.MSELoss()\n",
        "\n",
        "model.load_state_dict(best_model2)\n",
        "model.eval()\n",
        "\n",
        "pred_list = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        pred_norm = model(batch)\n",
        "        \n",
        "        # Reshape the prediction to (N, 60, 2)\n",
        "        pred = pred_norm * batch.scale.view(-1,1,1) + batch.origin.unsqueeze(1)\n",
        "        pred_list.append(pred.cpu().numpy())\n",
        "pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
        "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
        "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
        "output_df.index.name = 'index'\n",
        "output_df.to_csv('submission_lstm_simple_auto7.csv', index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "data-loading-and-submission-preperation",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 27.524611,
      "end_time": "2025-04-01T17:39:42.223757",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-01T17:39:14.699146",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
