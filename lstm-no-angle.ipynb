{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n-C_P-zs-pY"
      },
      "source": [
        "# LSTM - vanilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = \"best_model2.pt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:17.728787Z",
          "iopub.status.busy": "2025-04-01T17:39:17.728324Z",
          "iopub.status.idle": "2025-04-01T17:39:18.875979Z",
          "shell.execute_reply": "2025-04-01T17:39:18.874618Z"
        },
        "id": "F4_wHjhZs-pa",
        "papermill": {
          "duration": 1.154057,
          "end_time": "2025-04-01T17:39:18.878059",
          "exception": false,
          "start_time": "2025-04-01T17:39:17.724002",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/salmawafa/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "/Users/salmawafa/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import Data, Batch\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:18.890746Z",
          "iopub.status.busy": "2025-04-01T17:39:18.890075Z",
          "iopub.status.idle": "2025-04-01T17:39:40.968717Z",
          "shell.execute_reply": "2025-04-01T17:39:40.967158Z"
        },
        "id": "09texa_os-pc",
        "papermill": {
          "duration": 22.084222,
          "end_time": "2025-04-01T17:39:40.970631",
          "exception": false,
          "start_time": "2025-04-01T17:39:18.886409",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data's shape (10000, 50, 110, 6)\n",
            "test_data's shape (2100, 50, 50, 6)\n"
          ]
        }
      ],
      "source": [
        "train_file = np.load('./cse-251-b-2025/train.npz')\n",
        "\n",
        "train_data = train_file['data']\n",
        "print(\"train_data's shape\", train_data.shape)\n",
        "test_file = np.load('./cse-251-b-2025/test_input.npz')\n",
        "\n",
        "test_data = test_file['data']\n",
        "print(\"test_data's shape\", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:40.97884Z",
          "iopub.status.busy": "2025-04-01T17:39:40.978362Z",
          "iopub.status.idle": "2025-04-01T17:39:41.323077Z",
          "shell.execute_reply": "2025-04-01T17:39:41.321787Z"
        },
        "id": "ckJbGP_ds-pc",
        "papermill": {
          "duration": 0.351374,
          "end_time": "2025-04-01T17:39:41.325147",
          "exception": false,
          "start_time": "2025-04-01T17:39:40.973773",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot one\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_matrix = train_data[0]\n",
        "\n",
        "for i in range(data_matrix.shape[0]):\n",
        "    xs = data_matrix[i, :, 0]\n",
        "    ys = data_matrix[i, :, 1]\n",
        "    # trim all zeros\n",
        "    xs = xs[xs != 0]\n",
        "    ys = ys[ys != 0]\n",
        "    # plot each line going from transparent to full\n",
        "    plt.plot(xs, ys)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrajectoryDatasetTrain(Dataset):\n",
        "    def __init__(self, data, scale=10.0, augment=True):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Training data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        augment: Whether to apply data augmentation (only for training)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        scene = self.data[idx]\n",
        "        # Getting 50 historical timestamps and 60 future timestamps\n",
        "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
        "        future = torch.tensor(scene[0, 50:, :2].copy(), dtype=torch.float32)  # (60, 2)\n",
        "        \n",
        "        # Data augmentation(only for training)\n",
        "        if self.augment:\n",
        "            if np.random.rand() < 0.5:\n",
        "                theta = np.random.uniform(-np.pi, np.pi)\n",
        "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
        "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
        "                # Rotate the historical trajectory and future trajectory\n",
        "                hist[..., :2] = hist[..., :2] @ R\n",
        "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
        "                future = future @ R\n",
        "            if np.random.rand() < 0.5:\n",
        "                hist[..., 0] *= -1\n",
        "                hist[..., 2] *= -1\n",
        "                future[:, 0] *= -1\n",
        "\n",
        "        # Use the last timeframe of the historical trajectory as the origin\n",
        "        origin = hist[0, 49, :2].copy()  # (2,)\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        future = future - origin\n",
        "\n",
        "        # Normalize the historical trajectory and future trajectory\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "        future = future / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            y=future.type(torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
        "        )\n",
        "\n",
        "        return data_item\n",
        "    \n",
        "\n",
        "class TrajectoryDatasetTest(Dataset):\n",
        "    def __init__(self, data, scale=10.0):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Testing data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Testing data only contains historical trajectory\n",
        "        scene = self.data[idx]  # (50, 50, 6)\n",
        "        hist = scene.copy()\n",
        "        \n",
        "        origin = hist[0, 49, :2].copy()\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
        "        )\n",
        "        return data_item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple Silicon GPU\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(251)\n",
        "np.random.seed(42)\n",
        "\n",
        "scale = 7.0\n",
        "\n",
        "N = len(train_data)\n",
        "val_size = int(0.1 * N)\n",
        "train_size = N - val_size\n",
        "\n",
        "train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
        "val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "\n",
        "# Set device for training speedup\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"Using Apple Silicon GPU\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of basic model that should work\n",
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self, input_dim=4, hidden_dim=512, output_dim=60*2):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        \n",
        "        # Add multi-layer prediction head for better results\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.dropout = nn.Dropout(0.1)  # Add dropout for regularization\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "        # Initialize weights properly\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.xavier_normal_(param)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.constant_(param, 0.0)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        x = data.x[..., :4]\n",
        "        x = x.reshape(-1, 50, 50, 4)  # (batch_size, num_agents, seq_len, input_dim)\n",
        "        x = x[:, 0, :, :]  # Only consider ego agent (index 0)\n",
        "        \n",
        "        # Process through LSTM\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        \n",
        "        # Extract final hidden state\n",
        "        features = lstm_out[:, -1, :]\n",
        "        \n",
        "        # Process through prediction head\n",
        "        features = self.relu(self.fc1(features))\n",
        "        features = self.dropout(features)\n",
        "        out = self.fc2(features)\n",
        "        \n",
        "        # Reshape to (batch_size, 60, 2)\n",
        "        return out.view(-1, 60, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_improved_model(model, train_dataloader, val_dataloader, \n",
        "                         device, criterion=nn.MSELoss(), \n",
        "                         lr=0.001, epochs=100, patience=15):\n",
        "    \"\"\"\n",
        "    Improved training function with better debugging and early stopping\n",
        "    \"\"\"\n",
        "    # Initialize optimizer with smaller learning rate\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    # Exponential decay scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "    \n",
        "    early_stopping_patience = patience\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement = 0\n",
        "    \n",
        "    # Save initial state for comparison\n",
        "    initial_state_dict = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "    \n",
        "    for epoch in tqdm.tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
        "        # ---- Training ----\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        num_train_batches = 0\n",
        "        \n",
        "        for batch in train_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            \n",
        "            # Check for NaN predictions\n",
        "            if torch.isnan(pred).any():\n",
        "                print(f\"WARNING: NaN detected in predictions during training\")\n",
        "                continue\n",
        "                \n",
        "            loss = criterion(pred, y)\n",
        "            \n",
        "            # Check if loss is valid\n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                print(f\"WARNING: Invalid loss value: {loss.item()}\")\n",
        "                continue\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            \n",
        "            # More conservative gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            \n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            num_train_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid batches\n",
        "        if num_train_batches == 0:\n",
        "            print(\"WARNING: No valid training batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        train_loss /= num_train_batches\n",
        "        \n",
        "        # ---- Validation ----\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_mae = 0\n",
        "        val_mse = 0\n",
        "        num_val_batches = 0\n",
        "        \n",
        "        # Sample predictions for debugging\n",
        "        sample_input = None\n",
        "        sample_pred = None\n",
        "        sample_target = None\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(val_dataloader):\n",
        "                batch = batch.to(device)\n",
        "                pred = model(batch)\n",
        "                y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "                \n",
        "                # Store sample for debugging\n",
        "                if batch_idx == 0 and sample_input is None:\n",
        "                    sample_input = batch.x[0].cpu().numpy()\n",
        "                    sample_pred = pred[0].cpu().numpy()\n",
        "                    sample_target = y[0].cpu().numpy()\n",
        "                \n",
        "                # Skip invalid predictions\n",
        "                if torch.isnan(pred).any():\n",
        "                    print(f\"WARNING: NaN detected in predictions during validation\")\n",
        "                    continue\n",
        "                    \n",
        "                batch_loss = criterion(pred, y).item()\n",
        "                val_loss += batch_loss\n",
        "                \n",
        "                # Unnormalize for real-world metrics\n",
        "                pred_unnorm = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "                y_unnorm = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "                \n",
        "                val_mae += nn.L1Loss()(pred_unnorm, y_unnorm).item()\n",
        "                val_mse += nn.MSELoss()(pred_unnorm, y_unnorm).item()\n",
        "                \n",
        "                num_val_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid validation batches\n",
        "        if num_val_batches == 0:\n",
        "            print(\"WARNING: No valid validation batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        val_loss /= num_val_batches\n",
        "        val_mae /= num_val_batches\n",
        "        val_mse /= num_val_batches\n",
        "        \n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Print with more details\n",
        "        tqdm.tqdm.write(\n",
        "            f\"Epoch {epoch:03d} | LR {optimizer.param_groups[0]['lr']:.6f} | \"\n",
        "            f\"Train MSE {train_loss:.4f} | Val MSE {val_loss:.4f} | \"\n",
        "            f\"Val MAE {val_mae:.4f} | Val MSE {val_mse:.4f}\"\n",
        "        )\n",
        "        \n",
        "        # Debug output - first 3 predictions vs targets\n",
        "        if epoch % 5 == 0:\n",
        "            tqdm.tqdm.write(f\"Sample pred first 3 steps: {sample_pred[:3]}\")\n",
        "            tqdm.tqdm.write(f\"Sample target first 3 steps: {sample_target[:3]}\")\n",
        "            \n",
        "            # Check if model weights are changing\n",
        "            if epoch > 0:\n",
        "                weight_change = False\n",
        "                for name, param in model.named_parameters():\n",
        "                    if param.requires_grad:\n",
        "                        initial_param = initial_state_dict[name]\n",
        "                        if not torch.allclose(param, initial_param, rtol=1e-4):\n",
        "                            weight_change = True\n",
        "                            break\n",
        "                if not weight_change:\n",
        "                    tqdm.tqdm.write(\"WARNING: Model weights barely changing!\")\n",
        "        \n",
        "        # Relaxed improvement criterion - consider any improvement\n",
        "        if val_loss < best_val_loss:\n",
        "            tqdm.tqdm.write(f\"Validation improved: {best_val_loss:.6f} -> {val_loss:.6f}\")\n",
        "            best_val_loss = val_loss\n",
        "            no_improvement = 0\n",
        "            torch.save(model.state_dict(), best_model)\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "            if no_improvement >= early_stopping_patience:\n",
        "                print(f\"Early stopping after {epoch+1} epochs without improvement\")\n",
        "                break\n",
        "    \n",
        "    # Load best model before returning\n",
        "    model.load_state_dict(torch.load(best_model))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage\n",
        "def train_and_evaluate_model():\n",
        "    # Create model\n",
        "    model = SimpleLSTM(input_dim=4, hidden_dim=512)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Train with improved function\n",
        "    train_improved_model(\n",
        "        model=model,\n",
        "        train_dataloader=train_dataloader,\n",
        "        val_dataloader=val_dataloader,\n",
        "        device=device,\n",
        "        # lr=0.007, => 8.12 final val, public score 9.118\n",
        "        # lr = 0.01 => 7.9 final val, public score: 9.119\n",
        "        # lr = 0.015, # => 8.0 final val, 9.0 public\n",
        "        lr = 0.02, # => 10.5 final val, 11optional4\n",
        "        patience=20,  # More patience\n",
        "        epochs=100\n",
        "    )\n",
        "    \n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    test_mse = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            \n",
        "            # Unnormalize\n",
        "            pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            y = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            \n",
        "            test_mse += nn.MSELoss()(pred, y).item()\n",
        "    \n",
        "    test_mse /= len(val_dataloader)\n",
        "    print(f\"Val MSE: {test_mse:.4f}\")\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   0%|          | 0/100 [00:00<?, ?epoch/s]/var/folders/w3/lr66s56958q3881y1btpylth0000gn/T/ipykernel_28946/3713195397.py:30: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future = future @ R\n",
            "/var/folders/w3/lr66s56958q3881y1btpylth0000gn/T/ipykernel_28946/3713195397.py:39: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future = future - origin\n",
            "Epoch:   1%|          | 1/100 [00:07<12:36,  7.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000 | LR 0.019000 | Train MSE 5.7600 | Val MSE 1.0906 | Val MAE 4.6677 | Val MSE 53.4393\n",
            "Sample pred first 3 steps: [[-0.00544634 -0.01472018]\n",
            " [-0.02466344  0.05264921]\n",
            " [-0.06550986  0.04033234]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: inf -> 1.090598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   2%|▏         | 2/100 [00:15<12:15,  7.50s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 | LR 0.018050 | Train MSE 0.7823 | Val MSE 0.3805 | Val MAE 2.5916 | Val MSE 18.6453\n",
            "Validation improved: 1.090598 -> 0.380516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   3%|▎         | 3/100 [00:22<11:59,  7.42s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 002 | LR 0.017147 | Train MSE 0.7186 | Val MSE 0.4095 | Val MAE 2.5721 | Val MSE 20.0653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   4%|▍         | 4/100 [00:30<12:14,  7.66s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 003 | LR 0.016290 | Train MSE 0.7246 | Val MSE 0.3944 | Val MAE 2.6576 | Val MSE 19.3268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   5%|▌         | 5/100 [00:38<12:15,  7.74s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 004 | LR 0.015476 | Train MSE 0.6798 | Val MSE 0.3489 | Val MAE 2.2848 | Val MSE 17.0945\n",
            "Validation improved: 0.380516 -> 0.348868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   6%|▌         | 6/100 [00:46<12:15,  7.82s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 005 | LR 0.014702 | Train MSE 0.6321 | Val MSE 0.4544 | Val MAE 2.8019 | Val MSE 22.2643\n",
            "Sample pred first 3 steps: [[ 0.0065948  -0.0097685 ]\n",
            " [ 0.01755138 -0.00114881]\n",
            " [ 0.0348797   0.00385307]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   7%|▋         | 7/100 [00:54<12:06,  7.81s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 006 | LR 0.013967 | Train MSE 0.6282 | Val MSE 0.5631 | Val MAE 3.4067 | Val MSE 27.5924\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   8%|▊         | 8/100 [01:01<11:59,  7.82s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 007 | LR 0.013268 | Train MSE 0.6174 | Val MSE 0.4141 | Val MAE 2.6009 | Val MSE 20.2889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   9%|▉         | 9/100 [01:09<11:41,  7.70s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 008 | LR 0.012605 | Train MSE 0.5963 | Val MSE 0.2978 | Val MAE 2.0927 | Val MSE 14.5919\n",
            "Validation improved: 0.348868 -> 0.297794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  10%|█         | 10/100 [01:16<11:28,  7.65s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 009 | LR 0.011975 | Train MSE 0.5965 | Val MSE 0.4445 | Val MAE 2.7287 | Val MSE 21.7782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  11%|█         | 11/100 [01:24<11:16,  7.60s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 010 | LR 0.011376 | Train MSE 0.5745 | Val MSE 0.3770 | Val MAE 2.3975 | Val MSE 18.4713\n",
            "Sample pred first 3 steps: [[-8.0739614e-05  6.9148177e-03]\n",
            " [ 3.9556264e-03 -4.3984898e-03]\n",
            " [ 1.6222571e-03 -9.4753690e-04]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  12%|█▏        | 12/100 [01:31<11:04,  7.55s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 011 | LR 0.010807 | Train MSE 0.5616 | Val MSE 0.3216 | Val MAE 2.2007 | Val MSE 15.7568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  13%|█▎        | 13/100 [01:39<10:57,  7.56s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 012 | LR 0.010267 | Train MSE 0.5614 | Val MSE 0.3471 | Val MAE 2.2562 | Val MSE 17.0089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  14%|█▍        | 14/100 [01:47<10:52,  7.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 013 | LR 0.009753 | Train MSE 0.5740 | Val MSE 0.3834 | Val MAE 2.5364 | Val MSE 18.7873\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  15%|█▌        | 15/100 [01:54<10:50,  7.66s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 014 | LR 0.009266 | Train MSE 0.5754 | Val MSE 0.3135 | Val MAE 2.1257 | Val MSE 15.3633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  16%|█▌        | 16/100 [02:02<10:42,  7.65s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 015 | LR 0.008803 | Train MSE 0.5527 | Val MSE 0.2834 | Val MAE 1.9746 | Val MSE 13.8862\n",
            "Sample pred first 3 steps: [[-0.00073911  0.00176984]\n",
            " [-0.00332992  0.00322542]\n",
            " [ 0.00211967  0.00855912]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.297794 -> 0.283393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  17%|█▋        | 17/100 [02:10<10:46,  7.79s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 016 | LR 0.008362 | Train MSE 0.5596 | Val MSE 0.3023 | Val MAE 2.0794 | Val MSE 14.8106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  18%|█▊        | 18/100 [02:18<10:49,  7.92s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 017 | LR 0.007944 | Train MSE 0.5482 | Val MSE 0.3095 | Val MAE 2.1969 | Val MSE 15.1648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  19%|█▉        | 19/100 [02:26<10:37,  7.87s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 018 | LR 0.007547 | Train MSE 0.5437 | Val MSE 0.3003 | Val MAE 2.1277 | Val MSE 14.7165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  20%|██        | 20/100 [02:34<10:23,  7.79s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 019 | LR 0.007170 | Train MSE 0.5431 | Val MSE 0.2776 | Val MAE 1.9947 | Val MSE 13.6023\n",
            "Validation improved: 0.283393 -> 0.277599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  21%|██        | 21/100 [02:42<10:20,  7.86s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 020 | LR 0.006811 | Train MSE 0.5215 | Val MSE 0.3492 | Val MAE 2.3590 | Val MSE 17.1092\n",
            "Sample pred first 3 steps: [[-0.00265392 -0.00274003]\n",
            " [-0.00228084 -0.00123165]\n",
            " [-0.0039669  -0.01489578]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  22%|██▏       | 22/100 [02:49<10:06,  7.78s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 021 | LR 0.006471 | Train MSE 0.5439 | Val MSE 0.2857 | Val MAE 2.0973 | Val MSE 14.0005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  23%|██▎       | 23/100 [02:57<09:57,  7.76s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 022 | LR 0.006147 | Train MSE 0.5179 | Val MSE 0.3047 | Val MAE 2.1899 | Val MSE 14.9322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  24%|██▍       | 24/100 [03:04<09:40,  7.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 023 | LR 0.005840 | Train MSE 0.5362 | Val MSE 0.2917 | Val MAE 2.1569 | Val MSE 14.2951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  25%|██▌       | 25/100 [03:12<09:33,  7.65s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 024 | LR 0.005548 | Train MSE 0.5325 | Val MSE 0.3004 | Val MAE 2.1366 | Val MSE 14.7213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  26%|██▌       | 26/100 [03:20<09:25,  7.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 025 | LR 0.005270 | Train MSE 0.5277 | Val MSE 0.3156 | Val MAE 2.2563 | Val MSE 15.4632\n",
            "Sample pred first 3 steps: [[-0.00619776  0.00155567]\n",
            " [-0.01648824 -0.000933  ]\n",
            " [-0.02938575 -0.01060029]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  27%|██▋       | 27/100 [03:27<09:19,  7.67s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 026 | LR 0.005007 | Train MSE 0.4987 | Val MSE 0.2828 | Val MAE 1.9389 | Val MSE 13.8575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  28%|██▊       | 28/100 [03:35<09:05,  7.57s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 027 | LR 0.004757 | Train MSE 0.5092 | Val MSE 0.2550 | Val MAE 1.8805 | Val MSE 12.4940\n",
            "Validation improved: 0.277599 -> 0.254979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  29%|██▉       | 29/100 [03:43<09:06,  7.69s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 028 | LR 0.004519 | Train MSE 0.4769 | Val MSE 0.2823 | Val MAE 1.9555 | Val MSE 13.8305\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  30%|███       | 30/100 [03:50<08:55,  7.66s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 029 | LR 0.004293 | Train MSE 0.4936 | Val MSE 0.2936 | Val MAE 2.1301 | Val MSE 14.3860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  31%|███       | 31/100 [03:58<08:52,  7.72s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 030 | LR 0.004078 | Train MSE 0.5015 | Val MSE 0.2701 | Val MAE 1.9531 | Val MSE 13.2361\n",
            "Sample pred first 3 steps: [[ 0.00171031 -0.00096225]\n",
            " [-0.00375198  0.00708183]\n",
            " [ 0.00249969  0.01221419]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  32%|███▏      | 32/100 [04:06<08:41,  7.67s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 031 | LR 0.003874 | Train MSE 0.5085 | Val MSE 0.3103 | Val MAE 2.1975 | Val MSE 15.2065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  33%|███▎      | 33/100 [04:13<08:35,  7.70s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 032 | LR 0.003681 | Train MSE 0.4886 | Val MSE 0.3026 | Val MAE 2.1369 | Val MSE 14.8281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  34%|███▍      | 34/100 [04:21<08:21,  7.61s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 033 | LR 0.003496 | Train MSE 0.4932 | Val MSE 0.2512 | Val MAE 1.7773 | Val MSE 12.3064\n",
            "Validation improved: 0.254979 -> 0.251150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  35%|███▌      | 35/100 [04:30<08:36,  7.95s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 034 | LR 0.003322 | Train MSE 0.4819 | Val MSE 0.2852 | Val MAE 2.0614 | Val MSE 13.9724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  36%|███▌      | 36/100 [04:38<08:29,  7.96s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 035 | LR 0.003156 | Train MSE 0.4891 | Val MSE 0.2570 | Val MAE 1.8336 | Val MSE 12.5921\n",
            "Sample pred first 3 steps: [[-0.00129631  0.00153388]\n",
            " [-0.0013018   0.00100037]\n",
            " [-0.00183062  0.00250034]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  37%|███▋      | 37/100 [04:45<08:18,  7.91s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 036 | LR 0.002998 | Train MSE 0.4996 | Val MSE 0.2701 | Val MAE 1.9391 | Val MSE 13.2366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  38%|███▊      | 38/100 [04:53<08:00,  7.75s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 037 | LR 0.002848 | Train MSE 0.4787 | Val MSE 0.2534 | Val MAE 1.8311 | Val MSE 12.4189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  39%|███▉      | 39/100 [05:00<07:48,  7.67s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 038 | LR 0.002706 | Train MSE 0.4891 | Val MSE 0.2551 | Val MAE 1.9244 | Val MSE 12.5023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  40%|████      | 40/100 [05:09<07:53,  7.89s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 039 | LR 0.002570 | Train MSE 0.4696 | Val MSE 0.2775 | Val MAE 1.9480 | Val MSE 13.5969\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  41%|████      | 41/100 [05:16<07:43,  7.85s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 040 | LR 0.002442 | Train MSE 0.4928 | Val MSE 0.2410 | Val MAE 1.7950 | Val MSE 11.8068\n",
            "Sample pred first 3 steps: [[0.00154729 0.0009993 ]\n",
            " [0.00496507 0.0045645 ]\n",
            " [0.00901077 0.00691923]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.251150 -> 0.240956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  42%|████▏     | 42/100 [05:24<07:25,  7.68s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 041 | LR 0.002320 | Train MSE 0.4613 | Val MSE 0.2535 | Val MAE 1.8787 | Val MSE 12.4226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  43%|████▎     | 43/100 [05:31<07:07,  7.50s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 042 | LR 0.002204 | Train MSE 0.4771 | Val MSE 0.2566 | Val MAE 1.8507 | Val MSE 12.5735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  44%|████▍     | 44/100 [05:38<06:56,  7.44s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 043 | LR 0.002093 | Train MSE 0.4707 | Val MSE 0.2703 | Val MAE 2.0118 | Val MSE 13.2447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  45%|████▌     | 45/100 [05:46<06:52,  7.49s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 044 | LR 0.001989 | Train MSE 0.4684 | Val MSE 0.2426 | Val MAE 1.8000 | Val MSE 11.8856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  46%|████▌     | 46/100 [05:53<06:41,  7.43s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 045 | LR 0.001889 | Train MSE 0.4710 | Val MSE 0.2427 | Val MAE 1.8453 | Val MSE 11.8941\n",
            "Sample pred first 3 steps: [[-0.0065433  -0.00055232]\n",
            " [-0.01005428  0.00143192]\n",
            " [-0.01764311  0.00135956]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  47%|████▋     | 47/100 [06:00<06:23,  7.24s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 046 | LR 0.001795 | Train MSE 0.4756 | Val MSE 0.2560 | Val MAE 1.8681 | Val MSE 12.5432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  48%|████▊     | 48/100 [06:06<06:03,  7.00s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 047 | LR 0.001705 | Train MSE 0.4661 | Val MSE 0.2601 | Val MAE 1.9704 | Val MSE 12.7436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  49%|████▉     | 49/100 [06:14<06:05,  7.18s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 048 | LR 0.001620 | Train MSE 0.4794 | Val MSE 0.2399 | Val MAE 1.7280 | Val MSE 11.7545\n",
            "Validation improved: 0.240956 -> 0.239887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  50%|█████     | 50/100 [06:21<06:01,  7.23s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 049 | LR 0.001539 | Train MSE 0.4580 | Val MSE 0.2331 | Val MAE 1.7268 | Val MSE 11.4219\n",
            "Validation improved: 0.239887 -> 0.233101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  51%|█████     | 51/100 [06:29<06:03,  7.42s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 050 | LR 0.001462 | Train MSE 0.4699 | Val MSE 0.2336 | Val MAE 1.7456 | Val MSE 11.4466\n",
            "Sample pred first 3 steps: [[-0.00387254  0.00291892]\n",
            " [-0.00546072  0.00853286]\n",
            " [-0.00764897  0.01270044]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  52%|█████▏    | 52/100 [06:36<05:54,  7.39s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 051 | LR 0.001389 | Train MSE 0.4616 | Val MSE 0.2565 | Val MAE 1.9330 | Val MSE 12.5704\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  53%|█████▎    | 53/100 [06:44<05:47,  7.39s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 052 | LR 0.001319 | Train MSE 0.4571 | Val MSE 0.2386 | Val MAE 1.7282 | Val MSE 11.6906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  54%|█████▍    | 54/100 [06:51<05:38,  7.36s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 053 | LR 0.001253 | Train MSE 0.4665 | Val MSE 0.2393 | Val MAE 1.7364 | Val MSE 11.7239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  55%|█████▌    | 55/100 [06:58<05:30,  7.35s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 054 | LR 0.001191 | Train MSE 0.4570 | Val MSE 0.2415 | Val MAE 1.7512 | Val MSE 11.8336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  56%|█████▌    | 56/100 [07:06<05:24,  7.37s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 055 | LR 0.001131 | Train MSE 0.4551 | Val MSE 0.2426 | Val MAE 1.7285 | Val MSE 11.8872\n",
            "Sample pred first 3 steps: [[-6.4066210e-04 -6.8815128e-04]\n",
            " [-2.1843691e-04 -1.8249522e-04]\n",
            " [-3.3531268e-04 -6.1357627e-05]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  57%|█████▋    | 57/100 [07:13<05:16,  7.36s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 056 | LR 0.001075 | Train MSE 0.4515 | Val MSE 0.2513 | Val MAE 1.8571 | Val MSE 12.3122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  58%|█████▊    | 58/100 [07:21<05:12,  7.45s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 057 | LR 0.001021 | Train MSE 0.4620 | Val MSE 0.2487 | Val MAE 1.8485 | Val MSE 12.1843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  59%|█████▉    | 59/100 [07:28<05:07,  7.50s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 058 | LR 0.000970 | Train MSE 0.4571 | Val MSE 0.2406 | Val MAE 1.7259 | Val MSE 11.7880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  60%|██████    | 60/100 [07:36<05:03,  7.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 059 | LR 0.000921 | Train MSE 0.4542 | Val MSE 0.2401 | Val MAE 1.7350 | Val MSE 11.7637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  61%|██████    | 61/100 [07:44<04:58,  7.65s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 060 | LR 0.000875 | Train MSE 0.4487 | Val MSE 0.2355 | Val MAE 1.7272 | Val MSE 11.5409\n",
            "Sample pred first 3 steps: [[ 0.0014854  -0.00138476]\n",
            " [ 0.00231706 -0.00151993]\n",
            " [ 0.00282014 -0.00190255]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  62%|██████▏   | 62/100 [07:52<04:50,  7.63s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 061 | LR 0.000832 | Train MSE 0.4513 | Val MSE 0.2340 | Val MAE 1.7741 | Val MSE 11.4654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  63%|██████▎   | 63/100 [07:59<04:38,  7.54s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 062 | LR 0.000790 | Train MSE 0.4433 | Val MSE 0.2339 | Val MAE 1.7015 | Val MSE 11.4608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  64%|██████▍   | 64/100 [08:06<04:28,  7.46s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 063 | LR 0.000750 | Train MSE 0.4546 | Val MSE 0.2354 | Val MAE 1.7087 | Val MSE 11.5327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  65%|██████▌   | 65/100 [08:13<04:17,  7.37s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 064 | LR 0.000713 | Train MSE 0.4511 | Val MSE 0.2338 | Val MAE 1.7416 | Val MSE 11.4557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  66%|██████▌   | 66/100 [08:21<04:10,  7.37s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 065 | LR 0.000677 | Train MSE 0.4564 | Val MSE 0.2292 | Val MAE 1.7099 | Val MSE 11.2300\n",
            "Sample pred first 3 steps: [[ 0.00183663 -0.0001685 ]\n",
            " [ 0.00331689 -0.0002303 ]\n",
            " [ 0.00582176  0.00053442]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n",
            "Validation improved: 0.233101 -> 0.229184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  67%|██████▋   | 67/100 [08:28<04:05,  7.44s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 066 | LR 0.000643 | Train MSE 0.4390 | Val MSE 0.2385 | Val MAE 1.7238 | Val MSE 11.6845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  68%|██████▊   | 68/100 [08:36<04:05,  7.66s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 067 | LR 0.000611 | Train MSE 0.4479 | Val MSE 0.2338 | Val MAE 1.7208 | Val MSE 11.4583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  69%|██████▉   | 69/100 [08:44<04:01,  7.78s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 068 | LR 0.000581 | Train MSE 0.4535 | Val MSE 0.2239 | Val MAE 1.6667 | Val MSE 10.9697\n",
            "Validation improved: 0.229184 -> 0.223872\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  70%|███████   | 70/100 [08:53<03:56,  7.90s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 069 | LR 0.000552 | Train MSE 0.4494 | Val MSE 0.2339 | Val MAE 1.7112 | Val MSE 11.4609\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  71%|███████   | 71/100 [09:01<03:56,  8.15s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 070 | LR 0.000524 | Train MSE 0.4367 | Val MSE 0.2388 | Val MAE 1.7535 | Val MSE 11.6998\n",
            "Sample pred first 3 steps: [[-0.00207373  0.00069894]\n",
            " [-0.00383381  0.00078284]\n",
            " [-0.00553685  0.00090161]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  72%|███████▏  | 72/100 [09:10<03:50,  8.24s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 071 | LR 0.000498 | Train MSE 0.4464 | Val MSE 0.2266 | Val MAE 1.6770 | Val MSE 11.1031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  73%|███████▎  | 73/100 [09:19<03:50,  8.52s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 072 | LR 0.000473 | Train MSE 0.4484 | Val MSE 0.2355 | Val MAE 1.7111 | Val MSE 11.5419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  74%|███████▍  | 74/100 [09:28<03:45,  8.67s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 073 | LR 0.000449 | Train MSE 0.4425 | Val MSE 0.2292 | Val MAE 1.6892 | Val MSE 11.2330\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  75%|███████▌  | 75/100 [09:37<03:40,  8.82s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 074 | LR 0.000427 | Train MSE 0.4502 | Val MSE 0.2282 | Val MAE 1.7202 | Val MSE 11.1812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  76%|███████▌  | 76/100 [09:46<03:34,  8.93s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 075 | LR 0.000406 | Train MSE 0.4412 | Val MSE 0.2242 | Val MAE 1.6834 | Val MSE 10.9836\n",
            "Sample pred first 3 steps: [[-0.00181377  0.00068062]\n",
            " [-0.00266826  0.00112304]\n",
            " [-0.00323879  0.00142116]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  77%|███████▋  | 77/100 [09:55<03:20,  8.73s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 076 | LR 0.000385 | Train MSE 0.4575 | Val MSE 0.2235 | Val MAE 1.6645 | Val MSE 10.9508\n",
            "Validation improved: 0.223872 -> 0.223486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  78%|███████▊  | 78/100 [10:03<03:06,  8.49s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 077 | LR 0.000366 | Train MSE 0.4466 | Val MSE 0.2263 | Val MAE 1.6775 | Val MSE 11.0892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  79%|███████▉  | 79/100 [10:10<02:53,  8.24s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 078 | LR 0.000348 | Train MSE 0.4403 | Val MSE 0.2303 | Val MAE 1.6887 | Val MSE 11.2853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  80%|████████  | 80/100 [10:18<02:42,  8.14s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 079 | LR 0.000330 | Train MSE 0.4585 | Val MSE 0.2250 | Val MAE 1.6667 | Val MSE 11.0236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  81%|████████  | 81/100 [10:26<02:31,  7.96s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 080 | LR 0.000314 | Train MSE 0.4450 | Val MSE 0.2310 | Val MAE 1.6945 | Val MSE 11.3201\n",
            "Sample pred first 3 steps: [[ 3.5490451e-04 -5.7194068e-04]\n",
            " [ 2.6002171e-04 -8.4651093e-04]\n",
            " [ 4.0295366e-05 -7.4806268e-04]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  82%|████████▏ | 82/100 [10:33<02:18,  7.71s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 081 | LR 0.000298 | Train MSE 0.4533 | Val MSE 0.2250 | Val MAE 1.6647 | Val MSE 11.0243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  83%|████████▎ | 83/100 [10:41<02:11,  7.75s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 082 | LR 0.000283 | Train MSE 0.4425 | Val MSE 0.2215 | Val MAE 1.6729 | Val MSE 10.8513\n",
            "Validation improved: 0.223486 -> 0.221454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  84%|████████▍ | 84/100 [10:48<02:04,  7.75s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 083 | LR 0.000269 | Train MSE 0.4396 | Val MSE 0.2172 | Val MAE 1.6305 | Val MSE 10.6411\n",
            "Validation improved: 0.221454 -> 0.217166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  85%|████████▌ | 85/100 [10:56<01:53,  7.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 084 | LR 0.000256 | Train MSE 0.4413 | Val MSE 0.2286 | Val MAE 1.6973 | Val MSE 11.2035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  86%|████████▌ | 86/100 [11:03<01:44,  7.48s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 085 | LR 0.000243 | Train MSE 0.4344 | Val MSE 0.2218 | Val MAE 1.6591 | Val MSE 10.8683\n",
            "Sample pred first 3 steps: [[-0.00079412  0.0011244 ]\n",
            " [-0.00055661  0.00077316]\n",
            " [-0.00044486  0.00073554]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  87%|████████▋ | 87/100 [11:10<01:37,  7.51s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 086 | LR 0.000231 | Train MSE 0.4446 | Val MSE 0.2252 | Val MAE 1.7337 | Val MSE 11.0339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  88%|████████▊ | 88/100 [11:18<01:30,  7.52s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 087 | LR 0.000219 | Train MSE 0.4332 | Val MSE 0.2221 | Val MAE 1.6500 | Val MSE 10.8847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  89%|████████▉ | 89/100 [11:26<01:23,  7.60s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 088 | LR 0.000208 | Train MSE 0.4361 | Val MSE 0.2260 | Val MAE 1.6876 | Val MSE 11.0755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  90%|█████████ | 90/100 [11:33<01:15,  7.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 089 | LR 0.000198 | Train MSE 0.4391 | Val MSE 0.2181 | Val MAE 1.6399 | Val MSE 10.6888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  91%|█████████ | 91/100 [11:41<01:08,  7.57s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 090 | LR 0.000188 | Train MSE 0.4405 | Val MSE 0.2228 | Val MAE 1.6800 | Val MSE 10.9172\n",
            "Sample pred first 3 steps: [[-0.0004157  -0.00086713]\n",
            " [-0.00085212 -0.00158472]\n",
            " [-0.0012627  -0.00203307]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  92%|█████████▏| 92/100 [11:49<01:01,  7.68s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 091 | LR 0.000178 | Train MSE 0.4419 | Val MSE 0.2166 | Val MAE 1.6627 | Val MSE 10.6132\n",
            "Validation improved: 0.217166 -> 0.216596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  93%|█████████▎| 93/100 [11:56<00:53,  7.63s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 092 | LR 0.000170 | Train MSE 0.4296 | Val MSE 0.2207 | Val MAE 1.6625 | Val MSE 10.8147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  94%|█████████▍| 94/100 [12:04<00:45,  7.51s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 093 | LR 0.000161 | Train MSE 0.4307 | Val MSE 0.2159 | Val MAE 1.6342 | Val MSE 10.5781\n",
            "Validation improved: 0.216596 -> 0.215881\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  95%|█████████▌| 95/100 [12:12<00:38,  7.66s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 094 | LR 0.000153 | Train MSE 0.4431 | Val MSE 0.2183 | Val MAE 1.6754 | Val MSE 10.6970\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  96%|█████████▌| 96/100 [12:20<00:31,  7.76s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 095 | LR 0.000145 | Train MSE 0.4414 | Val MSE 0.2171 | Val MAE 1.6492 | Val MSE 10.6364\n",
            "Sample pred first 3 steps: [[-2.4019353e-04 -3.6009442e-05]\n",
            " [-2.9581430e-04 -1.9162151e-04]\n",
            " [-3.5004414e-04 -3.9133022e-04]]\n",
            "Sample target first 3 steps: [[3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]\n",
            " [3.2984033e-06 6.9473140e-06]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  97%|█████████▋| 97/100 [12:27<00:23,  7.74s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 096 | LR 0.000138 | Train MSE 0.4262 | Val MSE 0.2199 | Val MAE 1.6668 | Val MSE 10.7744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  98%|█████████▊| 98/100 [12:35<00:15,  7.63s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 097 | LR 0.000131 | Train MSE 0.4450 | Val MSE 0.2144 | Val MAE 1.6335 | Val MSE 10.5075\n",
            "Validation improved: 0.215881 -> 0.214438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  99%|█████████▉| 99/100 [12:42<00:07,  7.63s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 098 | LR 0.000125 | Train MSE 0.4245 | Val MSE 0.2205 | Val MAE 1.6667 | Val MSE 10.8034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 100/100 [12:50<00:00,  7.70s/epoch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 099 | LR 0.000118 | Train MSE 0.4328 | Val MSE 0.2165 | Val MAE 1.6472 | Val MSE 10.6101\n",
            "Val MSE: 10.5075\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SimpleLSTM(\n",
              "  (lstm): LSTM(4, 512, batch_first=True)\n",
              "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=512, out_features=120, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_and_evaluate_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = TrajectoryDatasetTest(test_data, scale=scale)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
        "                         collate_fn=lambda xs: Batch.from_data_list(xs))\n",
        "\n",
        "best_model2 = torch.load(best_model)\n",
        "model = SimpleLSTM().to(device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25) # You can try different schedulers\n",
        "# criterion = nn.MSELoss()\n",
        "\n",
        "model.load_state_dict(best_model2)\n",
        "model.eval()\n",
        "\n",
        "pred_list = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        pred_norm = model(batch)\n",
        "        \n",
        "        # Reshape the prediction to (N, 60, 2)\n",
        "        pred = pred_norm * batch.scale.view(-1,1,1) + batch.origin.unsqueeze(1)\n",
        "        pred_list.append(pred.cpu().numpy())\n",
        "pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
        "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
        "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
        "output_df.index.name = 'index'\n",
        "output_df.to_csv('submission_lstm_simple_auto11-optional4.csv', index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "data-loading-and-submission-preperation",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 27.524611,
      "end_time": "2025-04-01T17:39:42.223757",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-01T17:39:14.699146",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
