{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-n-C_P-zs-pY"
   },
   "source": [
    "# LSTM - vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape (10000, 50, 110, 6)\n",
      "test_data's shape (2100, 50, 50, 6)\n",
      "Using CUDA GPU\n"
     ]
    }
   ],
   "source": [
    "best_model = \"best_model23.pt\"\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "import tqdm\n",
    "\n",
    "\n",
    "\n",
    "train_file = np.load('data/train.npz')\n",
    "\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape\", train_data.shape)\n",
    "test_file = np.load('data/test_input.npz')\n",
    "\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape\", test_data.shape)\n",
    "\n",
    "\n",
    "class TrajectoryDatasetTrain(Dataset):\n",
    "    def __init__(self, data, scale=10.0, augment=True):\n",
    "        \"\"\"\n",
    "        data: Shape (N, 50, 110, 6) Training data\n",
    "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
    "        augment: Whether to apply data augmentation (only for training)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx]\n",
    "        # Getting 50 historical timestamps and 60 future timestamps\n",
    "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
    "        future = torch.tensor(scene[0, 50:, 2:4].copy(), dtype=torch.float32)  # (60, 2)\n",
    "        \n",
    "        # Data augmentation(only for training)\n",
    "        if self.augment:\n",
    "            if np.random.rand() < 0.5:\n",
    "                theta = np.random.uniform(-np.pi, np.pi)\n",
    "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
    "                # Rotate the historical trajectory and future trajectory\n",
    "                hist[..., :2] = hist[..., :2] @ R\n",
    "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
    "                future = future @ R\n",
    "            if np.random.rand() < 0.5:\n",
    "                hist[..., 0] *= -1\n",
    "                hist[..., 2] *= -1\n",
    "                future[:, 0] *= -1\n",
    "\n",
    "        # Use the last timeframe of the historical trajectory as the origin\n",
    "        origin = hist[0, 49, :2].copy()  # (2,)\n",
    "        hist[..., :2] = hist[..., :2] - origin\n",
    "        # future = future - origin\n",
    "\n",
    "        # Normalize the historical trajectory and future trajectory\n",
    "        hist[..., :4] = hist[..., :4] / self.scale\n",
    "        future = future / self.scale\n",
    "\n",
    "        data_item = Data(\n",
    "            x=torch.tensor(hist, dtype=torch.float32),\n",
    "            y=future.type(torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0), # (1,2)\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32), # scalar e.g. 7.0\n",
    "        )\n",
    "        \n",
    "        # print(f'x: {data_item.x.shape}')\n",
    "        # print(f'y: {data_item.y.shape}')\n",
    "\n",
    "        return data_item\n",
    "    \n",
    "\n",
    "class TrajectoryDatasetTest(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        \"\"\"\n",
    "        data: Shape (N, 50, 110, 6) Testing data\n",
    "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Testing data only contains historical trajectory\n",
    "        scene = self.data[idx]  # (50, 50, 6)\n",
    "        hist = scene.copy()\n",
    "        \n",
    "        origin = hist[0, 49, :2].copy()\n",
    "        hist[..., :2] = hist[..., :2] - origin\n",
    "        hist[..., :4] = hist[..., :4] / self.scale\n",
    "\n",
    "        data_item = Data(\n",
    "            x=torch.tensor(hist, dtype=torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )\n",
    "        return data_item\n",
    "\n",
    "\n",
    "torch.manual_seed(251)\n",
    "np.random.seed(42)\n",
    "\n",
    "scale = 7.0\n",
    "\n",
    "N = len(train_data)\n",
    "val_size = int(0.1 * N)\n",
    "train_size = N - val_size\n",
    "\n",
    "train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
    "val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
    "\n",
    "# Set device for training speedup\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "class AutoRegressiveLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=5, hidden_dim=512, output_dim=2, num_layers=1, window_size=20, future_steps=60):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.window_size = window_size\n",
    "        self.future_steps = future_steps\n",
    "\n",
    "        # Separate encoder for ego and each neighbor agent\n",
    "        self.encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "        self.neighbor_encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.LSTM(input_size=2, hidden_size=hidden_dim * 2, num_layers=num_layers, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def encode_trajectory_window(self, traj_window):\n",
    "        \"\"\"Encode a trajectory window using the appropriate encoder\"\"\"\n",
    "        return self.encoder(traj_window)\n",
    "\n",
    "    def encode_neighbor_window(self, neighbor_window):\n",
    "        \"\"\"Encode a neighbor trajectory window\"\"\"\n",
    "        return self.neighbor_encoder(neighbor_window)\n",
    "\n",
    "    def get_closest_neighbor(self, x, current_step):\n",
    "        \"\"\"Get the closest neighbor at the current step\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Get positions at current step\n",
    "        ego_pos = x[:, 0, current_step, :2].unsqueeze(1)  # (batch, 1, 2)\n",
    "        agent_pos = x[:, :, current_step, :2]  # (batch, 50, 2)\n",
    "        dists = torch.norm(agent_pos - ego_pos, dim=-1)  # (batch, 50)\n",
    "        dists[:, 0] = float('inf')  # mask out ego\n",
    "\n",
    "        # Select closest neighbor\n",
    "        _, neighbor_ids = torch.topk(dists, k=1, dim=1, largest=False)  # (batch, 1)\n",
    "        return neighbor_ids[:, 0]  # (batch,)\n",
    "\n",
    "    def forward(self, data, forcing_ratio=0.5):\n",
    "        x = data.x[..., :5]  # Only pos & vel\n",
    "        x = x.reshape(-1, 50, 50, 5)  # (batch, agents=50, time=50, features=5)\n",
    "        batch_size = x.size(0)\n",
    "        device = x.device\n",
    "\n",
    "        if self.training:\n",
    "            # During training, we have access to ground truth future\n",
    "            future = data.y.view(batch_size, 60, 2)\n",
    "            \n",
    "            # We'll predict from step 40 to step 110 (total 70 steps)\n",
    "            # First 10 steps (40-49) use existing data + some predictions\n",
    "            # Next 60 steps (50-109) are pure predictions\n",
    "            all_outputs = []\n",
    "            \n",
    "            # Initialize with last window_size steps from existing data\n",
    "            current_step = 50 - self.window_size  # Start from step 40\n",
    "            \n",
    "            for pred_step in range(70):  # Predict 70 steps total\n",
    "                # Determine the window end step\n",
    "                window_end = current_step + self.window_size\n",
    "                \n",
    "                if window_end <= 50:\n",
    "                    # Use existing data for the entire window\n",
    "                    ego_window = x[:, 0, current_step:window_end, :]  # (batch, window_size, 5)\n",
    "                    neighbor_id = self.get_closest_neighbor(x, window_end - 1)\n",
    "                    neighbor_window = torch.stack([x[b, neighbor_id[b], current_step:window_end] \n",
    "                                                 for b in range(batch_size)], dim=0)\n",
    "                else:\n",
    "                    # Mix existing data and predictions\n",
    "                    existing_steps = max(0, 50 - current_step)\n",
    "                    pred_steps = self.window_size - existing_steps\n",
    "                    \n",
    "                    if existing_steps > 0:\n",
    "                        # Use existing data for the first part\n",
    "                        ego_existing = x[:, 0, current_step:50, :]  # (batch, existing_steps, 5)\n",
    "                        neighbor_id = self.get_closest_neighbor(x, 49)\n",
    "                        neighbor_existing = torch.stack([x[b, neighbor_id[b], current_step:50] \n",
    "                                                       for b in range(batch_size)], dim=0)\n",
    "                        \n",
    "                        # For predicted part, we need to construct features from predictions\n",
    "                        if pred_steps > 0 and len(all_outputs) >= pred_steps:\n",
    "                            # Get recent predictions and convert to features\n",
    "                            recent_preds = torch.stack(all_outputs[-pred_steps:], dim=1)  # (batch, pred_steps, 2)\n",
    "                            \n",
    "                            # Create velocity from position differences\n",
    "                            if pred_steps > 1:\n",
    "                                pred_vel = recent_preds[:, 1:] - recent_preds[:, :-1]\n",
    "                                pred_vel = torch.cat([pred_vel[:, :1], pred_vel], dim=1)  # Duplicate first vel\n",
    "                            else:\n",
    "                                # Use last known velocity\n",
    "                                last_vel = x[:, 0, 49, 2:4].unsqueeze(1)\n",
    "                                pred_vel = last_vel.repeat(1, pred_steps, 1)\n",
    "                            \n",
    "                            # Combine position and velocity (ignore other features for now)\n",
    "                            ego_pred_features = torch.cat([recent_preds, pred_vel, \n",
    "                                                         torch.zeros(batch_size, pred_steps, 1, device=device)], dim=2)\n",
    "                            \n",
    "                            # Assume neighbor follows similar pattern (simplified)\n",
    "                            neighbor_pred_features = ego_pred_features.clone()\n",
    "                            \n",
    "                            # Concatenate existing and predicted features\n",
    "                            ego_window = torch.cat([ego_existing, ego_pred_features], dim=1)\n",
    "                            neighbor_window = torch.cat([neighbor_existing, neighbor_pred_features], dim=1)\n",
    "                        else:\n",
    "                            # Not enough predictions yet, pad with zeros or repeat last\n",
    "                            pad_size = pred_steps\n",
    "                            ego_pad = ego_existing[:, -1:].repeat(1, pad_size, 1)\n",
    "                            neighbor_pad = neighbor_existing[:, -1:].repeat(1, pad_size, 1)\n",
    "                            ego_window = torch.cat([ego_existing, ego_pad], dim=1)\n",
    "                            neighbor_window = torch.cat([neighbor_existing, neighbor_pad], dim=1)\n",
    "                    else:\n",
    "                        # Pure prediction mode - use only recent predictions\n",
    "                        if len(all_outputs) >= self.window_size:\n",
    "                            recent_preds = torch.stack(all_outputs[-self.window_size:], dim=1)\n",
    "                            \n",
    "                            # Create features from predictions\n",
    "                            if self.window_size > 1:\n",
    "                                pred_vel = recent_preds[:, 1:] - recent_preds[:, :-1]\n",
    "                                pred_vel = torch.cat([pred_vel[:, :1], pred_vel], dim=1)\n",
    "                            else:\n",
    "                                pred_vel = torch.zeros_like(recent_preds)\n",
    "                            \n",
    "                            ego_window = torch.cat([recent_preds, pred_vel, \n",
    "                                                  torch.zeros(batch_size, self.window_size, 1, device=device)], dim=2)\n",
    "                            neighbor_window = ego_window.clone()\n",
    "                        else:\n",
    "                            # Fallback: use last available data\n",
    "                            ego_window = x[:, 0, -self.window_size:, :]\n",
    "                            neighbor_id = self.get_closest_neighbor(x, 49)\n",
    "                            neighbor_window = torch.stack([x[b, neighbor_id[b], -self.window_size:] \n",
    "                                                         for b in range(batch_size)], dim=0)\n",
    "                \n",
    "                # Encode the windows\n",
    "                _, (ego_hidden, ego_cell) = self.encode_trajectory_window(ego_window)\n",
    "                _, (neighbor_hidden, neighbor_cell) = self.encode_neighbor_window(neighbor_window)\n",
    "                \n",
    "                # Concatenate hidden states\n",
    "                hidden = torch.cat([ego_hidden, neighbor_hidden], dim=2)\n",
    "                cell = torch.cat([ego_cell, neighbor_cell], dim=2)\n",
    "                \n",
    "                # Decode one step\n",
    "                if pred_step == 0:\n",
    "                    decoder_input = x[:, 0, 49, :2].unsqueeze(1)  # Last known position\n",
    "                else:\n",
    "                    decoder_input = all_outputs[-1].unsqueeze(1)\n",
    "                \n",
    "                output, (hidden, cell) = self.decoder(decoder_input, (hidden, cell))\n",
    "                pred = self.out(output).squeeze(1)  # (batch, 2)\n",
    "                \n",
    "                # Teacher forcing for first 10 steps during training\n",
    "                if pred_step < 10 and self.training and random.random() < forcing_ratio:\n",
    "                    if pred_step < len(future):\n",
    "                        pred = future[:, pred_step]\n",
    "                \n",
    "                all_outputs.append(pred)\n",
    "                current_step += 1\n",
    "            \n",
    "            # Return only the 60 future steps we care about (steps 10-69 correspond to timesteps 50-109)\n",
    "            outputs = torch.stack(all_outputs[10:], dim=1)  # (batch, 60, 2)\n",
    "            \n",
    "        else:\n",
    "            # Inference mode: predict 60 steps into the future\n",
    "            outputs = []\n",
    "            \n",
    "            # Start with the last window_size steps from input\n",
    "            current_step = 50 - self.window_size\n",
    "            \n",
    "            for pred_step in range(self.future_steps):\n",
    "                # Determine what data to use for the window\n",
    "                if current_step + self.window_size <= 50:\n",
    "                    # Use existing data\n",
    "                    ego_window = x[:, 0, current_step:current_step + self.window_size, :]\n",
    "                    neighbor_id = self.get_closest_neighbor(x, current_step + self.window_size - 1)\n",
    "                    neighbor_window = torch.stack([x[b, neighbor_id[b], current_step:current_step + self.window_size] \n",
    "                                                 for b in range(batch_size)], dim=0)\n",
    "                else:\n",
    "                    # Mix existing data and predictions\n",
    "                    existing_steps = max(0, 50 - current_step)\n",
    "                    pred_steps = self.window_size - existing_steps\n",
    "                    \n",
    "                    if existing_steps > 0:\n",
    "                        ego_existing = x[:, 0, current_step:50, :]\n",
    "                        neighbor_id = self.get_closest_neighbor(x, 49)\n",
    "                        neighbor_existing = torch.stack([x[b, neighbor_id[b], current_step:50] \n",
    "                                                       for b in range(batch_size)], dim=0)\n",
    "                        \n",
    "                        if pred_steps > 0 and len(outputs) >= pred_steps:\n",
    "                            recent_preds = torch.stack(outputs[-pred_steps:], dim=1)\n",
    "                            \n",
    "                            if pred_steps > 1:\n",
    "                                pred_vel = recent_preds[:, 1:] - recent_preds[:, :-1]\n",
    "                                pred_vel = torch.cat([pred_vel[:, :1], pred_vel], dim=1)\n",
    "                            else:\n",
    "                                last_vel = x[:, 0, 49, 2:4].unsqueeze(1)\n",
    "                                pred_vel = last_vel.repeat(1, pred_steps, 1)\n",
    "                            \n",
    "                            ego_pred_features = torch.cat([recent_preds, pred_vel,\n",
    "                                                         torch.zeros(batch_size, pred_steps, 1, device=device)], dim=2)\n",
    "                            neighbor_pred_features = ego_pred_features.clone()\n",
    "                            \n",
    "                            ego_window = torch.cat([ego_existing, ego_pred_features], dim=1)\n",
    "                            neighbor_window = torch.cat([neighbor_existing, neighbor_pred_features], dim=1)\n",
    "                        else:\n",
    "                            pad_size = pred_steps\n",
    "                            ego_pad = ego_existing[:, -1:].repeat(1, pad_size, 1)\n",
    "                            neighbor_pad = neighbor_existing[:, -1:].repeat(1, pad_size, 1)\n",
    "                            ego_window = torch.cat([ego_existing, ego_pad], dim=1)\n",
    "                            neighbor_window = torch.cat([neighbor_existing, neighbor_pad], dim=1)\n",
    "                    else:\n",
    "                        # Pure prediction mode\n",
    "                        if len(outputs) >= self.window_size:\n",
    "                            recent_preds = torch.stack(outputs[-self.window_size:], dim=1)\n",
    "                            \n",
    "                            if self.window_size > 1:\n",
    "                                pred_vel = recent_preds[:, 1:] - recent_preds[:, :-1]\n",
    "                                pred_vel = torch.cat([pred_vel[:, :1], pred_vel], dim=1)\n",
    "                            else:\n",
    "                                pred_vel = torch.zeros_like(recent_preds)\n",
    "                            \n",
    "                            ego_window = torch.cat([recent_preds, pred_vel,\n",
    "                                                  torch.zeros(batch_size, self.window_size, 1, device=device)], dim=2)\n",
    "                            neighbor_window = ego_window.clone()\n",
    "                        else:\n",
    "                            ego_window = x[:, 0, -self.window_size:, :]\n",
    "                            neighbor_id = self.get_closest_neighbor(x, 49)\n",
    "                            neighbor_window = torch.stack([x[b, neighbor_id[b], -self.window_size:] \n",
    "                                                         for b in range(batch_size)], dim=0)\n",
    "                \n",
    "                # Encode\n",
    "                _, (ego_hidden, ego_cell) = self.encode_trajectory_window(ego_window)\n",
    "                _, (neighbor_hidden, neighbor_cell) = self.encode_neighbor_window(neighbor_window)\n",
    "                \n",
    "                hidden = torch.cat([ego_hidden, neighbor_hidden], dim=2)\n",
    "                cell = torch.cat([ego_cell, neighbor_cell], dim=2)\n",
    "                \n",
    "                # Decode\n",
    "                if pred_step == 0:\n",
    "                    decoder_input = x[:, 0, 49, :2].unsqueeze(1)\n",
    "                else:\n",
    "                    decoder_input = outputs[-1].unsqueeze(1)\n",
    "                \n",
    "                output, (hidden, cell) = self.decoder(decoder_input, (hidden, cell))\n",
    "                pred = self.out(output).squeeze(1)\n",
    "                \n",
    "                outputs.append(pred)\n",
    "                current_step += 1\n",
    "            \n",
    "            outputs = torch.stack(outputs, dim=1)  # (batch, 60, 2)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def train_improved_model(model, train_dataloader, val_dataloader, \n",
    "                         device, criterion=nn.MSELoss(), \n",
    "                         lr=0.001, epochs=100, patience=15):\n",
    "    \"\"\"\n",
    "    Improved training function with better debugging and early stopping\n",
    "    \"\"\"\n",
    "    # Initialize optimizer with smaller learning rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Exponential decay scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    \n",
    "    early_stopping_patience = patience\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvement = 0\n",
    "    \n",
    "    # Save initial state for comparison\n",
    "    initial_state_dict = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "    \n",
    "    for epoch in tqdm.tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        # ---- Training ----\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        num_train_batches = 0\n",
    "        forcing_ratio = max(0.0, 1.0 - epoch / 50)\n",
    "        \n",
    "        for batch in train_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch, forcing_ratio=forcing_ratio)\n",
    "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "            \n",
    "            # Check for NaN predictions\n",
    "            if torch.isnan(pred).any():\n",
    "                print(f\"WARNING: NaN detected in predictions during training\")\n",
    "                continue\n",
    "                \n",
    "            loss = criterion(pred, y)\n",
    "            \n",
    "            # Check if loss is valid\n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"WARNING: Invalid loss value: {loss.item()}\")\n",
    "                continue\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # More conservative gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            num_train_batches += 1\n",
    "        \n",
    "        # Skip epoch if no valid batches\n",
    "        if num_train_batches == 0:\n",
    "            print(\"WARNING: No valid training batches in this epoch\")\n",
    "            continue\n",
    "            \n",
    "        train_loss /= num_train_batches\n",
    "        \n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_mae = 0\n",
    "        val_mse = 0\n",
    "        num_val_batches = 0\n",
    "        \n",
    "        # Sample predictions for debugging\n",
    "        sample_input = None\n",
    "        sample_pred = None\n",
    "        sample_target = None\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch in enumerate(val_dataloader):\n",
    "                batch = batch.to(device)\n",
    "                pred = model(batch)\n",
    "                y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "                \n",
    "                # Store sample for debugging\n",
    "                if batch_idx == 0 and sample_input is None:\n",
    "                    sample_input = batch.x[0].cpu().numpy()\n",
    "                    sample_pred = pred[0].cpu().numpy()\n",
    "                    sample_target = y[0].cpu().numpy()\n",
    "                \n",
    "                # Skip invalid predictions\n",
    "                if torch.isnan(pred).any():\n",
    "                    print(f\"WARNING: NaN detected in predictions during validation\")\n",
    "                    continue\n",
    "                    \n",
    "                batch_loss = criterion(pred, y).item()\n",
    "                val_loss += batch_loss\n",
    "                \n",
    "                # Unnormalize for real-world metrics\n",
    "                pred_unnorm = pred * batch.scale.view(-1, 1, 1)\n",
    "                y_unnorm = y * batch.scale.view(-1, 1, 1)\n",
    "                \n",
    "                val_mae += nn.L1Loss()(pred_unnorm, y_unnorm).item()\n",
    "                val_mse += nn.MSELoss()(pred_unnorm, y_unnorm).item()\n",
    "                \n",
    "                num_val_batches += 1\n",
    "        \n",
    "        # Skip epoch if no valid validation batches\n",
    "        if num_val_batches == 0:\n",
    "            print(\"WARNING: No valid validation batches in this epoch\")\n",
    "            continue\n",
    "            \n",
    "        val_loss /= num_val_batches\n",
    "        val_mae /= num_val_batches\n",
    "        val_mse /= num_val_batches\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print with more details\n",
    "        tqdm.tqdm.write(\n",
    "            f\"Epoch {epoch:03d} | LR {optimizer.param_groups[0]['lr']:.6f} | \"\n",
    "            f\"Train MSE {train_loss:.4f} | Val MSE (normalized) {val_loss:.4f} | \"\n",
    "            f\"Val MAE (true) {val_mae:.4f} | Val MSE (true) {val_mse:.4f}\"\n",
    "        )\n",
    "        \n",
    "        # Debug output - first 3 predictions vs targets\n",
    "        if epoch % 5 == 0:\n",
    "            tqdm.tqdm.write(f\"Sample pred first 3 steps: {sample_pred[:3]}\")\n",
    "            tqdm.tqdm.write(f\"Sample target first 3 steps: {sample_target[:3]}\")\n",
    "            \n",
    "            # Check if model weights are changing\n",
    "            if epoch > 0:\n",
    "                weight_change = False\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.requires_grad:\n",
    "                        initial_param = initial_state_dict[name]\n",
    "                        if not torch.allclose(param, initial_param, rtol=1e-4):\n",
    "                            weight_change = True\n",
    "                            break\n",
    "                if not weight_change:\n",
    "                    tqdm.tqdm.write(\"WARNING: Model weights barely changing!\")\n",
    "        \n",
    "        # Relaxed improvement criterion - consider any improvement\n",
    "        if val_loss < best_val_loss:\n",
    "            tqdm.tqdm.write(f\"Validation improved: {best_val_loss:.6f} -> {val_loss:.6f}\")\n",
    "            best_val_loss = val_loss\n",
    "            no_improvement = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')  # Fixed variable name\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            if no_improvement >= early_stopping_patience:\n",
    "                print(f\"Early stopping after {epoch+1} epochs without improvement\")\n",
    "                break\n",
    "    \n",
    "    # Load best model before returning\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    return model\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def train_and_evaluate_model(train_dataloader, val_dataloader, device):\n",
    "    # Create model with sliding window\n",
    "    model = AutoRegressiveLSTM(window_size=10, future_steps=60)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Train with improved function\n",
    "    train_improved_model(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        device=device,\n",
    "        lr=0.005,  # Lower learning rate\n",
    "        patience=20,  # More patience\n",
    "        epochs=150\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    test_mse = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "            \n",
    "            # Unnormalize\n",
    "            pred = pred * batch.scale.view(-1, 1, 1)\n",
    "            y = y * batch.scale.view(-1, 1, 1)\n",
    "            \n",
    "            test_mse += nn.MSELoss()(pred, y).item()\n",
    "    \n",
    "    test_mse /= len(val_dataloader)\n",
    "    print(f\"Val MSE: {test_mse:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1%|          | 1/150 [01:12<2:59:27, 72.26s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | LR 0.004750 | Train MSE 0.4824 | Val MSE (normalized) 0.7825 | Val MAE (true) 4.4064 | Val MSE (true) 38.3420\n",
      "Sample pred first 3 steps: [[-0.19138068  0.14863092]\n",
      " [-0.19138564  0.14862876]\n",
      " [-0.19138607  0.14862972]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n",
      "Validation improved: inf -> 0.782490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1%|▏         | 2/150 [02:23<2:56:51, 71.70s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | LR 0.004513 | Train MSE 0.4165 | Val MSE (normalized) 0.6330 | Val MAE (true) 3.8867 | Val MSE (true) 31.0162\n",
      "Validation improved: 0.782490 -> 0.632983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   2%|▏         | 3/150 [03:34<2:55:15, 71.54s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | LR 0.004287 | Train MSE 0.3612 | Val MSE (normalized) 1.2159 | Val MAE (true) 6.1735 | Val MSE (true) 59.5776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   3%|▎         | 4/150 [04:46<2:54:11, 71.59s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | LR 0.004073 | Train MSE 0.5277 | Val MSE (normalized) 0.6483 | Val MAE (true) 4.1758 | Val MSE (true) 31.7689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   3%|▎         | 5/150 [05:58<2:53:12, 71.67s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | LR 0.003869 | Train MSE 0.4206 | Val MSE (normalized) 0.9633 | Val MAE (true) 5.4157 | Val MSE (true) 47.2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 6/150 [07:10<2:52:15, 71.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | LR 0.003675 | Train MSE 0.2690 | Val MSE (normalized) 1.0011 | Val MAE (true) 5.4034 | Val MSE (true) 49.0552\n",
      "Sample pred first 3 steps: [[0.01332489 0.23051494]\n",
      " [0.01339083 0.23090136]\n",
      " [0.01337924 0.2314953 ]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▍         | 7/150 [08:22<2:51:29, 71.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | LR 0.003492 | Train MSE 0.1723 | Val MSE (normalized) 0.6304 | Val MAE (true) 3.8997 | Val MSE (true) 30.8903\n",
      "Validation improved: 0.632983 -> 0.630414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 8/150 [09:35<2:51:05, 72.29s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | LR 0.003317 | Train MSE 0.1069 | Val MSE (normalized) 0.5166 | Val MAE (true) 3.5111 | Val MSE (true) 25.3138\n",
      "Validation improved: 0.630414 -> 0.516609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   6%|▌         | 9/150 [10:48<2:50:29, 72.55s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | LR 0.003151 | Train MSE 0.1030 | Val MSE (normalized) 0.4496 | Val MAE (true) 3.3337 | Val MSE (true) 22.0297\n",
      "Validation improved: 0.516609 -> 0.449586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 10/150 [12:02<2:49:47, 72.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | LR 0.002994 | Train MSE 0.0925 | Val MSE (normalized) 0.4197 | Val MAE (true) 3.1299 | Val MSE (true) 20.5650\n",
      "Validation improved: 0.449586 -> 0.419695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   7%|▋         | 11/150 [13:15<2:48:53, 72.90s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | LR 0.002844 | Train MSE 0.0902 | Val MSE (normalized) 0.4267 | Val MAE (true) 3.1892 | Val MSE (true) 20.9105\n",
      "Sample pred first 3 steps: [[-0.5314613  -0.06865697]\n",
      " [-0.53145885 -0.068639  ]\n",
      " [-0.5314308  -0.06864282]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 12/150 [14:29<2:48:19, 73.19s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | LR 0.002702 | Train MSE 0.0922 | Val MSE (normalized) 0.4187 | Val MAE (true) 3.1401 | Val MSE (true) 20.5163\n",
      "Validation improved: 0.419695 -> 0.418701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   9%|▊         | 13/150 [15:42<2:47:27, 73.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | LR 0.002567 | Train MSE 0.0924 | Val MSE (normalized) 0.4282 | Val MAE (true) 3.2894 | Val MSE (true) 20.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   9%|▉         | 14/150 [16:56<2:46:40, 73.54s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | LR 0.002438 | Train MSE 0.0904 | Val MSE (normalized) 0.4040 | Val MAE (true) 3.1107 | Val MSE (true) 19.7956\n",
      "Validation improved: 0.418701 -> 0.403993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 15/150 [18:10<2:45:53, 73.73s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | LR 0.002316 | Train MSE 0.0915 | Val MSE (normalized) 0.3725 | Val MAE (true) 2.9856 | Val MSE (true) 18.2536\n",
      "Validation improved: 0.403993 -> 0.372523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  11%|█         | 16/150 [19:25<2:44:53, 73.83s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | LR 0.002201 | Train MSE 0.0837 | Val MSE (normalized) 0.3680 | Val MAE (true) 3.0143 | Val MSE (true) 18.0342\n",
      "Sample pred first 3 steps: [[0.10497974 0.02569452]\n",
      " [0.1047133  0.02604919]\n",
      " [0.10468215 0.02613487]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n",
      "Validation improved: 0.372523 -> 0.368044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  11%|█▏        | 17/150 [20:38<2:43:42, 73.86s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | LR 0.002091 | Train MSE 0.0887 | Val MSE (normalized) 0.3566 | Val MAE (true) 2.9581 | Val MSE (true) 17.4742\n",
      "Validation improved: 0.368044 -> 0.356616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 18/150 [21:52<2:42:34, 73.90s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | LR 0.001986 | Train MSE 0.0865 | Val MSE (normalized) 0.3608 | Val MAE (true) 2.8972 | Val MSE (true) 17.6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 19/150 [23:07<2:41:42, 74.07s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | LR 0.001887 | Train MSE 0.0874 | Val MSE (normalized) 0.3679 | Val MAE (true) 2.9411 | Val MSE (true) 18.0269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  13%|█▎        | 20/150 [24:22<2:41:04, 74.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | LR 0.001792 | Train MSE 0.0895 | Val MSE (normalized) 0.3568 | Val MAE (true) 2.7832 | Val MSE (true) 17.4846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  14%|█▍        | 21/150 [25:37<2:40:18, 74.56s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | LR 0.001703 | Train MSE 0.0882 | Val MSE (normalized) 0.3045 | Val MAE (true) 2.5961 | Val MSE (true) 14.9206\n",
      "Sample pred first 3 steps: [[0.17706004 0.06006136]\n",
      " [0.1769722  0.06004719]\n",
      " [0.17703271 0.06004643]]\n",
      "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
      " [-8.2099714e-06  2.6287930e-06]\n",
      " [ 1.4959690e-05 -1.9491419e-05]]\n",
      "Validation improved: 0.356616 -> 0.304501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▍        | 22/150 [26:52<2:39:24, 74.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021 | LR 0.001618 | Train MSE 0.0838 | Val MSE (normalized) 0.2628 | Val MAE (true) 2.5034 | Val MSE (true) 12.8791\n",
      "Validation improved: 0.304501 -> 0.262839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 23/150 [28:08<2:38:51, 75.05s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 | LR 0.001537 | Train MSE 0.0833 | Val MSE (normalized) 0.2558 | Val MAE (true) 2.5225 | Val MSE (true) 12.5352\n",
      "Validation improved: 0.262839 -> 0.255819\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(train_dataloader, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TrajectoryDatasetTest(test_data, scale=scale)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
    "                         collate_fn=lambda xs: Batch.from_data_list(xs))\n",
    "\n",
    "best_model2 = torch.load(best_model)\n",
    "model = AutoRegressiveLSTM().to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25) # You can try different schedulers\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "model.load_state_dict(best_model2)\n",
    "model.eval()\n",
    "\n",
    "pred_list = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        pred_vel_norm = model(batch)\n",
    "        \n",
    "        pred_vel = pred_vel_norm * batch.scale.view(-1,1,1) # (B, 60, 2)\n",
    "        \n",
    "        # Get origin in meters (position at t=49 for ego)\n",
    "        # origin = batch.origin  # (B, 1, 2)\n",
    "        origin = batch.origin.unsqueeze(1)  # Ensure shape is (B, 1, 2)\n",
    "        \n",
    "        # Integrate velocity to get position over 60 steps\n",
    "        dt = 0.1  # seconds per step\n",
    "        pred_pos = [origin]  # list of (B, 1, 2)\n",
    "        \n",
    "        for t in range(60):\n",
    "            next_pos = pred_pos[-1] + pred_vel[:, t:t+1, :] * dt  # (B, 1, 2)\n",
    "            pred_pos.append(next_pos)\n",
    "        \n",
    "        # Concatenate positions across time steps\n",
    "        pred_xy = torch.cat(pred_pos[1:], dim=1)  # skip initial origin, get (B, 60, 2)\n",
    "\n",
    "        pred_list.append(pred_xy.cpu().numpy())\n",
    "        \n",
    "        # pred_list.append(pred.cpu().numpy())\n",
    "pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
    "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
    "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
    "output_df.index.name = 'index'\n",
    "output_df.to_csv('submission_lstm_simple_auto23.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "data-loading-and-submission-preperation",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.524611,
   "end_time": "2025-04-01T17:39:42.223757",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-01T17:39:14.699146",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
