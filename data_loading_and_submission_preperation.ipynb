{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n-C_P-zs-pY"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:17.728787Z",
          "iopub.status.busy": "2025-04-01T17:39:17.728324Z",
          "iopub.status.idle": "2025-04-01T17:39:18.875979Z",
          "shell.execute_reply": "2025-04-01T17:39:18.874618Z"
        },
        "id": "F4_wHjhZs-pa",
        "papermill": {
          "duration": 1.154057,
          "end_time": "2025-04-01T17:39:18.878059",
          "exception": false,
          "start_time": "2025-04-01T17:39:17.724002",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:18.890746Z",
          "iopub.status.busy": "2025-04-01T17:39:18.890075Z",
          "iopub.status.idle": "2025-04-01T17:39:40.968717Z",
          "shell.execute_reply": "2025-04-01T17:39:40.967158Z"
        },
        "id": "09texa_os-pc",
        "papermill": {
          "duration": 22.084222,
          "end_time": "2025-04-01T17:39:40.970631",
          "exception": false,
          "start_time": "2025-04-01T17:39:18.886409",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m train_file = np.load(\u001b[33m'\u001b[39m\u001b[33m./cse-251-b-2025/train.npz\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m train_data = \u001b[43mtrain_file\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtrain_data\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms shape\u001b[39m\u001b[33m\"\u001b[39m, train_data.shape)\n\u001b[32m      5\u001b[39m test_file = np.load(\u001b[33m'\u001b[39m\u001b[33m./cse-251-b-2025/test_input.npz\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cse251/lib/python3.12/site-packages/numpy/lib/npyio.py:256\u001b[39m, in \u001b[36mNpzFile.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m magic == \u001b[38;5;28mformat\u001b[39m.MAGIC_PREFIX:\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mbytes\u001b[39m = \u001b[38;5;28mself\u001b[39m.zip.open(key)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.zip.read(key)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cse251/lib/python3.12/site-packages/numpy/lib/format.py:831\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    829\u001b[39m             read_count = \u001b[38;5;28mmin\u001b[39m(max_read_count, count - i)\n\u001b[32m    830\u001b[39m             read_size = \u001b[38;5;28mint\u001b[39m(read_count * dtype.itemsize)\n\u001b[32m--> \u001b[39m\u001b[32m831\u001b[39m             data = \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marray data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    832\u001b[39m             array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[32m    833\u001b[39m                                                      count=read_count)\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cse251/lib/python3.12/site-packages/numpy/lib/format.py:966\u001b[39m, in \u001b[36m_read_bytes\u001b[39m\u001b[34m(fp, size, error_template)\u001b[39m\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    962\u001b[39m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[32m    963\u001b[39m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[32m    964\u001b[39m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[32m    965\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m         r = \u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    967\u001b[39m         data += r\n\u001b[32m    968\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) == size:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cse251/lib/python3.12/zipfile/__init__.py:992\u001b[39m, in \u001b[36mZipExtFile.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m    990\u001b[39m \u001b[38;5;28mself\u001b[39m._offset = \u001b[32m0\u001b[39m\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n\u001b[32m--> \u001b[39m\u001b[32m992\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    993\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[32m    994\u001b[39m         \u001b[38;5;28mself\u001b[39m._readbuffer = data\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cse251/lib/python3.12/zipfile/__init__.py:1082\u001b[39m, in \u001b[36mZipExtFile._read1\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1080\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._left <= \u001b[32m0\u001b[39m:\n\u001b[32m   1081\u001b[39m     \u001b[38;5;28mself\u001b[39m._eof = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1082\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_crc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cse251/lib/python3.12/zipfile/__init__.py:1007\u001b[39m, in \u001b[36mZipExtFile._update_crc\u001b[39m\u001b[34m(self, newdata)\u001b[39m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expected_crc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1005\u001b[39m     \u001b[38;5;66;03m# No need to compute the CRC if we don't have a reference value\u001b[39;00m\n\u001b[32m   1006\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m \u001b[38;5;28mself\u001b[39m._running_crc = \u001b[43mcrc32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_running_crc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[38;5;66;03m# Check the CRC if we're at the end of the file\u001b[39;00m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._running_crc != \u001b[38;5;28mself\u001b[39m._expected_crc:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "train_file = np.load('./cse-251-b-2025/train.npz')\n",
        "\n",
        "train_data = train_file['data']\n",
        "print(\"train_data's shape\", train_data.shape)\n",
        "test_file = np.load('./cse-251-b-2025/test_input.npz')\n",
        "\n",
        "test_data = test_file['data']\n",
        "print(\"test_data's shape\", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "338.59322191910144\n",
            "3141.1610733749867\n",
            "277.5519818788174\n",
            "5120.083908238015\n",
            "151.68348216686076\n",
            "1520.9112447782634\n",
            "-1439.4765481150055\n",
            "5484.016233294116\n",
            "2943.118961848223\n",
            "6812.775120286165\n",
            "185.86787279036292\n",
            "2630.287139674461\n",
            "4542.4441756807255\n",
            "2778.157298010482\n",
            "3627.084088281751\n",
            "3186.7664771910886\n",
            "-741.0554175008206\n",
            "6328.087336589542\n",
            "3550.3901494954252\n",
            "68.06889174094954\n",
            "-300.52460006352146\n",
            "2125.2141405718635\n",
            "9517.177395754596\n",
            "2968.537095963221\n",
            "5164.223747137092\n",
            "-1843.0614330799417\n",
            "65.07074334965716\n",
            "-600.6842620243576\n",
            "2727.341672086217\n",
            "257.89922502315545\n",
            "-1779.5356765821361\n",
            "4350.571242314503\n",
            "-71.89738594550053\n",
            "6480.391285998383\n",
            "5565.927991722484\n",
            "5555.654290754947\n",
            "706.9439124393834\n",
            "2827.9448918858707\n",
            "3309.1973443253605\n",
            "2792.3367926294777\n",
            "3886.133915491251\n",
            "4142.802890686185\n",
            "18.45852602295149\n",
            "-607.5022219701269\n",
            "5553.428861734927\n",
            "5725.730263934792\n",
            "2182.0290689771823\n",
            "6413.496097240114\n",
            "5372.206181399366\n",
            "548.208257121106\n"
          ]
        }
      ],
      "source": [
        "for s in range(50):\n",
        "    print(train_data[s][0][0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:40.97884Z",
          "iopub.status.busy": "2025-04-01T17:39:40.978362Z",
          "iopub.status.idle": "2025-04-01T17:39:41.323077Z",
          "shell.execute_reply": "2025-04-01T17:39:41.321787Z"
        },
        "id": "ckJbGP_ds-pc",
        "papermill": {
          "duration": 0.351374,
          "end_time": "2025-04-01T17:39:41.325147",
          "exception": false,
          "start_time": "2025-04-01T17:39:40.973773",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot one\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_matrix = train_data[0]\n",
        "\n",
        "for i in range(data_matrix.shape[0]):\n",
        "    xs = data_matrix[i, :, 0]\n",
        "    ys = data_matrix[i, :, 1]\n",
        "    # trim all zeros\n",
        "    xs = xs[xs != 0]\n",
        "    ys = ys[ys != 0]\n",
        "    # plot each line going from transparent to full\n",
        "    plt.plot(xs, ys)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:41.339052Z",
          "iopub.status.busy": "2025-04-01T17:39:41.338689Z",
          "iopub.status.idle": "2025-04-01T17:39:41.348089Z",
          "shell.execute_reply": "2025-04-01T17:39:41.346792Z"
        },
        "id": "k1ZWD-EEs-pd",
        "papermill": {
          "duration": 0.015255,
          "end_time": "2025-04-01T17:39:41.349879",
          "exception": false,
          "start_time": "2025-04-01T17:39:41.334624",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2100, 1, 60, 2)"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# say you have a model trained. we write a dummy model just to show usage\n",
        "\n",
        "def dummy_model(input_data):\n",
        "    return np.ones((2100, 1, 60, 2))\n",
        "\n",
        "\n",
        "output = dummy_model(test_data)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:41.358147Z",
          "iopub.status.busy": "2025-04-01T17:39:41.357784Z",
          "iopub.status.idle": "2025-04-01T17:39:41.587769Z",
          "shell.execute_reply": "2025-04-01T17:39:41.586758Z"
        },
        "id": "V6RnZeqLs-pd",
        "papermill": {
          "duration": 0.236496,
          "end_time": "2025-04-01T17:39:41.589803",
          "exception": false,
          "start_time": "2025-04-01T17:39:41.353307",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# reshape to fit desired format: (2100, 1, 60, 2) -> (12600, 2)\n",
        "dummy_output = output.reshape(-1, 2)\n",
        "output_df = pd.DataFrame(dummy_output, columns=['x', 'y'])\n",
        "\n",
        "# adding a necessary step to match index of your prediction to that of the solution key\n",
        "\n",
        "output_df.index.name = 'index'\n",
        "\n",
        "output_df.to_csv('dummy_submission.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simple MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CxcJtU5s-pf",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 50, 50, 6) (10000, 60, 2)\n"
          ]
        }
      ],
      "source": [
        "# Split x and y for train data.\n",
        "\n",
        "train_x, train_y = train_data[:, :, :50, :], train_data[:, 0, 50:, :2]\n",
        "\n",
        "print(train_x.shape, train_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLC6JXYCs-pf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_features, output_features):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        # Define the layers\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_features, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(256, output_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.mlp(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wutVdErzs-pf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Calculate the total number of features after flattening\n",
        "input_features = 50 * 50 * 6  # = 15000\n",
        "output_features = 60 * 2\n",
        "\n",
        "# Create the model\n",
        "simple_model = MLP(input_features, output_features)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()  # For regression task\n",
        "\n",
        "optimizer = optim.Adam(simple_model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK9mi4Nas-pf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Example of how to prepare data and train the model\n",
        "\n",
        "def train_model(model, train_x, train_y, batch_size=64, epochs=10):\n",
        "    # Convert numpy arrays to PyTorch tensors\n",
        "    X_train_tensor = torch.FloatTensor(train_x).reshape((-1, input_features))\n",
        "    y_train_tensor = torch.FloatTensor(train_y).reshape((-1, output_features))\n",
        "    print(X_train_tensor.shape)\n",
        "    print(y_train_tensor.shape)\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_X, batch_y in tqdm(train_loader):\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, batch_y)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Print epoch statistics\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41faFOm2s-pg",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 15000])\n",
            "torch.Size([10000, 120])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:24<00:00,  6.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 881208.6087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:22<00:00,  7.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 327127.6840\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:20<00:00,  7.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: 235649.2520\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:20<00:00,  7.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: 231455.6176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:21<00:00,  7.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss: 215819.8926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:20<00:00,  7.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss: 250712.6843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:19<00:00,  8.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss: 214834.2305\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:20<00:00,  7.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss: 247021.6875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:20<00:00,  7.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss: 178459.0109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:20<00:00,  7.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 201185.7981\n"
          ]
        }
      ],
      "source": [
        "simple_model = train_model(simple_model, train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2IsLzTEs-pg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def predict(model, X_test):\n",
        "    \"\"\"Make predictions with the trained model\"\"\"\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        X_test_tensor = torch.FloatTensor(X_test).reshape((-1, input_features))\n",
        "        predictions = model(X_test_tensor).reshape((-1, 60, 2))\n",
        "    return predictions.numpy()\n",
        "\n",
        "# Save model\n",
        "def save_model(model, path=\"mlp_model.pth\"):\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"Model saved to {path}\")\n",
        "\n",
        "# Load model\n",
        "def load_model(path=\"mlp_model.pth\"):\n",
        "    loaded_model = MLP()\n",
        "    loaded_model.load_state_dict(torch.load(path))\n",
        "    loaded_model.eval()\n",
        "    return loaded_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simple MLP model train MSE: 104943.0821\n"
          ]
        }
      ],
      "source": [
        "# train loss\n",
        "\n",
        "# Predict on training data\n",
        "train_pred_y = predict(simple_model, train_x)\n",
        "\n",
        "# Compute mean squared error between predicted and true future trajectories\n",
        "mlp_mse = ((train_pred_y - train_y) ** 2).mean()\n",
        "print(f\"Simple MLP model train MSE: {mlp_mse:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_x shape: (10000, 50, 50, 6)\n",
            "train_pred_y shape: (10000, 60, 2)\n",
            "train_y shape: (10000, 60, 2)\n"
          ]
        }
      ],
      "source": [
        "print(f'train_x shape: {train_x.shape}')\n",
        "print(f'train_pred_y shape: {train_pred_y.shape}')\n",
        "print(f'train_y shape: {train_y.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: [[ 287.38553 -611.02747]\n",
            " [ 283.4844  -609.6404 ]\n",
            " [ 300.98788 -625.56537]\n",
            " [ 292.9798  -620.84015]\n",
            " [ 309.76144 -599.1161 ]]\n",
            "Ground truth: [[ 287.20506697 -656.44786782]\n",
            " [ 286.15194295 -656.12434684]\n",
            " [ 285.09779188 -655.8001401 ]\n",
            " [ 284.04323995 -655.47571797]\n",
            " [ 282.98837762 -655.15099393]]\n"
          ]
        }
      ],
      "source": [
        "# Check one prediction vs true value\n",
        "i = 0\n",
        "print(\"Predicted:\", train_pred_y[i, :5])  # First 5 steps\n",
        "print(\"Ground truth:\", train_y[i, :5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBzrfB_gs-pg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "pred_y = predict(simple_model, test_data)\n",
        "\n",
        "pred_output = pred_y.reshape(-1, 2)\n",
        "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
        "\n",
        "# adding a necessary step to match index of your prediction to that of the solution key\n",
        "\n",
        "output_df.index.name = 'index'\n",
        "\n",
        "output_df.to_csv('mlp_baseline.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5ponqm0s-pg",
        "papermill": {
          "duration": 0.003051,
          "end_time": "2025-04-01T17:39:41.596387",
          "exception": false,
          "start_time": "2025-04-01T17:39:41.593336",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        " # Now you can submit to the leaderboard!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SHANTIH MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Taking just the x, y as input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 50, 50, 2) (10000, 60, 2)\n"
          ]
        }
      ],
      "source": [
        "train_x, train_y = train_data[:, :, :50, :2], train_data[:, 0, 50:, :2]\n",
        "\n",
        "print(train_x.shape, train_y.shape)\n",
        "\n",
        "# Calculate the total number of features after flattening\n",
        "input_features = 50 * 50 * 2  # = 5000\n",
        "output_features = 60 * 2\n",
        "\n",
        "pos_model = MLP(input_features, output_features)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()  # For regression task\n",
        "\n",
        "optimizer = optim.Adam(pos_model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 5000])\n",
            "torch.Size([10000, 120])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:08<00:00, 18.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 818656.2593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:09<00:00, 16.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 328710.1956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:07<00:00, 22.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: 271412.3518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:07<00:00, 22.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: 214101.8230\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:06<00:00, 22.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss: 215431.4034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:07<00:00, 21.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss: 267139.8893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:09<00:00, 17.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss: 217641.2600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:09<00:00, 16.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss: 194271.5078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:07<00:00, 19.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss: 175669.3564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:08<00:00, 18.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 151924.2085\n"
          ]
        }
      ],
      "source": [
        "pos_model = train_model(pos_model, train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP model train MSE: 165880.8008\n"
          ]
        }
      ],
      "source": [
        "train_pred_y = predict(pos_model, train_x)\n",
        "\n",
        "# Compute mean squared error between predicted and true future trajectories\n",
        "mlp_mse = ((train_pred_y - train_y) ** 2).mean()\n",
        "print(f\"MLP model train MSE: {mlp_mse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using just the ego"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 50, 2) (10000, 60, 2)\n"
          ]
        }
      ],
      "source": [
        "train_x, train_y = train_data[:, 0, :50, :2], train_data[:, 0, 50:, :2]\n",
        "\n",
        "print(train_x.shape, train_y.shape)\n",
        "\n",
        "# Calculate the total number of features after flattening\n",
        "input_features = 50 * 2  # = 100\n",
        "output_features = 60 * 2\n",
        "\n",
        "ego_model = MLP(input_features, output_features)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()  # For regression task\n",
        "\n",
        "optimizer = optim.Adam(ego_model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 100])\n",
            "torch.Size([10000, 120])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 119.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 602073.4793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 134.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 143305.9692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 137.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: 107230.8281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 101.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: 131723.8611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 98.04it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss: 133177.1938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 99.81it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss: 96822.9371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 110.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss: 116843.7296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 120.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss: 92490.9523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 102.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss: 86938.2755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 84.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 91513.7790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "ego_model = train_model(ego_model, train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP model train MSE: 9339.2535\n"
          ]
        }
      ],
      "source": [
        "train_pred_y = predict(ego_model, train_x)\n",
        "\n",
        "# Compute mean squared error between predicted and true future trajectories\n",
        "mlp_mse = ((train_pred_y - train_y) ** 2).mean()\n",
        "print(f\"MLP model train MSE: {mlp_mse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 50, 2) (10000, 60, 2)\n"
          ]
        }
      ],
      "source": [
        "train_x, train_y = train_data[:, 0, :50, :2], train_data[:, 0, 50:, :2]\n",
        "initial_x, initial_y = train_x[:, 0:1, :].copy(), train_y[:, 0:1, :].copy()\n",
        "train_x -= initial_x\n",
        "train_y -= initial_y\n",
        "\n",
        "print(train_x.shape, train_y.shape)\n",
        "\n",
        "# Calculate the total number of features after flattening\n",
        "input_features = 50 * 2  # = 100\n",
        "output_features = 60 * 2\n",
        "\n",
        "norm_model = MLP(input_features, output_features)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()  # For regression task\n",
        "\n",
        "optimizer = optim.Adam(norm_model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 100])\n",
            "torch.Size([10000, 120])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 123.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 62.0360\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 136.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Loss: 38.9814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 110.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Loss: 35.0662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 100.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Loss: 33.7527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 116.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Loss: 31.2684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 110.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Loss: 31.6507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 109.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Loss: 30.3936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 109.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Loss: 29.7717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 96.46it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Loss: 28.4794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 157/157 [00:01<00:00, 108.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 28.3565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "norm_model = train_model(norm_model, train_x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP model train MSE: 24.0053\n"
          ]
        }
      ],
      "source": [
        "train_pred_y = predict(norm_model, train_x)\n",
        "\n",
        "# Compute mean squared error between predicted and true future trajectories\n",
        "mlp_mse = ((train_pred_y - train_y) ** 2).mean()\n",
        "print(f\"MLP model train MSE: {mlp_mse:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CODE TO START NORMALIZING TEST AND RUN ALL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data's shape (10000, 50, 110, 6)\n",
            "test_data's shape (2100, 50, 50, 6)\n"
          ]
        }
      ],
      "source": [
        "train_file = np.load('./cse-251-b-2025/train.npz')\n",
        "\n",
        "train_data = train_file['data']\n",
        "print(\"train_data's shape\", train_data.shape)\n",
        "test_file = np.load('./cse-251-b-2025/test_input.npz')\n",
        "\n",
        "test_data = test_file['data']\n",
        "print(\"test_data's shape\", test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2100, 50, 2)\n"
          ]
        }
      ],
      "source": [
        "# FORGOT WE DONT HAVE LABELS FOR TEST LOL\n",
        "test_data = test_file['data']\n",
        "test_x = test_data[:, 0, :50, :2]\n",
        "initial_test_x = test_x[:, 0:1, :].copy()\n",
        "test_x -= initial_test_x\n",
        "\n",
        "print(test_x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code for autoregressive stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_features = 50\n",
        "num_labels = 10\n",
        "\n",
        "def do_autoregressive(train_data, num_features, num_labels):\n",
        "    ar_train_x, ar_train_y = [], []\n",
        "\n",
        "    for s in range(train_data.shape[0]):\n",
        "        for p in range(num_features, 110 - num_labels):\n",
        "            train_x, train_y = train_data[s, 0, p-num_features:p, :2], train_data[s, 0, p:p+num_labels, :2] \n",
        "            initial_train_x, = train_x[0:1, :].copy()\n",
        "            train_x -= initial_train_x\n",
        "            train_y -= initial_train_x\n",
        "            ar_train_x.append(train_x)\n",
        "            ar_train_y.append(train_y)\n",
        "    ar_train_x = np.stack(ar_train_x, axis=0)\n",
        "    ar_train_y = np.stack(ar_train_y, axis=0)\n",
        "    return ar_train_x, ar_train_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 50, 2)\n",
            "(500000, 50, 2) (500000, 10, 2)\n",
            "(500000, 50, 2) (500000, 10, 2)\n",
            "(400000, 50, 2) (400000, 10, 2)\n",
            "(100000, 50, 2) (100000, 10, 2)\n"
          ]
        }
      ],
      "source": [
        "auto_regressive = True\n",
        "\n",
        "train_x, train_y = train_data[:, 0, :50, :2], train_data[:, 0, 50:, :2]\n",
        "initial_train_x, initial_train_y = train_x[:, 0:1, :].copy(), train_y[:, 0:1, :].copy()\n",
        "train_x -= initial_train_x\n",
        "train_y -= initial_train_x\n",
        "\n",
        "print(train_x.shape)\n",
        "\n",
        "if auto_regressive:\n",
        "    train_x, train_y = do_autoregressive(train_data, num_features, num_labels)\n",
        "    print(train_x.shape, train_y.shape)\n",
        "\n",
        "ratio_validation = 0.2\n",
        "perm = torch.randperm(train_x.shape[0])\n",
        "idx = int(ratio_validation * train_x.shape[0])\n",
        "\n",
        "new_train_x = train_x[perm[idx:]]\n",
        "new_train_y = train_y[perm[idx:]]\n",
        "\n",
        "val_x = train_x[perm[:idx]]\n",
        "val_y = train_y[perm[:idx]]\n",
        "\n",
        "print(train_x.shape, train_y.shape)\n",
        "print(new_train_x.shape, new_train_y.shape)\n",
        "print(val_x.shape, val_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Code for adding closest agent feature (in progress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dist(x1, y1, x2, y2):\n",
        "    return Math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
        "\n",
        "def add_closest_agent(x):\n",
        "    #x is the features.\n",
        "    #I want to take them from (num_scenes, num_agents, num_timesteps, num_dimensions) to (num_scenes, num_timesteps, num_dimensions * 2) by adding the dimensions of the closest agent\n",
        "\n",
        "    new_x = []\n",
        "    for s in x.shape[0]:\n",
        "        each_scene = []\n",
        "        for t in x.shape[2]:\n",
        "            ca = 1\n",
        "            for a in x.shape[1]:\n",
        "                if dist(x[s][0][t][0], x[s][0][t][1], x[s][a][t][0], x[s][a][t][1]) < dist(x[s][0][t][0], x[s][0][t][1], x[s][ca][t][0], x[s][ca][t][1]):\n",
        "                    ca = a\n",
        "            each_scene.append([x[s][0][t][0], x[s][0][t][1], x[s][ca][t][0], x[s][ca][t][1]])\n",
        "        new_x.append(each_scene)\n",
        "\n",
        "    return new_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ComplexMLP(nn.Module):\n",
        "    def __init__(self, input_features, output_features):\n",
        "        super(ComplexMLP, self).__init__()\n",
        "\n",
        "        # Define the layers\n",
        "        self.input_features = input_features\n",
        "        self.output_features = output_features\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_features, 1024),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(512, output_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.mlp(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(model, x):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        print(input_features, output_features, output_features / 2)\n",
        "        x_tensor = torch.FloatTensor(x).reshape((-1, input_features))\n",
        "        predictions = model(x_tensor).reshape((-1, int(output_features / 2), 2))\n",
        "        return predictions.numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, x, y, dataset):\n",
        "    pred_y = predict(model, x)\n",
        "        \n",
        "    mse = ((pred_y - y) ** 2).mean()\n",
        "    print(\"Model MSE evaluated on\", dataset, \":\", mse.item())\n",
        "    return mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of how to prepare data and train the model\n",
        "\n",
        "def new_train_model(model, criterion, optimizer, train_x, train_y, val_x, val_y, batch_size=64, epochs=10):\n",
        "    # Convert numpy arrays to PyTorch tensors\n",
        "    X_train_tensor = torch.FloatTensor(train_x).reshape((-1, model.input_features))\n",
        "    y_train_tensor = torch.FloatTensor(train_y).reshape((-1, model.output_features))\n",
        "    print(X_train_tensor.shape)\n",
        "    print(y_train_tensor.shape)\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, batch_y)\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Print epoch statistics\n",
        "        #print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}')\n",
        "        evaluate_model(model, train_x, train_y, \"TRAIN\")\n",
        "        evaluate_model(model, val_x, val_y, \"VALIDATION\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 20\n",
            "torch.Size([400000, 100])\n",
            "torch.Size([400000, 20])\n",
            "Epoch 1, Loss: 3.3900\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 1.0828152877139652\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 1.0743849798671727\n",
            "Epoch 2, Loss: 1.4226\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.8946436561768514\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.8866487318935139\n",
            "Epoch 3, Loss: 0.9329\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.9747986184621523\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.9693825974833505\n",
            "Epoch 4, Loss: 0.8040\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.7465484780693817\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.7460102568266834\n",
            "Epoch 5, Loss: 0.7042\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.6077719392221514\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.6049964269061965\n",
            "Epoch 6, Loss: 0.6305\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.7581213748297403\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.7522217850506681\n",
            "Epoch 7, Loss: 0.5943\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.513140037868203\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.5114997400902739\n",
            "Epoch 8, Loss: 0.5655\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.9377614220263211\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.9291518448302764\n",
            "Epoch 9, Loss: 0.5113\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.46722975161342556\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.46560346699707134\n",
            "Epoch 10, Loss: 0.5091\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.44562176664685477\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.4449076269815046\n",
            "Epoch 11, Loss: 0.5132\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.38863800462236414\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.3876645269644237\n",
            "Epoch 12, Loss: 0.4683\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.5168186297188263\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.512904111757808\n",
            "Epoch 13, Loss: 0.4725\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.42543446749823133\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.4231463648620557\n",
            "Epoch 14, Loss: 0.4557\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.4044011283327403\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.4023181646462332\n",
            "Epoch 15, Loss: 0.4558\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.47959302988459496\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.47708631156330555\n",
            "Epoch 16, Loss: 0.4351\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.48075315617924863\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.47985008604411244\n",
            "Epoch 17, Loss: 0.4444\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.3889069766496425\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.38635357576040397\n",
            "Epoch 18, Loss: 0.4315\n",
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.3667418037593705\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.36523197879936026\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m criterion = nn.MSELoss()\n\u001b[32m     15\u001b[39m optimizer = optim.Adam(norm_model.parameters(), lr=\u001b[32m0.001\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m norm_model = \u001b[43mnew_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_train_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_train_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mnew_train_model\u001b[39m\u001b[34m(model, criterion, optimizer, train_x, train_y, val_x, val_y, batch_size, epochs)\u001b[39m\n\u001b[32m     28\u001b[39m     \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[32m     29\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     running_loss += loss.item()\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Print epoch statistics\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m#print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}')\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cse251/lib/python3.12/site-packages/torch/optim/optimizer.py:385\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    381\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    382\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    383\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    388\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cse251/lib/python3.12/site-packages/torch/optim/optimizer.py:76\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     74\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m'\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     75\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     78\u001b[39m     torch._dynamo.graph_break()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cse251/lib/python3.12/site-packages/torch/optim/adam.py:166\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    155\u001b[39m     beta1, beta2 = group[\u001b[33m'\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    157\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    158\u001b[39m         group,\n\u001b[32m    159\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    163\u001b[39m         max_exp_avg_sqs,\n\u001b[32m    164\u001b[39m         state_steps)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cse251/lib/python3.12/site-packages/torch/optim/adam.py:316\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    314\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cse251/lib/python3.12/site-packages/torch/optim/adam.py:391\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[39m\n\u001b[32m    388\u001b[39m     param = torch.view_as_real(param)\n\u001b[32m    390\u001b[39m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[43mexp_avg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m exp_avg_sq.mul_(beta2).addcmul_(grad, grad.conj(), value=\u001b[32m1\u001b[39m - beta2)\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "input_features = 50 * 2  # = 100\n",
        "output_features = 60 * 2\n",
        "\n",
        "if auto_regressive:\n",
        "    input_features = num_features * 2\n",
        "    output_features = num_labels * 2\n",
        "\n",
        "print(input_features, output_features)\n",
        "\n",
        "norm_model = ComplexMLP(input_features, output_features)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(norm_model.parameters(), lr=0.001)\n",
        "\n",
        "norm_model = new_train_model(norm_model, criterion, optimizer, new_train_x, new_train_y, val_x, val_y, batch_size=64, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 20 10.0\n",
            "Model MSE evaluated on TRAIN : 0.3644307232142692\n",
            "100 20 10.0\n",
            "Model MSE evaluated on VALIDATION : 0.36405780795426457\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.36405780795426457"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_model(norm_model, train_x, train_y, \"TRAIN\")\n",
        "evaluate_model(norm_model, val_x, val_y, \"VALIDATION\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ar_inference(norm_model, feature):\n",
        "    print('in', feature.shape)\n",
        "    answer = []\n",
        "    for i in range(int(60 / num_labels)):\n",
        "        pred = predict(norm_model, feature)\n",
        "        answer.append(pred)\n",
        "        feature = np.concatenate((feature, pred), axis=1)\n",
        "        feature = feature[:, -num_features:, :]\n",
        "    answer = np.concatenate(answer, axis=1)\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2100, 50, 2)\n",
            "in (2100, 50, 2)\n",
            "100 20 10.0\n",
            "100 20 10.0\n",
            "100 20 10.0\n",
            "100 20 10.0\n",
            "100 20 10.0\n",
            "100 20 10.0\n"
          ]
        }
      ],
      "source": [
        "print(test_x.shape)\n",
        "if not auto_regressive:\n",
        "    pred_y = predict(norm_model, test_x)\n",
        "else:\n",
        "    pred_y = ar_inference(norm_model, test_x)\n",
        "\n",
        "pred_y += initial_test_x\n",
        "\n",
        "# Code to write the prediction to file\n",
        "pred_output = pred_y.reshape(-1, 2)\n",
        "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
        "\n",
        "output_df.index.name = 'index'\n",
        "\n",
        "output_df.to_csv('shantih_mlp.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "data-loading-and-submission-preperation",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "cse251",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 27.524611,
      "end_time": "2025-04-01T17:39:42.223757",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-01T17:39:14.699146",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
