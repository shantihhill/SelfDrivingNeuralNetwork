{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n-C_P-zs-pY"
      },
      "source": [
        "# LSTM - vanilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = \"best_model_all_feat_2layers_all_agents_attn.pt\"\n",
        "\n",
        "# best_model = \"best_model_all_feat_all_agents.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'best_model_all_feat_2layers_all_agents_attn.pt'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:17.728787Z",
          "iopub.status.busy": "2025-04-01T17:39:17.728324Z",
          "iopub.status.idle": "2025-04-01T17:39:18.875979Z",
          "shell.execute_reply": "2025-04-01T17:39:18.874618Z"
        },
        "id": "F4_wHjhZs-pa",
        "papermill": {
          "duration": 1.154057,
          "end_time": "2025-04-01T17:39:18.878059",
          "exception": false,
          "start_time": "2025-04-01T17:39:17.724002",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import Data, Batch\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:18.890746Z",
          "iopub.status.busy": "2025-04-01T17:39:18.890075Z",
          "iopub.status.idle": "2025-04-01T17:39:40.968717Z",
          "shell.execute_reply": "2025-04-01T17:39:40.967158Z"
        },
        "id": "09texa_os-pc",
        "papermill": {
          "duration": 22.084222,
          "end_time": "2025-04-01T17:39:40.970631",
          "exception": false,
          "start_time": "2025-04-01T17:39:18.886409",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data's shape (10000, 50, 110, 6)\n",
            "test_data's shape (2100, 50, 50, 6)\n"
          ]
        }
      ],
      "source": [
        "train_file = np.load('../cse-251-b-2025/train.npz')\n",
        "\n",
        "train_data = train_file['data']\n",
        "# train_data = train_data[::3]\n",
        "print(\"train_data's shape\", train_data.shape)\n",
        "test_file = np.load('../cse-251-b-2025/test_input.npz')\n",
        "\n",
        "test_data = test_file['data']\n",
        "print(\"test_data's shape\", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:40.97884Z",
          "iopub.status.busy": "2025-04-01T17:39:40.978362Z",
          "iopub.status.idle": "2025-04-01T17:39:41.323077Z",
          "shell.execute_reply": "2025-04-01T17:39:41.321787Z"
        },
        "id": "ckJbGP_ds-pc",
        "papermill": {
          "duration": 0.351374,
          "end_time": "2025-04-01T17:39:41.325147",
          "exception": false,
          "start_time": "2025-04-01T17:39:40.973773",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot one\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_matrix = train_data[0]\n",
        "\n",
        "for i in range(data_matrix.shape[0]):\n",
        "    xs = data_matrix[i, :, 0]\n",
        "    ys = data_matrix[i, :, 1]\n",
        "    # trim all zeros\n",
        "    xs = xs[xs != 0]\n",
        "    ys = ys[ys != 0]\n",
        "    # plot each line going from transparent to full\n",
        "    plt.plot(xs, ys)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrajectoryDatasetTrain(Dataset):\n",
        "    def __init__(self, data, scale=10.0, augment=True):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Training data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        augment: Whether to apply data augmentation (only for training)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        scene = self.data[idx]\n",
        "        # Getting 50 historical timestamps and 60 future timestamps\n",
        "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
        "        future = torch.tensor(scene[0, 50:, :].copy(), dtype=torch.float32)  # (60, 2)\n",
        "        \n",
        "        # Data augmentation(only for training)\n",
        "        if self.augment:\n",
        "            if np.random.rand() < 0.5:\n",
        "                theta = np.random.uniform(-np.pi, np.pi)\n",
        "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
        "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
        "                # Rotate the historical trajectory and future trajectory\n",
        "                hist[..., :2] = hist[..., :2] @ R\n",
        "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
        "                future[..., :2] = future[..., :2] @ R\n",
        "                future[..., 2:4] = future[..., 2:4] @ R\n",
        "                # future = future @ R\n",
        "            if np.random.rand() < 0.5:\n",
        "                hist[..., 0] *= -1\n",
        "                hist[..., 2] *= -1\n",
        "                future[:, 0] *= -1\n",
        "\n",
        "        # Use the last timeframe of the historical trajectory as the origin\n",
        "        origin = hist[0, 49, :2].copy()  # (2,)\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        future[..., :2] = future[..., :2] - origin\n",
        "\n",
        "        # Normalize the historical trajectory and future trajectory\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "        future[..., :4] = future[..., :4] / self.scale\n",
        "\n",
        "        # future = future / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            y=future.type(torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0), # (1,2)\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32), # scalar e.g. 7.0\n",
        "        )\n",
        "\n",
        "        return data_item\n",
        "    \n",
        "\n",
        "class TrajectoryDatasetTest(Dataset):\n",
        "    def __init__(self, data, scale=10.0):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Testing data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Testing data only contains historical trajectory\n",
        "        scene = self.data[idx]  # (50, 50, 6)\n",
        "        hist = scene.copy()\n",
        "        \n",
        "        origin = hist[0, 49, :2].copy()\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
        "        )\n",
        "        return data_item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple Silicon GPU\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(251)\n",
        "np.random.seed(42)\n",
        "\n",
        "scale = 7.0 #why not 10\n",
        "\n",
        "N = len(train_data)\n",
        "val_size = int(0.1 * N)\n",
        "train_size = N - val_size\n",
        "\n",
        "train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
        "val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "\n",
        "# Set device for training speedup\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"Using Apple Silicon GPU\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, input_dim, embed_dim, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(input_dim, embed_dim)\n",
        "        self.key = nn.Linear(input_dim, embed_dim)\n",
        "        self.value = nn.Linear(input_dim, embed_dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, time_steps, num_agents, input_dim]\n",
        "        B, T, N, D = x.shape\n",
        "        x = x.reshape(B * T, N, D)  # Combine batch and time\n",
        "\n",
        "        Q = self.query(x)\n",
        "        K = self.key(x)\n",
        "        V = self.value(x)\n",
        "\n",
        "        out, _ = self.attn(Q, K, V)  # [B*T, N, D]\n",
        "        return out.reshape(B, T, N, -1).permute(0,2,1,3)  # Restore shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/0r/zhth93bs1ygg_ln8t_nhb4f80000gn/T/ipykernel_84522/3979743590.py:30: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future[..., :2] = future[..., :2] @ R\n",
            "/var/folders/0r/zhth93bs1ygg_ln8t_nhb4f80000gn/T/ipykernel_84522/3979743590.py:31: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future[..., 2:4] = future[..., 2:4] @ R\n",
            "/var/folders/0r/zhth93bs1ygg_ln8t_nhb4f80000gn/T/ipykernel_84522/3979743590.py:41: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future[..., :2] = future[..., :2] - origin\n"
          ]
        }
      ],
      "source": [
        "\n",
        "attention = SpatialAttention(input_dim=6, embed_dim=64, num_heads=4).to(device)\n",
        "i = 0\n",
        "for batch in train_dataloader:\n",
        "    batch = batch.to(device)\n",
        "    batch_x = batch.x.view(batch.batch_size, 50, 50, 6)\n",
        "    batch_x = batch_x.permute(0,2,1,3)  # [B, N, T, D]\n",
        "    attn_output = attention(batch_x)\n",
        "    i += 1\n",
        "    if i == 1:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 50, 50, 64])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attn_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AutoRegressiveLSTM(nn.Module):\n",
        "    def __init__(self, input_dim=5, hidden_dim=512, output_dim=2, num_layers=2, future_steps=60):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.future_steps = future_steps\n",
        "\n",
        "        # Encoder: takes in past trajectory\n",
        "        #attention\n",
        "        self.attention = SpatialAttention(input_dim =  self.input_dim, embed_dim= self.hidden_dim, num_heads=4)\n",
        "\n",
        "        self.encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        # Decoder: predicts future positions one step at a time\n",
        "        self.decoder = nn.LSTM(input_size=5, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, data, forcing_ratio = 0.5):\n",
        "    # def forward(self, data):\n",
        "        x = data.x[..., :5]  # Use position + velocity\n",
        "        x_ego = x.reshape(-1, 50, 50, self.input_dim)[:, 0, :, :]  # (batch, 50, 5), ego only\n",
        "        # x = x.reshape(-1, 50, self.input_dim)\n",
        "\n",
        "        x = x.reshape(-1, 50, 50, self.input_dim)\n",
        "\n",
        "        x_attn = self.attention(x)  # Apply attention to the input\n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "        if self.training:\n",
        "            future = data.y.view(batch_size, 60, self.output_dim) # (batch, 60, 2)\n",
        "\n",
        "        device = x.device\n",
        "\n",
        "        # Encode past\n",
        "        _, (hidden, cell) = self.encoder(x)\n",
        "\n",
        "        # Initialize decoder input with last observed position\n",
        "        decoder_input = x[:, -1, :self.output_dim].unsqueeze(1)  # (batch, 1, 2)\n",
        "        \n",
        "        # print(\"decoder_input.shape - initial\", decoder_input.shape)  # should be (batch, 1, 2)\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for t in range(self.future_steps):\n",
        "            output, (hidden, cell) = self.decoder(decoder_input, (hidden, cell))\n",
        "            pred = self.out(output)  # (batch, 1, 2)\n",
        "            outputs.append(pred)\n",
        "\n",
        "            # TODO: remove forcing ratio?\n",
        "            if self.training and random.random() < forcing_ratio:\n",
        "            # if self.training:\n",
        "                decoder_input = future[:, t].unsqueeze(1)  # ground truth\n",
        "                # print(\"decoder_input.shape - teacher forcing\", decoder_input.shape)  # should be (batch, 1, 2)\n",
        "            else:\n",
        "                decoder_input = pred.detach()  # predicted output as next input\n",
        "                # print(\"decoder_input.shape - autoreg\", decoder_input.shape)  # should be (batch, 1, 2)\n",
        "\n",
        "        outputs = torch.cat(outputs, dim=1)  # (batch, 60, 2)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Example of basic model with simple attention mechanism\n",
        "# class SimpleLSTMWithAttn(nn.Module):\n",
        "#     def __init__(self, input_dim=5, hidden_dim=512, output_dim=60*2):\n",
        "#         super(SimpleLSTMWithAttn, self).__init__()\n",
        "#         self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        \n",
        "#         # Simple attention mechanism\n",
        "#         self.attention = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "#         # Add multi-layer prediction head for better results\n",
        "#         self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "#         self.dropout = nn.Dropout(0.1)  # Add dropout for regularization\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "#         # Initialize weights properly\n",
        "#         for name, param in self.named_parameters():\n",
        "#             if 'weight' in name:\n",
        "#                 nn.init.xavier_normal_(param)\n",
        "#             elif 'bias' in name:\n",
        "#                 nn.init.constant_(param, 0.0)\n",
        "        \n",
        "#     def forward(self, data):\n",
        "#         x = data.x[..., :5]\n",
        "#         x = x.reshape(-1, 50, 50, 5)  # (batch_size, num_agents, seq_len, input_dim)\n",
        "#         x = x[:, 0, :, :]  # Only consider ego agent (index 0)\n",
        "        \n",
        "#         # Process through LSTM\n",
        "#         lstm_out, _ = self.lstm(x)  # (batch_size, seq_len, hidden_dim)\n",
        "        \n",
        "#         # Apply attention mechanism\n",
        "#         attention_weights = torch.softmax(self.attention(lstm_out), dim=1)  # (batch_size, seq_len, 1)\n",
        "#         attended_features = torch.sum(lstm_out * attention_weights, dim=1)  # (batch_size, hidden_dim)\n",
        "        \n",
        "#         # Process through prediction head\n",
        "#         features = self.relu(self.fc1(attended_features))\n",
        "#         features = self.dropout(features)\n",
        "#         out = self.fc2(features)\n",
        "        \n",
        "#         # Reshape to (batch_size, 60, 2)\n",
        "#         return out.view(-1, 60, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_improved_model(model, train_dataloader, val_dataloader, \n",
        "                         device, criterion=nn.MSELoss(), \n",
        "                         lr=0.001, epochs=100, patience=15):\n",
        "    \"\"\"\n",
        "    Improved training function with better debugging and early stopping\n",
        "    \"\"\"\n",
        "    # Initialize optimizer with smaller learning rate\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    # Exponential decay scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "    \n",
        "    early_stopping_patience = patience\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement = 0\n",
        "    \n",
        "    # Save initial state for comparison\n",
        "    initial_state_dict = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "    \n",
        "    for epoch in tqdm.tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
        "        # ---- Training ----\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        num_train_batches = 0\n",
        "        forcing_ratio = max(0.0, 1.0 - epoch / 50)\n",
        "        \n",
        "        for batch in train_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch, forcing_ratio=forcing_ratio)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 5)\n",
        "            \n",
        "            # Check for NaN predictions\n",
        "            if torch.isnan(pred).any():\n",
        "                print(f\"WARNING: NaN detected in predictions during training\")\n",
        "                continue\n",
        "                \n",
        "            loss = criterion(pred, y)\n",
        "            \n",
        "            # Check if loss is valid\n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                print(f\"WARNING: Invalid loss value: {loss.item()}\")\n",
        "                continue\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            \n",
        "            # More conservative gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            \n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            num_train_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid batches\n",
        "        if num_train_batches == 0:\n",
        "            print(\"WARNING: No valid training batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        train_loss /= num_train_batches\n",
        "        \n",
        "        # ---- Validation ----\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_mae = 0\n",
        "        val_mse = 0\n",
        "        num_val_batches = 0\n",
        "        \n",
        "        # Sample predictions for debugging\n",
        "        sample_input = None\n",
        "        sample_pred = None\n",
        "        sample_target = None\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(val_dataloader):\n",
        "                batch = batch.to(device)\n",
        "                pred = model(batch)\n",
        "                y = batch.y.view(batch.num_graphs, 60, 5)\n",
        "                \n",
        "                # Store sample for debugging\n",
        "                if batch_idx == 0 and sample_input is None:\n",
        "                    sample_input = batch.x[0].cpu().numpy()\n",
        "                    sample_pred = pred[0].cpu().numpy()\n",
        "                    sample_target = y[0].cpu().numpy()\n",
        "                \n",
        "                # Skip invalid predictions\n",
        "                if torch.isnan(pred).any():\n",
        "                    print(f\"WARNING: NaN detected in predictions during validation\")\n",
        "                    continue\n",
        "                    \n",
        "                batch_loss = criterion(pred, y).item()\n",
        "                val_loss += batch_loss\n",
        "                \n",
        "                # Unnormalize for real-world metrics\n",
        "                # batch.scale turns scale from 7.0 or (1,) shape i.e. scalar to (B,) shape\n",
        "                # batch.origin turns origin from (1,2) shape to (B,2)\n",
        "                \n",
        "                # then .view(-1, 1, 1) turns scale from (B,) to (B, 1, 1)\n",
        "                # then .unsqueeze(1) turns origin from (B, 2) to (B, 1, 2)\n",
        "                # because pred and y have shapes (B, 60, 2) so these transformations make them compatible for the calculation\n",
        "                \n",
        "                pred_unnorm = pred[...,:2] * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "                y_unnorm = y[...,:2] * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "                \n",
        "                val_mae += nn.L1Loss()(pred_unnorm, y_unnorm).item()\n",
        "                val_mse += nn.MSELoss()(pred_unnorm, y_unnorm).item()\n",
        "                \n",
        "                num_val_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid validation batches\n",
        "        if num_val_batches == 0:\n",
        "            print(\"WARNING: No valid validation batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        val_loss /= num_val_batches\n",
        "        val_mae /= num_val_batches\n",
        "        val_mse /= num_val_batches\n",
        "        \n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Print with more details\n",
        "        tqdm.tqdm.write(\n",
        "            f\"Epoch {epoch:03d} | LR {optimizer.param_groups[0]['lr']:.6f} | \"\n",
        "            f\"Train MSE {train_loss:.4f} | Val MSE {val_loss:.4f} | \"\n",
        "            f\"Val MAE {val_mae:.4f} | Val MSE {val_mse:.4f}\"\n",
        "        )\n",
        "        \n",
        "        # Debug output - first 3 predictions vs targets\n",
        "        if epoch % 5 == 0:\n",
        "            tqdm.tqdm.write(f\"Sample pred first 3 steps: {sample_pred[:3]}\")\n",
        "            tqdm.tqdm.write(f\"Sample target first 3 steps: {sample_target[:3]}\")\n",
        "            \n",
        "            # Check if model weights are changing\n",
        "            if epoch > 0:\n",
        "                weight_change = False\n",
        "                for name, param in model.named_parameters():\n",
        "                    if param.requires_grad:\n",
        "                        initial_param = initial_state_dict[name]\n",
        "                        if not torch.allclose(param, initial_param, rtol=1e-4):\n",
        "                            weight_change = True\n",
        "                            break\n",
        "                if not weight_change:\n",
        "                    tqdm.tqdm.write(\"WARNING: Model weights barely changing!\")\n",
        "        \n",
        "        # Relaxed improvement criterion - consider any improvement\n",
        "        if val_loss < best_val_loss:\n",
        "            tqdm.tqdm.write(f\"Validation improved: {best_val_loss:.6f} -> {val_loss:.6f}\")\n",
        "            best_val_loss = val_loss\n",
        "            no_improvement = 0\n",
        "            torch.save(model.state_dict(), best_model)\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "            if no_improvement >= early_stopping_patience:\n",
        "                print(f\"Early stopping after {epoch+1} epochs without improvement\")\n",
        "                break\n",
        "    \n",
        "    # Load best model before returning\n",
        "    model.load_state_dict(torch.load(best_model))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage\n",
        "def train_and_evaluate_model():\n",
        "    # Create model\n",
        "    model = AutoRegressiveLSTM(input_dim=5, output_dim = 5, hidden_dim=512)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Train with improved function\n",
        "    train_improved_model(\n",
        "        model=model,\n",
        "        train_dataloader=train_dataloader,\n",
        "        val_dataloader=val_dataloader,\n",
        "        device=device,\n",
        "        # lr = 0.007 => 8.946\n",
        "        lr=0.007,  # Lower learning rate\n",
        "        patience=20,  # More patience\n",
        "        epochs=150\n",
        "    )\n",
        "    \n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    test_mse = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 5)\n",
        "            \n",
        "            # Unnormalize\n",
        "            pred = pred[..., :2] * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            y = y[..., :2] * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
        "            \n",
        "            test_mse += nn.MSELoss()(pred, y).item()\n",
        "    \n",
        "    test_mse /= len(val_dataloader)\n",
        "    print(f\"Val MSE: {test_mse:.4f}\")\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   0%|          | 0/200 [00:00<?, ?epoch/s]/var/folders/0r/zhth93bs1ygg_ln8t_nhb4f80000gn/T/ipykernel_77665/673074036.py:44: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future[..., :2] = future[..., :2] - origin\n",
            "/var/folders/0r/zhth93bs1ygg_ln8t_nhb4f80000gn/T/ipykernel_77665/673074036.py:32: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future[..., :2] = future[..., :2] @ R\n",
            "Epoch:   0%|          | 0/200 [08:11<?, ?epoch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000 | LR 0.006650 | Train MSE 101599.6383 | Val MSE 13183.5758 | Val MAE 652.1830 | Val MSE 645995.2227\n",
            "Validation improved: inf -> 13183.575775\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   1%|          | 2/200 [46:40<85:49:15, 1560.38s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 | LR 0.006317 | Train MSE 45909.0026 | Val MSE 12731.7138 | Val MAE 722.1488 | Val MSE 623853.9707\n",
            "Validation improved: 13183.575775 -> 12731.713806\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   2%|         | 3/200 [1:29:58<111:19:44, 2034.44s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 002 | LR 0.006002 | Train MSE 33096.0912 | Val MSE 13569.0201 | Val MAE 572.9189 | Val MSE 664881.9844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   2%|         | 4/200 [2:18:42<129:52:33, 2385.48s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 003 | LR 0.005702 | Train MSE 23893.0956 | Val MSE 9821.6796 | Val MAE 504.4683 | Val MSE 481262.3086\n",
            "Validation improved: 12731.713806 -> 9821.679596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   2%|         | 5/200 [3:11:29<144:29:31, 2667.54s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 004 | LR 0.005416 | Train MSE 17768.4478 | Val MSE 20516.3224 | Val MAE 797.0940 | Val MSE 1005299.7812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   3%|         | 6/200 [3:52:32<139:59:49, 2597.89s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 005 | LR 0.005146 | Train MSE 15421.2308 | Val MSE 9576.3862 | Val MAE 488.7864 | Val MSE 469242.9248\n",
            "Validation improved: 9821.679596 -> 9576.386169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   4%|         | 7/200 [4:52:32<156:50:36, 2925.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 006 | LR 0.004888 | Train MSE 13281.9149 | Val MSE 77561.5190 | Val MAE 1360.9954 | Val MSE 3800514.4844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   4%|         | 8/200 [5:14:20<128:33:55, 2410.60s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 007 | LR 0.004644 | Train MSE 11740.0415 | Val MSE 15824.0450 | Val MAE 660.7334 | Val MSE 775378.2090\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   4%|         | 9/200 [6:02:22<135:42:46, 2557.94s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 008 | LR 0.004412 | Train MSE 10902.0011 | Val MSE 19387.9565 | Val MAE 712.3643 | Val MSE 950009.8711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   5%|         | 10/200 [6:36:34<126:45:25, 2401.71s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 009 | LR 0.004191 | Train MSE 10009.9170 | Val MSE 14076.5045 | Val MAE 676.9984 | Val MSE 689748.7188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   6%|         | 11/200 [7:32:40<141:34:59, 2696.82s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 010 | LR 0.003982 | Train MSE 9997.5639 | Val MSE 12164.1658 | Val MAE 570.8118 | Val MSE 596044.1211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   6%|         | 12/200 [7:45:57<110:39:12, 2118.90s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 011 | LR 0.003783 | Train MSE 8676.5275 | Val MSE 37049.6276 | Val MAE 1006.6403 | Val MSE 1815431.7578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   6%|         | 13/200 [7:51:59<82:25:19, 1586.74s/epoch] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 012 | LR 0.003593 | Train MSE 8414.5772 | Val MSE 11690.8309 | Val MAE 559.3520 | Val MSE 572850.7148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   7%|         | 14/200 [8:30:27<93:13:53, 1804.48s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 013 | LR 0.003414 | Train MSE 7983.3890 | Val MSE 34584.8360 | Val MAE 1040.4482 | Val MSE 1694656.9883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   8%|         | 15/200 [8:54:39<87:16:01, 1698.17s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 014 | LR 0.003243 | Train MSE 7645.2480 | Val MSE 9086.7221 | Val MAE 486.4455 | Val MSE 445249.3857\n",
            "Validation improved: 9576.386169 -> 9086.722076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   8%|         | 16/200 [9:33:31<96:33:01, 1889.03s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 015 | LR 0.003081 | Train MSE 7400.6779 | Val MSE 16032.6917 | Val MAE 647.8649 | Val MSE 785601.9121\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   8%|         | 17/200 [9:43:31<76:19:12, 1501.38s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 016 | LR 0.002927 | Train MSE 7053.3118 | Val MSE 16938.5577 | Val MAE 649.2918 | Val MSE 829989.3281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   9%|         | 18/200 [10:00:02<68:09:17, 1348.12s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 017 | LR 0.002781 | Train MSE 6811.5127 | Val MSE 10055.9805 | Val MAE 484.2866 | Val MSE 492743.0420\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  10%|         | 19/200 [10:10:10<56:35:56, 1125.72s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 018 | LR 0.002641 | Train MSE 6550.1073 | Val MSE 15812.0377 | Val MAE 629.5929 | Val MSE 774789.8574\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  10%|         | 20/200 [10:20:30<48:41:40, 973.89s/epoch] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 019 | LR 0.002509 | Train MSE 6467.1689 | Val MSE 22242.7582 | Val MAE 742.1007 | Val MSE 1089895.1719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  10%|         | 21/200 [10:38:56<50:23:56, 1013.61s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 020 | LR 0.002384 | Train MSE 6558.7782 | Val MSE 14904.4789 | Val MAE 610.6758 | Val MSE 730319.4570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  11%|         | 22/200 [10:52:56<47:32:14, 961.43s/epoch] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 021 | LR 0.002265 | Train MSE 6596.4149 | Val MSE 23249.5422 | Val MAE 758.1893 | Val MSE 1139227.5977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  12%|        | 23/200 [11:15:37<53:10:21, 1081.48s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 022 | LR 0.002151 | Train MSE 6421.0944 | Val MSE 30165.1314 | Val MAE 899.4417 | Val MSE 1478091.4453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  12%|        | 24/200 [11:48:30<65:56:43, 1348.88s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 023 | LR 0.002044 | Train MSE 6249.3977 | Val MSE 12680.2073 | Val MAE 581.3728 | Val MSE 621330.1582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  12%|        | 25/200 [12:06:47<61:53:35, 1273.23s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 024 | LR 0.001942 | Train MSE 6294.6207 | Val MSE 20160.6077 | Val MAE 720.7866 | Val MSE 987869.7598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  13%|        | 26/200 [12:29:37<62:56:50, 1302.36s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 025 | LR 0.001845 | Train MSE 6340.0740 | Val MSE 11592.2406 | Val MAE 600.2550 | Val MSE 568019.7891\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  14%|        | 27/200 [12:53:03<64:05:08, 1333.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 026 | LR 0.001752 | Train MSE 6776.9280 | Val MSE 24765.8148 | Val MAE 929.1552 | Val MSE 1213524.9336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  14%|        | 28/200 [13:21:17<68:52:04, 1441.42s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 027 | LR 0.001665 | Train MSE 6687.8810 | Val MSE 17611.7851 | Val MAE 654.9770 | Val MSE 862977.4707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  14%|        | 29/200 [13:49:25<71:59:40, 1515.68s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 028 | LR 0.001582 | Train MSE 6651.1510 | Val MSE 18218.9570 | Val MAE 667.7999 | Val MSE 892728.8906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  15%|        | 30/200 [14:08:50<66:35:58, 1410.34s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 029 | LR 0.001502 | Train MSE 7017.9118 | Val MSE 13929.3522 | Val MAE 589.0640 | Val MSE 682538.2500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  16%|        | 31/200 [14:52:32<83:16:37, 1773.95s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 030 | LR 0.001427 | Train MSE 7386.5598 | Val MSE 18589.0686 | Val MAE 685.3988 | Val MSE 910864.3535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  16%|        | 32/200 [15:22:03<82:44:35, 1773.07s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 031 | LR 0.001356 | Train MSE 7346.8356 | Val MSE 15646.3723 | Val MAE 619.2424 | Val MSE 766672.2578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  16%|        | 32/200 [15:37:22<82:01:12, 1757.58s/epoch]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[28], line 8\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train with improved function\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain_improved_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# lr = 0.007 => 8.946\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.007\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Lower learning rate\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# More patience\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
            "Cell \u001b[0;32mIn[27], line 76\u001b[0m, in \u001b[0;36mtrain_improved_model\u001b[0;34m(model, train_dataloader, val_dataloader, device, criterion, lr, epochs, patience)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_dataloader):\n\u001b[1;32m     75\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 76\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     77\u001b[0m     y \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# Skip invalid predictions\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/data_science/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/data_science/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[17], line 41\u001b[0m, in \u001b[0;36mAutoRegressiveLSTM.forward\u001b[0;34m(self, data, forcing_ratio)\u001b[0m\n\u001b[1;32m     38\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture_steps):\n\u001b[0;32m---> 41\u001b[0m     output, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(output)  \u001b[38;5;66;03m# (batch, 1, 2)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(pred)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/data_science/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/data_science/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m/opt/anaconda3/envs/data_science/lib/python3.9/site-packages/torch/nn/modules/rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1138\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1146\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_and_evaluate_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = TrajectoryDatasetTest(test_data, scale=scale)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
        "                         collate_fn=lambda xs: Batch.from_data_list(xs))\n",
        "\n",
        "best_model2 = torch.load(best_model)\n",
        "model = AutoRegressiveLSTM(input_dim=5, output_dim = 5, hidden_dim=512).to(device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25) # You can try different schedulers\n",
        "# criterion = nn.MSELoss()\n",
        "\n",
        "model.load_state_dict(best_model2)\n",
        "model.eval()\n",
        "\n",
        "pred_list = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        pred_norm = model(batch)\n",
        "        \n",
        "        # Reshape the prediction to (N, 60, 2)\n",
        "        pred = pred_norm[...,:2] * batch.scale.view(-1,1,1) + batch.origin.unsqueeze(1)\n",
        "        pred_list.append(pred.cpu().numpy())\n",
        "pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
        "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
        "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
        "output_df.index.name = 'index'\n",
        "output_df.to_csv('submission_lstm_5_out.csv', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5426.052734</td>\n",
              "      <td>1467.540771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5426.041992</td>\n",
              "      <td>1467.670532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5426.288086</td>\n",
              "      <td>1467.650269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5426.220215</td>\n",
              "      <td>1467.730713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5426.110352</td>\n",
              "      <td>1467.654907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 x            y\n",
              "index                          \n",
              "0      5426.052734  1467.540771\n",
              "1      5426.041992  1467.670532\n",
              "2      5426.288086  1467.650269\n",
              "3      5426.220215  1467.730713\n",
              "4      5426.110352  1467.654907"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "data-loading-and-submission-preperation",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "data_science",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 27.524611,
      "end_time": "2025-04-01T17:39:42.223757",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-01T17:39:14.699146",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
