{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n-C_P-zs-pY"
      },
      "source": [
        "# LSTM - vanilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = \"best_model0.pt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:17.728787Z",
          "iopub.status.busy": "2025-04-01T17:39:17.728324Z",
          "iopub.status.idle": "2025-04-01T17:39:18.875979Z",
          "shell.execute_reply": "2025-04-01T17:39:18.874618Z"
        },
        "id": "F4_wHjhZs-pa",
        "papermill": {
          "duration": 1.154057,
          "end_time": "2025-04-01T17:39:18.878059",
          "exception": false,
          "start_time": "2025-04-01T17:39:17.724002",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/salmawafa/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "/Users/salmawafa/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import Data, Batch\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:18.890746Z",
          "iopub.status.busy": "2025-04-01T17:39:18.890075Z",
          "iopub.status.idle": "2025-04-01T17:39:40.968717Z",
          "shell.execute_reply": "2025-04-01T17:39:40.967158Z"
        },
        "id": "09texa_os-pc",
        "papermill": {
          "duration": 22.084222,
          "end_time": "2025-04-01T17:39:40.970631",
          "exception": false,
          "start_time": "2025-04-01T17:39:18.886409",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data's shape (10000, 50, 110, 6)\n",
            "test_data's shape (2100, 50, 50, 6)\n"
          ]
        }
      ],
      "source": [
        "train_file = np.load('./cse-251-b-2025/train.npz')\n",
        "\n",
        "train_data = train_file['data']\n",
        "print(\"train_data's shape\", train_data.shape)\n",
        "test_file = np.load('./cse-251-b-2025/test_input.npz')\n",
        "\n",
        "test_data = test_file['data']\n",
        "print(\"test_data's shape\", test_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-01T17:39:40.97884Z",
          "iopub.status.busy": "2025-04-01T17:39:40.978362Z",
          "iopub.status.idle": "2025-04-01T17:39:41.323077Z",
          "shell.execute_reply": "2025-04-01T17:39:41.321787Z"
        },
        "id": "ckJbGP_ds-pc",
        "papermill": {
          "duration": 0.351374,
          "end_time": "2025-04-01T17:39:41.325147",
          "exception": false,
          "start_time": "2025-04-01T17:39:40.973773",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot one\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_matrix = train_data[0]\n",
        "\n",
        "for i in range(data_matrix.shape[0]):\n",
        "    xs = data_matrix[i, :, 0]\n",
        "    ys = data_matrix[i, :, 1]\n",
        "    # trim all zeros\n",
        "    xs = xs[xs != 0]\n",
        "    ys = ys[ys != 0]\n",
        "    # plot each line going from transparent to full\n",
        "    plt.plot(xs, ys)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrajectoryDatasetTrain(Dataset):\n",
        "    def __init__(self, data, scale=10.0, augment=True):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Training data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        augment: Whether to apply data augmentation (only for training)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        scene = self.data[idx]\n",
        "        # Getting 50 historical timestamps and 60 future timestamps\n",
        "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
        "        future = torch.tensor(scene[0, 50:, 2:4].copy(), dtype=torch.float32)  # (60, 2)\n",
        "        \n",
        "        # Data augmentation(only for training)\n",
        "        if self.augment:\n",
        "            if np.random.rand() < 0.5:\n",
        "                theta = np.random.uniform(-np.pi, np.pi)\n",
        "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
        "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
        "                # Rotate the historical trajectory and future trajectory\n",
        "                hist[..., :2] = hist[..., :2] @ R\n",
        "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
        "                future = future @ R\n",
        "            if np.random.rand() < 0.5:\n",
        "                hist[..., 0] *= -1\n",
        "                hist[..., 2] *= -1\n",
        "                future[:, 0] *= -1\n",
        "\n",
        "        # Use the last timeframe of the historical trajectory as the origin\n",
        "        origin = hist[0, 49, :2].copy()  # (2,)\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        # future = future - origin\n",
        "\n",
        "        # Normalize the historical trajectory and future trajectory\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "        future = future / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            y=future.type(torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0), # (1,2)\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32), # scalar e.g. 7.0\n",
        "        )\n",
        "        \n",
        "        # print(f'x: {data_item.x.shape}')\n",
        "        # print(f'y: {data_item.y.shape}')\n",
        "\n",
        "        return data_item\n",
        "    \n",
        "\n",
        "class TrajectoryDatasetTest(Dataset):\n",
        "    def __init__(self, data, scale=10.0):\n",
        "        \"\"\"\n",
        "        data: Shape (N, 50, 110, 6) Testing data\n",
        "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.scale = scale\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Testing data only contains historical trajectory\n",
        "        scene = self.data[idx]  # (50, 50, 6)\n",
        "        hist = scene.copy()\n",
        "        \n",
        "        origin = hist[0, 49, :2].copy()\n",
        "        hist[..., :2] = hist[..., :2] - origin\n",
        "        hist[..., :4] = hist[..., :4] / self.scale\n",
        "\n",
        "        data_item = Data(\n",
        "            x=torch.tensor(hist, dtype=torch.float32),\n",
        "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
        "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
        "        )\n",
        "        return data_item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple Silicon GPU\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(251)\n",
        "np.random.seed(42)\n",
        "\n",
        "scale = 7.0\n",
        "\n",
        "N = len(train_data)\n",
        "val_size = int(0.1 * N)\n",
        "train_size = N - val_size\n",
        "\n",
        "train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
        "val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
        "\n",
        "# Set device for training speedup\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "    print(\"Using Apple Silicon GPU\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"Using CUDA GPU\")\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of basic model that should work\n",
        "class SimpleLSTM(nn.Module):\n",
        "    # 2 layers 9.77 val\n",
        "    def __init__(self, input_dim=5, hidden_dim=512, output_dim=60*2, num_layers=1):\n",
        "        super(SimpleLSTM, self).__init__()\n",
        "        self.ego_encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.neighbor_encoder = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        # Add multi-layer prediction head for better results\n",
        "        self.fc1 = nn.Linear(hidden_dim*2, hidden_dim*2)\n",
        "        self.dropout = nn.Dropout(0.1)  # Add dropout for regularization\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim*2, output_dim)\n",
        "        \n",
        "        # Initialize weights properly\n",
        "        # for name, param in self.named_parameters():\n",
        "        #     if 'weight' in name:\n",
        "        #         nn.init.xavier_normal_(param)\n",
        "        #     elif 'bias' in name:\n",
        "        #         nn.init.constant_(param, 0.0)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        x = data.x[..., :5]\n",
        "        x = x.reshape(-1, 50, 50, 5)  # (batch_size, num_agents, seq_len, input_dim)\n",
        "        batch_size = x.size(0)\n",
        "        # x = x[:, 0, :, :]  # Only consider ego agent (index 0)\n",
        "        \n",
        "        # EGO AGENT\n",
        "        ego_traj = x[:, 0, :, :]  # (batch, 50, 5)\n",
        "        # Process through LSTM\n",
        "        ego_lstm_out, _ = self.ego_encoder(ego_traj)\n",
        "        # Extract final hidden state\n",
        "        ego_features = ego_lstm_out[:, -1, :]\n",
        "        \n",
        "        # CLOSEST NEIGHBOR\n",
        "        # ---- DISTANCES TO OTHER AGENTS ----\n",
        "        ego_pos = x[:, 0, 49, :2].unsqueeze(1)  # (batch, 1, 2)\n",
        "        agent_pos = x[:, :, 49, :2]  # (batch, 50, 2)\n",
        "        dists = torch.norm(agent_pos - ego_pos, dim=-1)  # (batch, 50)\n",
        "        dists[:, 0] = float('inf')  # mask out ego\n",
        "        \n",
        "        _, neighbor_ids = torch.topk(dists, k=1, dim=1, largest=False)  # (batch, 3)\n",
        "        \n",
        "        # ---- ENCODE NEIGHBORS ----\n",
        "        neighbor_out_list = []\n",
        "\n",
        "        for i in range(1):\n",
        "            idx = neighbor_ids[:, i]  # (batch,)\n",
        "            neighbor_trajs = torch.stack([x[b, idx[b]] for b in range(batch_size)], dim=0)  # (batch, 50, 5)\n",
        "\n",
        "            neighbor_lstm_out, _ = self.neighbor_encoder(neighbor_trajs)  # both: (num_layers, batch, hidden_dim)\n",
        "\n",
        "            neighbor_out_list.append(neighbor_lstm_out[:, -1, :])\n",
        "\n",
        "        # ---- CONCATENATE HIDDEN AND CELL STATES ----\n",
        "        all_features = torch.cat([ego_features] + neighbor_out_list, dim=1)  # (num_layers, batch, hidden_dim * 4)\n",
        "        \n",
        "        # Process through prediction head\n",
        "        features = self.relu(self.fc1(all_features))\n",
        "        features = self.dropout(features)\n",
        "        out = self.fc2(features)\n",
        "        \n",
        "        # Reshape to (batch_size, 60, 2)\n",
        "        return out.view(-1, 60, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_improved_model(model, train_dataloader, val_dataloader, \n",
        "                         device, criterion=nn.MSELoss(), \n",
        "                         lr=0.001, epochs=100, patience=15):\n",
        "    \"\"\"\n",
        "    Improved training function with better debugging and early stopping\n",
        "    \"\"\"\n",
        "    # Initialize optimizer with smaller learning rate\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    # Exponential decay scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "    \n",
        "    early_stopping_patience = patience\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement = 0\n",
        "    \n",
        "    # Save initial state for comparison\n",
        "    initial_state_dict = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "    \n",
        "    for epoch in tqdm.tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
        "        # ---- Training ----\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        num_train_batches = 0\n",
        "        \n",
        "        for batch in train_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            \n",
        "            # Check for NaN predictions\n",
        "            if torch.isnan(pred).any():\n",
        "                print(f\"WARNING: NaN detected in predictions during training\")\n",
        "                continue\n",
        "                \n",
        "            loss = criterion(pred, y)\n",
        "            \n",
        "            # Check if loss is valid\n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                print(f\"WARNING: Invalid loss value: {loss.item()}\")\n",
        "                continue\n",
        "                \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            \n",
        "            # More conservative gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            \n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            num_train_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid batches\n",
        "        if num_train_batches == 0:\n",
        "            print(\"WARNING: No valid training batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        train_loss /= num_train_batches\n",
        "        \n",
        "        # ---- Validation ----\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_mae = 0\n",
        "        val_mse = 0\n",
        "        num_val_batches = 0\n",
        "        \n",
        "        # Sample predictions for debugging\n",
        "        sample_input = None\n",
        "        sample_pred = None\n",
        "        sample_target = None\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(val_dataloader):\n",
        "                batch = batch.to(device)\n",
        "                pred = model(batch)\n",
        "                y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "                \n",
        "                # Store sample for debugging\n",
        "                if batch_idx == 0 and sample_input is None:\n",
        "                    sample_input = batch.x[0].cpu().numpy()\n",
        "                    sample_pred = pred[0].cpu().numpy()\n",
        "                    sample_target = y[0].cpu().numpy()\n",
        "                \n",
        "                # Skip invalid predictions\n",
        "                if torch.isnan(pred).any():\n",
        "                    print(f\"WARNING: NaN detected in predictions during validation\")\n",
        "                    continue\n",
        "                    \n",
        "                batch_loss = criterion(pred, y).item()\n",
        "                val_loss += batch_loss\n",
        "                \n",
        "                # Unnormalize for real-world metrics\n",
        "                pred_unnorm = pred * batch.scale.view(-1, 1, 1)\n",
        "                y_unnorm = y * batch.scale.view(-1, 1, 1)\n",
        "                \n",
        "                val_mae += nn.L1Loss()(pred_unnorm, y_unnorm).item()\n",
        "                val_mse += nn.MSELoss()(pred_unnorm, y_unnorm).item()\n",
        "                \n",
        "                num_val_batches += 1\n",
        "        \n",
        "        # Skip epoch if no valid validation batches\n",
        "        if num_val_batches == 0:\n",
        "            print(\"WARNING: No valid validation batches in this epoch\")\n",
        "            continue\n",
        "            \n",
        "        val_loss /= num_val_batches\n",
        "        val_mae /= num_val_batches\n",
        "        val_mse /= num_val_batches\n",
        "        \n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Print with more details\n",
        "        tqdm.tqdm.write(\n",
        "            f\"Epoch {epoch:03d} | LR {optimizer.param_groups[0]['lr']:.6f} | \"\n",
        "            f\"Train MSE {train_loss:.4f} | Val MSE {val_loss:.4f} | \"\n",
        "            f\"Val MAE {val_mae:.4f} | Val MSE {val_mse:.4f}\"\n",
        "        )\n",
        "        \n",
        "        # Debug output - first 3 predictions vs targets\n",
        "        if epoch % 5 == 0:\n",
        "            tqdm.tqdm.write(f\"Sample pred first 3 steps: {sample_pred[:3]}\")\n",
        "            tqdm.tqdm.write(f\"Sample target first 3 steps: {sample_target[:3]}\")\n",
        "            \n",
        "            # Check if model weights are changing\n",
        "            if epoch > 0:\n",
        "                weight_change = False\n",
        "                for name, param in model.named_parameters():\n",
        "                    if param.requires_grad:\n",
        "                        initial_param = initial_state_dict[name]\n",
        "                        if not torch.allclose(param, initial_param, rtol=1e-4):\n",
        "                            weight_change = True\n",
        "                            break\n",
        "                if not weight_change:\n",
        "                    tqdm.tqdm.write(\"WARNING: Model weights barely changing!\")\n",
        "        \n",
        "        # Relaxed improvement criterion - consider any improvement\n",
        "        if val_loss < best_val_loss:\n",
        "            tqdm.tqdm.write(f\"Validation improved: {best_val_loss:.6f} -> {val_loss:.6f}\")\n",
        "            best_val_loss = val_loss\n",
        "            no_improvement = 0\n",
        "            torch.save(model.state_dict(), best_model)\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "            if no_improvement >= early_stopping_patience:\n",
        "                print(f\"Early stopping after {epoch+1} epochs without improvement\")\n",
        "                break\n",
        "    \n",
        "    # Load best model before returning\n",
        "    model.load_state_dict(torch.load(best_model))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage\n",
        "def train_and_evaluate_model():\n",
        "    # Create model\n",
        "    model = SimpleLSTM(input_dim=5, hidden_dim=512)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Train with improved function\n",
        "    train_improved_model(\n",
        "        model=model,\n",
        "        train_dataloader=train_dataloader,\n",
        "        val_dataloader=val_dataloader,\n",
        "        device=device,\n",
        "        # lr = 0.007 => 8.946\n",
        "        lr=0.005,  # Lower learning rate\n",
        "        patience=20,  # More patience\n",
        "        epochs=150\n",
        "    )\n",
        "    \n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    test_mse = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            batch = batch.to(device)\n",
        "            pred = model(batch)\n",
        "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
        "            \n",
        "            # Unnormalize\n",
        "            pred = pred * batch.scale.view(-1, 1, 1)\n",
        "            y = y * batch.scale.view(-1, 1, 1)\n",
        "            \n",
        "            test_mse += nn.MSELoss()(pred, y).item()\n",
        "    \n",
        "    test_mse /= len(val_dataloader)\n",
        "    print(f\"Val MSE: {test_mse:.4f}\")\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   0%|          | 0/150 [00:00<?, ?epoch/s]/var/folders/w3/lr66s56958q3881y1btpylth0000gn/T/ipykernel_99874/1407810273.py:30: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  future = future @ R\n",
            "Epoch:   1%|          | 1/150 [00:25<1:04:28, 25.97s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 000 | LR 0.004750 | Train MSE 0.1033 | Val MSE 0.0744 | Val MAE 1.2737 | Val MSE 3.6462\n",
            "Sample pred first 3 steps: [[ 0.00992205 -0.04663911]\n",
            " [ 0.01231095 -0.04625532]\n",
            " [ 0.00725001 -0.04788506]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n",
            "Validation improved: inf -> 0.074411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   1%|▏         | 2/150 [00:43<51:28, 20.87s/epoch]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 | LR 0.004513 | Train MSE 0.0700 | Val MSE 0.0638 | Val MAE 1.1364 | Val MSE 3.1270\n",
            "Validation improved: 0.074411 -> 0.063817\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   2%|▏         | 3/150 [01:00<46:50, 19.12s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 002 | LR 0.004287 | Train MSE 0.0684 | Val MSE 0.0701 | Val MAE 1.1789 | Val MSE 3.4338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   3%|▎         | 4/150 [01:17<45:02, 18.51s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 003 | LR 0.004073 | Train MSE 0.0688 | Val MSE 0.0638 | Val MAE 1.0734 | Val MSE 3.1249\n",
            "Validation improved: 0.063817 -> 0.063773\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   3%|▎         | 5/150 [01:34<42:59, 17.79s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 004 | LR 0.003869 | Train MSE 0.5174 | Val MSE 0.0744 | Val MAE 1.3364 | Val MSE 3.6449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   4%|▍         | 6/150 [01:51<42:06, 17.55s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 005 | LR 0.003675 | Train MSE 0.0720 | Val MSE 0.0610 | Val MAE 1.0783 | Val MSE 2.9883\n",
            "Sample pred first 3 steps: [[-0.02520285 -0.06868999]\n",
            " [-0.02745395 -0.06837235]\n",
            " [-0.02728537 -0.06990357]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n",
            "Validation improved: 0.063773 -> 0.060985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   5%|▍         | 7/150 [02:08<41:18, 17.33s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 006 | LR 0.003492 | Train MSE 0.0685 | Val MSE 0.0603 | Val MAE 1.0824 | Val MSE 2.9567\n",
            "Validation improved: 0.060985 -> 0.060341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   5%|▌         | 8/150 [02:24<40:26, 17.08s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 007 | LR 0.003317 | Train MSE 0.0639 | Val MSE 0.0555 | Val MAE 1.0790 | Val MSE 2.7202\n",
            "Validation improved: 0.060341 -> 0.055515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   6%|▌         | 9/150 [02:41<39:38, 16.87s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 008 | LR 0.003151 | Train MSE 0.0601 | Val MSE 0.0509 | Val MAE 1.0113 | Val MSE 2.4963\n",
            "Validation improved: 0.055515 -> 0.050945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   7%|▋         | 10/150 [02:58<39:45, 17.04s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 009 | LR 0.002994 | Train MSE 0.0576 | Val MSE 0.0532 | Val MAE 0.9599 | Val MSE 2.6074\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   7%|▋         | 11/150 [03:14<38:53, 16.78s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 010 | LR 0.002844 | Train MSE 0.0565 | Val MSE 0.0475 | Val MAE 0.9199 | Val MSE 2.3257\n",
            "Sample pred first 3 steps: [[ 0.04619426 -0.05129036]\n",
            " [ 0.04778666 -0.04876822]\n",
            " [ 0.04918512 -0.04919636]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n",
            "Validation improved: 0.050945 -> 0.047464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   8%|▊         | 12/150 [03:32<38:49, 16.88s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 011 | LR 0.002702 | Train MSE 0.0537 | Val MSE 0.0462 | Val MAE 0.9179 | Val MSE 2.2616\n",
            "Validation improved: 0.047464 -> 0.046155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   9%|▊         | 13/150 [03:48<38:08, 16.70s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 012 | LR 0.002567 | Train MSE 0.0524 | Val MSE 0.0447 | Val MAE 0.8885 | Val MSE 2.1916\n",
            "Validation improved: 0.046155 -> 0.044727\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   9%|▉         | 14/150 [04:05<38:22, 16.93s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 013 | LR 0.002438 | Train MSE 0.0520 | Val MSE 0.0469 | Val MAE 0.9059 | Val MSE 2.3001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  10%|█         | 15/150 [04:22<37:46, 16.79s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 014 | LR 0.002316 | Train MSE 0.0517 | Val MSE 0.0433 | Val MAE 0.8659 | Val MSE 2.1240\n",
            "Validation improved: 0.044727 -> 0.043347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  11%|█         | 16/150 [04:39<37:44, 16.90s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 015 | LR 0.002201 | Train MSE 0.0496 | Val MSE 0.0426 | Val MAE 0.8819 | Val MSE 2.0881\n",
            "Sample pred first 3 steps: [[-0.02741403 -0.05114945]\n",
            " [-0.02912626 -0.04875872]\n",
            " [-0.03017307 -0.04616387]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n",
            "Validation improved: 0.043347 -> 0.042614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  11%|█▏        | 17/150 [04:55<37:05, 16.73s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 016 | LR 0.002091 | Train MSE 0.0492 | Val MSE 0.0410 | Val MAE 0.8086 | Val MSE 2.0081\n",
            "Validation improved: 0.042614 -> 0.040981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  12%|█▏        | 18/150 [05:12<36:32, 16.61s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 017 | LR 0.001986 | Train MSE 0.0486 | Val MSE 0.0408 | Val MAE 0.8148 | Val MSE 1.9980\n",
            "Validation improved: 0.040981 -> 0.040776\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  13%|█▎        | 19/150 [05:28<36:01, 16.50s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 018 | LR 0.001887 | Train MSE 0.0478 | Val MSE 0.0488 | Val MAE 0.9700 | Val MSE 2.3891\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  13%|█▎        | 20/150 [05:45<36:12, 16.71s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 019 | LR 0.001792 | Train MSE 0.0478 | Val MSE 0.0379 | Val MAE 0.7917 | Val MSE 1.8592\n",
            "Validation improved: 0.040776 -> 0.037943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  14%|█▍        | 21/150 [06:01<35:35, 16.56s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 020 | LR 0.001703 | Train MSE 0.0454 | Val MSE 0.0395 | Val MAE 0.8157 | Val MSE 1.9369\n",
            "Sample pred first 3 steps: [[-0.00889807 -0.03894227]\n",
            " [-0.00970895 -0.03833549]\n",
            " [-0.0098531  -0.03717237]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  15%|█▍        | 22/150 [06:19<35:59, 16.87s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 021 | LR 0.001618 | Train MSE 0.0449 | Val MSE 0.0391 | Val MAE 0.8263 | Val MSE 1.9167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  15%|█▌        | 23/150 [06:35<35:19, 16.69s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 022 | LR 0.001537 | Train MSE 0.0445 | Val MSE 0.0378 | Val MAE 0.7825 | Val MSE 1.8531\n",
            "Validation improved: 0.037943 -> 0.037819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  16%|█▌        | 24/150 [06:52<35:21, 16.84s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 023 | LR 0.001460 | Train MSE 0.0439 | Val MSE 0.0376 | Val MAE 0.7606 | Val MSE 1.8436\n",
            "Validation improved: 0.037819 -> 0.037625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  17%|█▋        | 25/150 [07:08<34:28, 16.55s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 024 | LR 0.001387 | Train MSE 0.0437 | Val MSE 0.0389 | Val MAE 0.8041 | Val MSE 1.9083\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  17%|█▋        | 26/150 [07:25<34:20, 16.62s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 025 | LR 0.001318 | Train MSE 0.0432 | Val MSE 0.0379 | Val MAE 0.7691 | Val MSE 1.8562\n",
            "Sample pred first 3 steps: [[ 0.00541966 -0.00831529]\n",
            " [ 0.00445266 -0.00721668]\n",
            " [ 0.00459507 -0.00587184]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  18%|█▊        | 27/150 [07:42<34:05, 16.63s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 026 | LR 0.001252 | Train MSE 0.0431 | Val MSE 0.0379 | Val MAE 0.7765 | Val MSE 1.8569\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  19%|█▊        | 28/150 [07:58<33:36, 16.53s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 027 | LR 0.001189 | Train MSE 0.0421 | Val MSE 0.0375 | Val MAE 0.7691 | Val MSE 1.8370\n",
            "Validation improved: 0.037625 -> 0.037489\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  19%|█▉        | 29/150 [08:14<33:02, 16.39s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 028 | LR 0.001130 | Train MSE 0.0418 | Val MSE 0.0388 | Val MAE 0.7996 | Val MSE 1.8997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  20%|██        | 30/150 [08:30<32:48, 16.40s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 029 | LR 0.001073 | Train MSE 0.0420 | Val MSE 0.0369 | Val MAE 0.7615 | Val MSE 1.8086\n",
            "Validation improved: 0.037489 -> 0.036910\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  21%|██        | 31/150 [08:46<32:20, 16.31s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 030 | LR 0.001020 | Train MSE 0.0416 | Val MSE 0.0390 | Val MAE 0.7873 | Val MSE 1.9093\n",
            "Sample pred first 3 steps: [[0.0094606  0.01331409]\n",
            " [0.00830241 0.01275019]\n",
            " [0.00735157 0.0118613 ]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  21%|██▏       | 32/150 [09:03<32:01, 16.28s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 031 | LR 0.000969 | Train MSE 0.0408 | Val MSE 0.0376 | Val MAE 0.7709 | Val MSE 1.8405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  22%|██▏       | 33/150 [09:19<31:39, 16.23s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 032 | LR 0.000920 | Train MSE 0.0411 | Val MSE 0.0376 | Val MAE 0.7638 | Val MSE 1.8412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  23%|██▎       | 34/150 [09:36<32:03, 16.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 033 | LR 0.000874 | Train MSE 0.0409 | Val MSE 0.0378 | Val MAE 0.7523 | Val MSE 1.8498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  23%|██▎       | 35/150 [09:54<32:33, 16.99s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 034 | LR 0.000830 | Train MSE 0.0402 | Val MSE 0.0366 | Val MAE 0.7376 | Val MSE 1.7911\n",
            "Validation improved: 0.036910 -> 0.036553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  24%|██▍       | 36/150 [10:11<32:14, 16.97s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 035 | LR 0.000789 | Train MSE 0.0406 | Val MSE 0.0375 | Val MAE 0.7666 | Val MSE 1.8399\n",
            "Sample pred first 3 steps: [[0.01489472 0.00157697]\n",
            " [0.0138477  0.00075525]\n",
            " [0.01354785 0.00089134]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  25%|██▍       | 37/150 [10:28<31:56, 16.96s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 036 | LR 0.000749 | Train MSE 0.0400 | Val MSE 0.0368 | Val MAE 0.7491 | Val MSE 1.8020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  25%|██▌       | 38/150 [10:45<31:26, 16.85s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 037 | LR 0.000712 | Train MSE 0.0394 | Val MSE 0.0367 | Val MAE 0.7654 | Val MSE 1.7982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  26%|██▌       | 39/150 [11:00<30:28, 16.48s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 038 | LR 0.000676 | Train MSE 0.0393 | Val MSE 0.0370 | Val MAE 0.7892 | Val MSE 1.8148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  27%|██▋       | 40/150 [11:16<29:39, 16.17s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 039 | LR 0.000643 | Train MSE 0.0396 | Val MSE 0.0360 | Val MAE 0.7351 | Val MSE 1.7631\n",
            "Validation improved: 0.036553 -> 0.035981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  27%|██▋       | 41/150 [11:31<29:11, 16.07s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 040 | LR 0.000610 | Train MSE 0.0395 | Val MSE 0.0366 | Val MAE 0.7524 | Val MSE 1.7924\n",
            "Sample pred first 3 steps: [[ 0.00427895 -0.01091008]\n",
            " [ 0.00310627 -0.01016471]\n",
            " [ 0.00241658 -0.0098084 ]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  28%|██▊       | 42/150 [11:47<28:39, 15.92s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 041 | LR 0.000580 | Train MSE 0.0392 | Val MSE 0.0363 | Val MAE 0.7430 | Val MSE 1.7807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  29%|██▊       | 43/150 [12:03<28:15, 15.85s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 042 | LR 0.000551 | Train MSE 0.0387 | Val MSE 0.0365 | Val MAE 0.7316 | Val MSE 1.7887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  29%|██▉       | 44/150 [12:18<27:53, 15.79s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 043 | LR 0.000523 | Train MSE 0.0389 | Val MSE 0.0357 | Val MAE 0.7309 | Val MSE 1.7501\n",
            "Validation improved: 0.035981 -> 0.035716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  30%|███       | 45/150 [12:36<28:25, 16.24s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 044 | LR 0.000497 | Train MSE 0.0385 | Val MSE 0.0358 | Val MAE 0.7342 | Val MSE 1.7555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  31%|███       | 46/150 [12:53<28:35, 16.49s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 045 | LR 0.000472 | Train MSE 0.0383 | Val MSE 0.0348 | Val MAE 0.7138 | Val MSE 1.7069\n",
            "Sample pred first 3 steps: [[ 0.00129613 -0.00150009]\n",
            " [ 0.00080091 -0.00032061]\n",
            " [ 0.00067473  0.00117258]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n",
            "Validation improved: 0.035716 -> 0.034835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  31%|███▏      | 47/150 [13:10<28:34, 16.65s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 046 | LR 0.000449 | Train MSE 0.0385 | Val MSE 0.0353 | Val MAE 0.7293 | Val MSE 1.7279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  32%|███▏      | 48/150 [13:26<28:09, 16.56s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 047 | LR 0.000426 | Train MSE 0.0379 | Val MSE 0.0352 | Val MAE 0.7278 | Val MSE 1.7242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  33%|███▎      | 49/150 [13:43<28:15, 16.78s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 048 | LR 0.000405 | Train MSE 0.0380 | Val MSE 0.0354 | Val MAE 0.7162 | Val MSE 1.7370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  33%|███▎      | 50/150 [14:00<27:45, 16.66s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 049 | LR 0.000385 | Train MSE 0.0376 | Val MSE 0.0352 | Val MAE 0.7326 | Val MSE 1.7259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  34%|███▍      | 51/150 [14:17<27:37, 16.74s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 050 | LR 0.000365 | Train MSE 0.0376 | Val MSE 0.0353 | Val MAE 0.7130 | Val MSE 1.7306\n",
            "Sample pred first 3 steps: [[-0.00335962 -0.01554899]\n",
            " [-0.00377673 -0.0144316 ]\n",
            " [-0.00407497 -0.01349828]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  35%|███▍      | 52/150 [14:33<27:03, 16.57s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 051 | LR 0.000347 | Train MSE 0.0375 | Val MSE 0.0355 | Val MAE 0.7408 | Val MSE 1.7404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  35%|███▌      | 53/150 [14:50<26:59, 16.70s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 052 | LR 0.000330 | Train MSE 0.0372 | Val MSE 0.0354 | Val MAE 0.7312 | Val MSE 1.7331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  36%|███▌      | 54/150 [15:06<26:26, 16.53s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 053 | LR 0.000313 | Train MSE 0.0371 | Val MSE 0.0350 | Val MAE 0.7201 | Val MSE 1.7132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  37%|███▋      | 55/150 [15:23<26:30, 16.74s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 054 | LR 0.000298 | Train MSE 0.0370 | Val MSE 0.0350 | Val MAE 0.7141 | Val MSE 1.7142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  37%|███▋      | 56/150 [15:40<26:03, 16.64s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 055 | LR 0.000283 | Train MSE 0.0370 | Val MSE 0.0349 | Val MAE 0.7085 | Val MSE 1.7120\n",
            "Sample pred first 3 steps: [[ 0.00280163 -0.01758193]\n",
            " [ 0.00182379 -0.01675399]\n",
            " [ 0.00125464 -0.01619411]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  38%|███▊      | 57/150 [15:56<25:34, 16.50s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 056 | LR 0.000269 | Train MSE 0.0369 | Val MSE 0.0353 | Val MAE 0.7099 | Val MSE 1.7280\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  39%|███▊      | 58/150 [16:12<25:17, 16.49s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 057 | LR 0.000255 | Train MSE 0.0367 | Val MSE 0.0349 | Val MAE 0.7144 | Val MSE 1.7080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  39%|███▉      | 59/150 [16:29<25:09, 16.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 058 | LR 0.000242 | Train MSE 0.0366 | Val MSE 0.0348 | Val MAE 0.7049 | Val MSE 1.7065\n",
            "Validation improved: 0.034835 -> 0.034826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  40%|████      | 60/150 [16:46<24:53, 16.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 059 | LR 0.000230 | Train MSE 0.0368 | Val MSE 0.0348 | Val MAE 0.7062 | Val MSE 1.7075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  41%|████      | 61/150 [17:02<24:33, 16.56s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 060 | LR 0.000219 | Train MSE 0.0365 | Val MSE 0.0350 | Val MAE 0.7232 | Val MSE 1.7162\n",
            "Sample pred first 3 steps: [[ 5.0927326e-04 -8.1249084e-03]\n",
            " [ 1.9282475e-04 -7.8815129e-03]\n",
            " [-1.2870878e-05 -7.5734816e-03]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  41%|████▏     | 62/150 [17:19<24:27, 16.68s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 061 | LR 0.000208 | Train MSE 0.0363 | Val MSE 0.0346 | Val MAE 0.7093 | Val MSE 1.6963\n",
            "Validation improved: 0.034826 -> 0.034619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  42%|████▏     | 63/150 [17:36<24:14, 16.71s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 062 | LR 0.000197 | Train MSE 0.0366 | Val MSE 0.0353 | Val MAE 0.7249 | Val MSE 1.7300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  43%|████▎     | 64/150 [17:53<24:15, 16.92s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 063 | LR 0.000188 | Train MSE 0.0364 | Val MSE 0.0349 | Val MAE 0.7177 | Val MSE 1.7112\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  43%|████▎     | 65/150 [18:10<23:49, 16.81s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 064 | LR 0.000178 | Train MSE 0.0365 | Val MSE 0.0348 | Val MAE 0.7126 | Val MSE 1.7064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  44%|████▍     | 66/150 [18:26<23:18, 16.65s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 065 | LR 0.000169 | Train MSE 0.0363 | Val MSE 0.0347 | Val MAE 0.7101 | Val MSE 1.6980\n",
            "Sample pred first 3 steps: [[ 3.6428124e-04  2.8800839e-03]\n",
            " [-3.8877130e-05  3.7846728e-03]\n",
            " [-2.7683005e-04  4.6325605e-03]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  45%|████▍     | 67/150 [18:42<22:43, 16.42s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 066 | LR 0.000161 | Train MSE 0.0359 | Val MSE 0.0345 | Val MAE 0.7049 | Val MSE 1.6886\n",
            "Validation improved: 0.034619 -> 0.034460\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  45%|████▌     | 68/150 [18:57<21:52, 16.01s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 067 | LR 0.000153 | Train MSE 0.0361 | Val MSE 0.0344 | Val MAE 0.7043 | Val MSE 1.6870\n",
            "Validation improved: 0.034460 -> 0.034428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  46%|████▌     | 69/150 [19:07<19:13, 14.24s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 068 | LR 0.000145 | Train MSE 0.0360 | Val MSE 0.0343 | Val MAE 0.7090 | Val MSE 1.6810\n",
            "Validation improved: 0.034428 -> 0.034307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  47%|████▋     | 70/150 [19:17<17:04, 12.80s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 069 | LR 0.000138 | Train MSE 0.0353 | Val MSE 0.0346 | Val MAE 0.7055 | Val MSE 1.6960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  47%|████▋     | 71/150 [19:26<15:36, 11.86s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 070 | LR 0.000131 | Train MSE 0.0359 | Val MSE 0.0346 | Val MAE 0.7100 | Val MSE 1.6963\n",
            "Sample pred first 3 steps: [[-0.0005482  -0.00989815]\n",
            " [-0.00031289 -0.00955626]\n",
            " [-0.000378   -0.00904732]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  48%|████▊     | 72/150 [19:36<14:43, 11.33s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 071 | LR 0.000124 | Train MSE 0.0354 | Val MSE 0.0346 | Val MAE 0.7073 | Val MSE 1.6935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  49%|████▊     | 73/150 [19:48<14:33, 11.34s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 072 | LR 0.000118 | Train MSE 0.0358 | Val MSE 0.0346 | Val MAE 0.7069 | Val MSE 1.6939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  49%|████▉     | 74/150 [19:58<13:56, 11.01s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 073 | LR 0.000112 | Train MSE 0.0357 | Val MSE 0.0345 | Val MAE 0.7023 | Val MSE 1.6895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  50%|█████     | 75/150 [20:08<13:24, 10.72s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 074 | LR 0.000107 | Train MSE 0.0355 | Val MSE 0.0347 | Val MAE 0.7072 | Val MSE 1.6981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  51%|█████     | 76/150 [20:18<12:57, 10.50s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 075 | LR 0.000101 | Train MSE 0.0357 | Val MSE 0.0347 | Val MAE 0.7062 | Val MSE 1.7022\n",
            "Sample pred first 3 steps: [[ 0.01003844 -0.0128159 ]\n",
            " [ 0.00964749 -0.01202324]\n",
            " [ 0.00924278 -0.0112793 ]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  51%|█████▏    | 77/150 [20:28<12:25, 10.21s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 076 | LR 0.000096 | Train MSE 0.0355 | Val MSE 0.0347 | Val MAE 0.7177 | Val MSE 1.7005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  52%|█████▏    | 78/150 [20:37<12:03, 10.05s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 077 | LR 0.000091 | Train MSE 0.0353 | Val MSE 0.0342 | Val MAE 0.7005 | Val MSE 1.6780\n",
            "Validation improved: 0.034307 -> 0.034244\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  53%|█████▎    | 79/150 [20:47<11:47,  9.96s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 078 | LR 0.000087 | Train MSE 0.0355 | Val MSE 0.0342 | Val MAE 0.7023 | Val MSE 1.6759\n",
            "Validation improved: 0.034244 -> 0.034202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  53%|█████▎    | 80/150 [20:56<11:24,  9.78s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 079 | LR 0.000083 | Train MSE 0.0352 | Val MSE 0.0345 | Val MAE 0.7028 | Val MSE 1.6892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  54%|█████▍    | 81/150 [21:06<11:05,  9.65s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 080 | LR 0.000078 | Train MSE 0.0356 | Val MSE 0.0346 | Val MAE 0.7107 | Val MSE 1.6947\n",
            "Sample pred first 3 steps: [[-0.00109966 -0.00730716]\n",
            " [-0.00152688 -0.00639898]\n",
            " [-0.00193236 -0.00560246]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  55%|█████▍    | 82/150 [21:15<10:51,  9.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 081 | LR 0.000075 | Train MSE 0.0355 | Val MSE 0.0347 | Val MAE 0.7054 | Val MSE 1.7005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  55%|█████▌    | 83/150 [21:25<10:40,  9.56s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 082 | LR 0.000071 | Train MSE 0.0353 | Val MSE 0.0347 | Val MAE 0.7067 | Val MSE 1.6999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  56%|█████▌    | 84/150 [21:34<10:32,  9.59s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 083 | LR 0.000067 | Train MSE 0.0353 | Val MSE 0.0348 | Val MAE 0.7051 | Val MSE 1.7033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  57%|█████▋    | 85/150 [21:44<10:22,  9.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 084 | LR 0.000064 | Train MSE 0.0350 | Val MSE 0.0345 | Val MAE 0.7009 | Val MSE 1.6906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  57%|█████▋    | 86/150 [21:53<10:11,  9.55s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 085 | LR 0.000061 | Train MSE 0.0354 | Val MSE 0.0346 | Val MAE 0.6995 | Val MSE 1.6945\n",
            "Sample pred first 3 steps: [[-2.9839575e-05 -1.4578316e-02]\n",
            " [-2.4737790e-04 -1.3793139e-02]\n",
            " [-5.6646392e-04 -1.3180531e-02]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  58%|█████▊    | 87/150 [22:03<09:57,  9.49s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 086 | LR 0.000058 | Train MSE 0.0354 | Val MSE 0.0346 | Val MAE 0.6983 | Val MSE 1.6939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  59%|█████▊    | 88/150 [22:12<09:49,  9.50s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 087 | LR 0.000055 | Train MSE 0.0350 | Val MSE 0.0347 | Val MAE 0.7044 | Val MSE 1.6995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  59%|█████▉    | 89/150 [22:22<09:44,  9.58s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 088 | LR 0.000052 | Train MSE 0.0350 | Val MSE 0.0346 | Val MAE 0.7076 | Val MSE 1.6966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  60%|██████    | 90/150 [22:32<09:42,  9.71s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 089 | LR 0.000049 | Train MSE 0.0352 | Val MSE 0.0346 | Val MAE 0.7017 | Val MSE 1.6935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  61%|██████    | 91/150 [22:42<09:45,  9.92s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 090 | LR 0.000047 | Train MSE 0.0353 | Val MSE 0.0343 | Val MAE 0.7000 | Val MSE 1.6831\n",
            "Sample pred first 3 steps: [[ 0.00148171 -0.00773643]\n",
            " [ 0.00119276 -0.00722106]\n",
            " [ 0.00081966 -0.00666295]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  61%|██████▏   | 92/150 [22:52<09:32,  9.88s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 091 | LR 0.000045 | Train MSE 0.0352 | Val MSE 0.0345 | Val MAE 0.7039 | Val MSE 1.6910\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  62%|██████▏   | 93/150 [23:02<09:17,  9.79s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 092 | LR 0.000042 | Train MSE 0.0352 | Val MSE 0.0345 | Val MAE 0.6993 | Val MSE 1.6899\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  63%|██████▎   | 94/150 [23:11<09:04,  9.73s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 093 | LR 0.000040 | Train MSE 0.0344 | Val MSE 0.0345 | Val MAE 0.6997 | Val MSE 1.6898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  63%|██████▎   | 95/150 [23:21<08:58,  9.79s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 094 | LR 0.000038 | Train MSE 0.0351 | Val MSE 0.0344 | Val MAE 0.7033 | Val MSE 1.6865\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  64%|██████▍   | 96/150 [23:31<08:45,  9.73s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 095 | LR 0.000036 | Train MSE 0.0349 | Val MSE 0.0344 | Val MAE 0.7043 | Val MSE 1.6872\n",
            "Sample pred first 3 steps: [[0.00515417 0.0008028 ]\n",
            " [0.00515135 0.00083889]\n",
            " [0.00499601 0.00087211]]\n",
            "Sample target first 3 steps: [[-1.0263214e-05  5.1069769e-06]\n",
            " [-8.2099714e-06  2.6287930e-06]\n",
            " [ 1.4959690e-05 -1.9491419e-05]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  65%|██████▍   | 97/150 [23:40<08:32,  9.67s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 096 | LR 0.000035 | Train MSE 0.0349 | Val MSE 0.0343 | Val MAE 0.6968 | Val MSE 1.6821\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  65%|██████▌   | 98/150 [23:50<08:26,  9.74s/epoch]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 097 | LR 0.000033 | Train MSE 0.0351 | Val MSE 0.0344 | Val MAE 0.7023 | Val MSE 1.6845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  65%|██████▌   | 98/150 [24:00<12:44, 14.70s/epoch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 098 | LR 0.000031 | Train MSE 0.0351 | Val MSE 0.0344 | Val MAE 0.6999 | Val MSE 1.6844\n",
            "Early stopping after 99 epochs without improvement\n",
            "Val MSE: 1.6759\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SimpleLSTM(\n",
              "  (ego_encoder): LSTM(5, 512, batch_first=True)\n",
              "  (neighbor_encoder): LSTM(5, 512, batch_first=True)\n",
              "  (fc1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=1024, out_features=120, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# added more epochs: 150\n",
        "train_and_evaluate_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = TrajectoryDatasetTest(test_data, scale=scale)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
        "                         collate_fn=lambda xs: Batch.from_data_list(xs))\n",
        "\n",
        "best_model2 = torch.load(best_model)\n",
        "model = SimpleLSTM().to(device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.25) # You can try different schedulers\n",
        "# criterion = nn.MSELoss()\n",
        "\n",
        "model.load_state_dict(best_model2)\n",
        "model.eval()\n",
        "\n",
        "pred_list = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        pred_vel_norm = model(batch)\n",
        "        \n",
        "        # Reshape the prediction to (N, 60, 2)\n",
        "        pred_vel = pred_vel_norm * batch.scale.view(-1,1,1)\n",
        "        \n",
        "        # Get origin in meters (position at t=49 for ego)\n",
        "        # origin = batch.origin  # (B, 1, 2)\n",
        "        origin = batch.origin.unsqueeze(1)  # Ensure shape is (B, 1, 2)\n",
        "        \n",
        "        # Integrate velocity to get position over 60 steps\n",
        "        dt = 0.1  # seconds per step\n",
        "        pred_pos = [origin]  # list of (B, 1, 2)\n",
        "        \n",
        "        for t in range(60):\n",
        "            next_pos = pred_pos[-1] + pred_vel[:, t:t+1, :] * dt  # (B, 1, 2)\n",
        "            pred_pos.append(next_pos)\n",
        "        \n",
        "        # Concatenate positions across time steps\n",
        "        pred_xy = torch.cat(pred_pos[1:], dim=1)  # skip initial origin, get (B, 60, 2)\n",
        "\n",
        "        pred_list.append(pred_xy.cpu().numpy())\n",
        "        \n",
        "pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
        "pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
        "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
        "output_df.index.name = 'index'\n",
        "output_df.to_csv('submission_lstm_simple_auto8.csv', index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "data-loading-and-submission-preperation",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 27.524611,
      "end_time": "2025-04-01T17:39:42.223757",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-01T17:39:14.699146",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
